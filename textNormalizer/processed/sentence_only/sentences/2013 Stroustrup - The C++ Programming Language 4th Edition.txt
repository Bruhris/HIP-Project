San Francisco New York.
Mexico City ptg10564057 Many of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks.
Where those designations appear in this book, and the publisher was aware of a trademark claim, the designations have been printed with initial capital letters or in all capitals.
The author and publisher have taken care in the preparation of this book, but make no expressed or implied warranty of any kind and assume no responsibility for errors or omissions.
No liability is assumed for incidental or consequential damages in connection with or arising out of the use of the information or programs contained herein.
The publisher offers excellent discounts on this book when ordered in quantity for bulk purchases or special sales, which may include electronic versions and/or custom covers and content particular to your business, training goals, marketing focus, and branding interests.
For more information, please contact: The United States Corporate and Government Sales (800) 382-3419 corpsales@pearsontechgroup_0_com For sales outside the United States, please contact: International Sales international@pearsoned_0_com Visit us on the Web: informit_0_com/aw Library of Congress Cataloging-in-Publication Data Stroustrup, Bjarne.
The Cplus_plus programming language / Bjarne Stroustrup_0_—Fourth edition.
Cplus_plus (Computer programming language) I.
QA76_0_73_0_C153 S77 2013 005_0_13'3—dc23 2013002159 Copyright © 2013 by Pearson Education, Inc.
All rights reserved.
Printed in the United States of America.
This publication is protected by copyright, and permission must be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise.
To obtain permission to use material from this work, please submit a written request to Pearson Education, Inc_0_, Permissions Department, One Lake Street, Upper Saddle River, New Jersey 07458, or you may fax your request to (201) 236-3290.
This book was typeset in Times and Helvetica by the author.
ISBN-13: 978-0-321-56384-2 ISBN-10: 0-321-56384-0 Te xt printed in the United States on recycled paper at Edwards Brothers Malloy in Ann Arbor, Michigan.
Second printing, June 2013 ptg10564057 Contents Contents iii Preface v Preface to the Fourth Edition _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Notes to the Reader _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
A Tour of Cplus_plus: The Basics _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
A Tour of Cplus_plus: Abstraction Mechanisms _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
A Tour of Cplus_plus: Containers and Algorithms _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
A Tour of Cplus_plus: Concurrency and Utilities _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Types and Declarations _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Pointers, Arrays, and References _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Structures, Unions, and Enumerations _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Select Operations _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Exception Handling _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Source Files and Programs _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Construction, Cleanup, Copy, and Move _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Special Operators _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Derived Classes _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Run-Time Type Information _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Generic Programming _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
A Matrix Design _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Standard Library Summary _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
STL Containers _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
STL Algorithms _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
STL Iterators _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Memory and Resources _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Regular Expressions _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Threads and Tasks _0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0__0_.
Wheeler Cplus_plus feels like a new.
That is, I can express my ideas more clearly, more simply, and more directly in Cplus_plus11 than I could in Cplus_plus98.
Furthermore, the resulting programs are better checked by the compiler and run faster.
In this book, I aim for completeness.
I describe every  feature and standard-library component that a professional programmer is likely to need.
Rationale: What kinds of problems is it designed to help solve.
What principles underlie the design.
What are the fundamental limitations.
Speciﬁcation: What is its deﬁnition.
The level of detail is chosen for the expert programmer; the aspiring  lawyer can follow the many references to the ISO standard.
Examples: How can it be used well by itself and in combination with other features.
What are the key techniques and idioms.
What are the implications for maintainability and performance.
The use of Cplus_plus has changed dramatically over the years and so has the  itself.
From the point of view of a programmer, most of the changes have been improvements.
The current ISO standard Cplus_plus (ISO/IEC 14882-2011, usually called Cplus_plus11) is simply a far better tool for writing quality software than were previous versions.
What kinds of programming styles and techniques does modern Cplus_plus support.
What  and standard-library features support those techniques.
What are the basic building blocks of elegant, correct, maintainable, and efﬁcient Cplus_plus code.
Those are the key questions answered by this book.
Many answers are not the same as you would ﬁnd with 1985, 1995, or 2005 vintage Cplus_plus: progress happens.
Cplus_plus is a general-purpose programming  emphasizing the design and use of type-rich, lightweight abstractions.
It is particularly suited for resource-constrained applications, such as those found in software infrastructures.
Cplus_plus rewards the programmer who takes the time to master ptg10564057 vi Preface techniques for writing quality code.
Cplus_plus is a  for someone who takes the task of programming seriously.
Our civilization depends critically on software; it had better be quality software.
There are billions of lines of Cplus_plus deployed.
This puts a premium on stability, so 1985 and 1995 Cplus_plus code still works and will continue to work for decades.
However, for all applications, you can do better with modern Cplus_plus; if you stick to older styles, you will be writing lower-quality and worse-performing code.
The emphasis on stability also implies that standards-conforming code you write today will still work a couple of decades from now.
All code in this book conforms to the 2011 ISO Cplus_plus standard.
This book is aimed at three audiences:.
Cplus_plus programmers who want to know what the latest ISO Cplus_plus standard has to offer,.
C programmers who wonder what Cplus_plus provides beyond C, and.
People with a background in application languages, such as Java, C#, Python, and Ruby, looking for something "closer to the machine" – something more ﬂexible, something offering better compile-time checking, or something offering better performance.
Naturally, these three groups are not disjoint – a professional software developer masters more than just one programming.
This book assumes that its readers are programmers.
If you ask, "What's a for-loop_0_" or "What's a compiler_0_" then this book is not (yet) for you; instead, I recommend my Programming: Principles and Practice Using Cplus_plus to get started with programming and Cplus_plus.
Furthermore, I – Karen Blixen, ptg10564057 1 Notes to the Reader Hurry Slowly (festina lente).
The Structure of This Book Introduction; Basic Facilities; Abstraction Mechanisms; The Standard Library; Examples and References.
The Design of Cplus_plus Programming Styles; Type Checking; C Compatibility; Language, Libraries, and Systems.
Learning Cplus_plus Programming in Cplus_plus; Suggestions for Cplus_plus Programmers; Suggestions for C Programmers; Suggestions for Java Programmers.
History Timeline; The Early Years; The 1998 Standard; The 2011 Standard; What is Cplus_plus Used for.
References 1_0_1 The Structure of This Book A pure tutorial sorts its topics so that no concept is used before it has been introduced; it must be read linearly starting with page one.
Conversely, a pure reference manual can be accessed starting at any point; it describes each topic succinctly with references (forward and backward) to related topics.
A pure tutorial can in principle be read without prerequisites – it carefully describes all.
A pure reference can be used only by someone familiar with all fundamental concepts and techniques.
This book combines aspects of both.
If you know most concepts and techniques, you can access it on a per-chapter or even on a per-section basis.
If not, you can start at the beginning, but try not to get bogged down in details.
Use the index and the cross-references.
The book is heavily cross-referenced both to itself and to the ISO Cplus_plus standard.
Experienced programmers can read the (relatively) quick "tour" of Cplus_plus to gain the overview needed to use the book as a reference.
This book consists of four parts: Part I Introduction: Chapter 1 (this chapter) is a guide to this book and provides a bit of Cplus_plus background.
Chapters 2-5 give a quick introduction to the Cplus_plus language and its standard library.
Part II Basic Facilities: Chapters 6-15 describe Cplus_plus's built-in types and the basic facilities for constructing programs out of them.
Part III Abstraction Mechanisms: Chapters 16-29 describe Cplus_plus's abstraction mechanisms and their use for object-oriented and generic programming.
Part IV Chapters 30-44 provide an overview of the standard library and a discussion of compatibility issues.
You are encouraged to skim through it, read what appears interesting, and return to it after reading other parts of the book.
Please do not feel obliged to read it all carefully before proceeding.
The following chapters provide an overview of the major concepts and features of the Cplus_plus programming language and its standard library: Chapter 2 A Tour of Cplus_plus: The Basics describes Cplus_plus's model of memory, computation, and error handling.
Chapter 3 A Tour of Cplus_plus: Abstraction Mechanisms presents the language features supporting data abstraction, object-oriented programming, and generic programming.
Chapter 4 A Tour of Cplus_plus: Containers and Algorithms introduces strings, simple I/O, containers, and algorithms as provided by the standard library.
Chapter 5 A Tour of Cplus_plus: Concurrency and Utilities outlines the standard-library utilities related to resource management, concurrency, mathematical computation, regular expressions, and more.
This whirlwind tour of Cplus_plus's facilities aims to give the reader a taste of what Cplus_plus offers.
In particular, it should convince readers that Cplus_plus has come a long way since the ﬁrst, second, and third editions of this book.
It introduces the notions of type, object, scope, and storage.
It presents the fundamentals of computation: expressions, statements, and functions.
Modularity – as supported by namespaces, source ﬁles, and exception handling – is also discussed: Chapter 6 Types and Declarations: Fundamental types, naming, scopes, initialization, simple type deduction, object lifetimes, and type aliases ptg10564057 Section 1_0_1_0_2 Basic Facilities 5 Chapter 7 Pointers, Arrays, and References Chapter 8 Structures, Unions,  Enumerations Chapter 9 Statements: Declarations as statements, selection statements (if  switch), iteration statements (for, while,  do), goto,  comments Chapter 10 Expressions: A desk calculator example, survey of operators, constant expressions,  implicit type conversion.
Chapter 11 Select Operations: Logical operators, the conditional expression, increment decrement, free store (new  delete), {}-lists, lambda expressions,  explicit Chapter 12 Functions: Function declarations  deﬁnitions, inline functions, constexpr functions, argument passing, overloaded functions, pre-  postconditions, pointers to functions,  macros Chapter 13 Exception Handling: Styles of error handling, exception guarantees, resource management, enforcing invariants, throw  catch, a vector implementation Chapter 14 Namespaces: namespace, modularization  interface, composition using namespaces Chapter 15 Source Files  Programs: Separate compilation, linkage, using header ﬁles, program start  termination I assume that you are familiar with most of the programming concepts used in Part I.
For example, I explain the Cplus_plus facilities for expressing recursion  iteration, but I do not go into technical details or spend much time explaining how these concepts are useful.
The exception to this rule is exceptions.
Many programmers lack experience with exceptions or got their experience from languages (such as Java) where resource management  exception handling are not integrated.
Consequently, the chapter on exception handling (Chapter 13) presents the basic philosophy of Cplus_plus exception handling  resource management.
It goes into some detail about strategy with a focus on the "Resource Acquisition Is Initialization" technique (RAII).
The chapters fall into three rough categories: classes, class hierarchies,  templates.
The ﬁrst four chapters concentrate of the classes themselves: Chapter 16 Classes: The notion of a user-deﬁned type, a class, is the foundation of all Cplus_plus abstraction mechanisms.
Chapter 17 Construction, Cleanup, Copy,  Move shows how a programmer can deﬁne the meaning of creation  initialization of objects of a class.
Further, the meaning of copy, move,  destruction can be speciﬁed.
Chapter 18 Operator Overloading presents the rules for giving meaning to operators for user-deﬁned types with an emphasis on conventional arithmetic  logical operators, such as +, ∗,  &.
Chapter 19 Special Operators discusses the use of user-deﬁned operator for non-arithmetic purposes, such as [] for subscripting, () for function objects,  −> for "smart ptg10564057 6 Notes to the Reader Chapter 1 Classes can be organized into hierarchies: Chapter 20 Derived Classes presents the basic language facilities for building hierarchies out of classes  the fundamental ways of using them.
We can provide complete separation between an interface (an abstract class)  its implementations (derived classes); the connection between them is provided by virtual functions.
The Cplus_plus model for access control (public, protected,  private) is presented.
Chapter 21 Class  discusses ways of using class hierarchies effectively.
It also presents the notion of multiple inheritance, that is, a class having more than one direct base class.
Chapter 22 Run-Time Type Information presents ways to navigate class hierarchies using data stored in objects.
We can use dynamic_cast to inquire whether an object of a base class was deﬁned as an object of a derived class  use the typeid to gain minimal information from an object (such as the name of its class).
Many of the most ﬂexible, efﬁcient,  useful abstractions involve the parameterization of types (classes)  algorithms (functions) with other types  algorithms: Chapter 23 Templates presents the basic principles behind templates  their use.
Class templates, function templates,  template aliases are presented.
Chapter 24 Generic Programming introduces the basic techniques for designing generic programs.
The technique of lifting an abstract algorithm from a number of concrete code examples is central, as is the notion of concepts specifying a generic algorithm's requirements on its arguments.
Chapter 25 Specialization describes how templates are used to generate classes  functions, specializations, giv en a set of template arguments.
Chapter 26 Instantiation focuses on the rules for name binding.
Chapter 27 Templates   explains how templates  class hierarchies can be used in combination.
Chapter 28 Metaprogramming explores how templates can be used to generate programs.
Templates provide a Turing-complete mechanism for generating code.
Chapter 29 A Matrix Design gives a longish example to show how language features can be used in combination to solve a complex design problem: the design of an Ndimensional matrix with near-arbitrary element types.
The language features supporting abstraction techniques are described in the context of those techniques.
The presentation technique in Part III differs from that of Part II in that I don't assume that the reader knows the techniques described.
In particular, they are meant to be read in any order and can be used as a user-level manual for the library components: Chapter 30 Standard-Library Overview gives an overview of the standard library, lists the standard-library headers, and presents language support and diagnostics support, such as exception and system_error.
Chapter 31 STL Containers presents the containers from the iterators, containers, and algorithms framework (called the STL), including vector, map, and unordered_set.
Chapter 33 STL Iterators presents iterators and other utilities from the STL, including reverse_iterator, move_iterator, and function.
Chapter 34 Memory and Resources presents utility components related to memory and resource management, such as array, bitset, pair, tuple, unique_ptr, shared_ptr, allocators, and the garbage collector interface.
Chapter 35 Utilities presents minor utility components, such as time utilities, type traits, and various type functions.
Chapter 36 Strings documents the string library, including the character traits that are the basis for the use of different character sets.
Chapter 37 Regular Expressions describes the regular expression syntax and the various ways of using it for string matching, including regex_match() for matching a for simple replacement, and regex_iterator for general traversal of a stream of characters.
Chapter 38 I/O Streams documents the stream I/O library.
It describes formatted and unformatted input and output, error handling, and buffering.
Chapter 39 Locales describes class locale and its various facets that provide support for the handling of cultural differences in character sets, formatting of numeric values, formatting of date and time, and more.
Chapter 40 Numerics describes facilities for numerical computation (such as complex, valarray, random numbers, and generalized numerical algorithms).
Chapter 41 Concurrency presents the Cplus_plus basic memory model and the facilities offered for concurrent programming without locks.
Chapter 42 Threads and Tasks presents the classes providing threads-and-locks-style concurrent programming (such as thread, timed_mutex, lock_guard, and try_lock()) and the support for task-based concurrency (such as future and async()).
Chapter 43 The C Standard Library documents the C standard library (including printf() and clock()) as incorporated into the Cplus_plus standard library.
Chapter 44 Compatibility discusses the relation between C and Cplus_plus and between Standard Cplus_plus (also called ISO Cplus_plus) and the versions of Cplus_plus that preceded it.
Consequently, I avoid clever or harder-to-understand algorithms.
A trivial algorithm is typically better suited to illustrate an aspect of the language deﬁnition or a point about program structure.
For example, I use a Shell sort where, in real code, a quicksort would be better.
Often, reimplementation with a more suitable algorithm is an exercise.
In real code, a call of a library function is typically more appropriate than the code used here to illustrate language features.
Te xtbook examples necessarily give a warped view of software development.
By clarifying and simplifying the examples, the complexities that arise from scale disappear.
I see no substitute for writing realistically sized programs in order to get an impression of what programming and a ptg10564057 8 Notes to the Reader Chapter 1 programming language are really like.
This book concentrates on the language features and the standard-library facilities.
These are the basic techniques from which every program is composed.
The rules and techniques for such composition are emphasized.
The selection of examples reﬂects my background in compilers, foundation libraries, and simulations.
The emphasis reﬂects my interest in systems programming.
Examples are simpliﬁed versions of what is found in real code.
The simpliﬁcation is necessary to keep programming language and design points from getting lost in details.
My ideal is the shortest and clearest example that illustrates a design principle, a programming technique, a language construct, or a library feature.
There are no "cute" examples without counterparts in real code.
For purely language-technical examples, I use variables named x and y, types called A and B, and functions called f() and g().
Where possible, the Cplus_plus language and library features are presented in the context of their use rather than in the dry manner of a manual.
The language features presented and the detail in which they are described roughly reﬂect my view of what is needed for effective use of Cplus_plus.
The purpose is to give you an idea of how a feature can be used, often in combination with other features.
An understanding of every language-technical detail of a language feature or library component is neither necessary nor sufﬁcient for writing good programs.
In fact, an obsession with understanding ev ery little detail is a prescription for awful – overelaborate and overly clever – code.
What is needed is an understanding of design and programming techniques together with an appreciation of application domains.
I assume that you have access to online information sources.
The ﬁnal arbiter of language and standard-library rules is the ISO Cplus_plus standard [Cplus_plus,2011].
References to parts of this book are of the form 2_0_3_0_4 (Chapter 2, section 3, subsection 4) and iso_0_5_0_3_0_1 (ISO Cplus_plus standard, 5_0_3_0_1).
Italics are used sparingly for emphasis (e_0_g_0_, "a string literal is not acceptable"), for ﬁrst occurrences of important concepts (e_0_g_0_, polymorphism), and for comments in code examples.
To sav e a few trees and to simplify additions, the hundreds of exercises for this book have been moved to the Web.
The language and library used in this book are "pure Cplus_plus" as deﬁned by the Cplus_plus standard [Cplus_plus,2011].
Therefore, the examples should run on every up-to-date Cplus_plus implementation.
The major program fragments in this book were tried using several Cplus_plus implementations.
Examples using  only recently adopted into Cplus_plus didn't compile on every implementation.
However, I see no point in mentioning which implementations failed to compile which examples.
Such information would soon be out of date because implementers are working hard to ensure that their implementations correctly accept every Cplus_plus feature.
See Chapter 44 for suggestions on how to cope with older Cplus_plus compilers and with code written for C compilers.
I use Cplus_plus11  freely wherever I  ﬁnd them most appropriate.
For example, I prefer {}-style initializers and using for type aliases.
In places, that usage may startle "old timers_0_" Howev er, being startled is often a good way to start reviewing material.
On the other hand, I don't use just because they are ;  ideal is the most elegant expression of the fundamental ideas – and that may very well be using something that has been in Cplus_plus or even in C for ages.
Obviously, if you have to use a pre-Cplus_plus11 compiler (say, because some of your customers have not yet upgraded to the current standard), you have to refrain from using novel.
However, please don't assume that "the old ways" are better or simpler just because they are old and familiar.
In that, a programming language performs two related tasks: it provides a vehicle for the programmer to specify actions to be executed by the machine, and it provides a set of concepts for the programmer to use when thinking about what can be done.
The ﬁrst purpose ideally requires a language that is "close to the machine" so that all important aspects of a machine are handled simply and efﬁciently in a way that is reasonably obvious to the programmer.
The C language was primarily designed with this in so that the concepts of a solution can be expressed directly and concisely.
The facilities added to C to create Cplus_plus, such as function argument checking, const, classes, constructors and destructors, exceptions, and templates, were primarily designed with this in mind.
Thus, Cplus_plus is based on the idea of providing both.
This was initially achieved by applying ideas from Simula to C.
Over the years, further application of these simple ideals resulted in a far more general, efﬁcient, and ﬂexible set of facilities.
The result supports a synthesis of programming styles that can be simultaneously efﬁcient and elegant.
The design of Cplus_plus has focused on programming techniques dealing with fundamental notions such as memory, mutability, abstraction, resource management, expression of algorithms, error handling, and modularity.
Those are the most important concerns of a systems programmer and more generally of programmers of resource-constrained and high-performance systems.
By deﬁning libraries of classes, class hierarchies, and templates, you can write Cplus_plus programs at a much higher level than the one presented in this book.
For example, Cplus_plus is widely used in ﬁnancial systems, for game development, and for scientiﬁc computation (1_0_4_0_5).
For high-level applications programming to be effective and convenient, we need libraries.
Using just the bare language  makes almost all programming quite painful.
That's true for every general-purpose language.
Conversely, giv en suitable libraries just about any programming task can be pleasant.
My standard introduction of Cplus_plus used to start:.
Cplus_plus is a general-purpose programming language with a bias toward systems programming.
This is still true.
What has changed over the years is an increase in the importance, power, and ﬂexibility of Cplus_plus's abstraction mechanisms:.
Cplus_plus is a general-purpose programming language pro viding a direct and efﬁcient model of hardware combined with facilities for deﬁning lightweight abstractions.
Cplus_plus is a language for developing and using elegant and efﬁcient abstractions.
By general-purpose programming language I mean a language designed to support a wide variety of uses.
Cplus_plus has indeed been used for an incredible variety of uses (from microcontrollers to huge distributed commercial applications), but the key point is that Cplus_plus is not deliberately specialized for any giv en application area.
No language is ideal for every application and every programmer, but the ideal for Cplus_plus is to support the widest possible range of application areas well.
In particular, the implementation of software infrastructure (e_0_g_0_, device drivers, communications stacks, virtual machines, operating systems, operations systems, programming environments, and foundation libraries) is mostly systems programming.
The importance of the "bias toward systems programming" qualiﬁcation in long-standing characterization of Cplus_plus is that Cplus_plus has not been simpliﬁed (compromised) by ejecting the facilities aimed at the expert-level use of hardware and systems resources in the hope of making it more suitable for other application areas.
Of course, you can also program in ways that completely hide hardware, use expensive abstractions (e_0_g_0_, every object on the free store and every operation a virtual function), use inelegant styles (e_0_g_0_, overabstraction), or use essentially no abstractions ("gloriﬁed assembly code").
However, many languages can do that, so those are not distinguishing characteristics of Cplus_plus.
The Design and Evolution of Cplus_plus book [Stroustrup,1994] (known as D&E) outlines the ideas and design aims of Cplus_plus in greater detail, but two principles should be noted:.
Leave no room for a lower-level language below Cplus_plus (except for assembly code in rare cases).
If you can write more efﬁcient code in a lower-level language then that language will most likely become the systems programming language of choice.
If programmers can hand-write reasonable code to simulate a language feature or a fundamental abstraction and provide even slightly better performance, someone will do so, and many will imitate.
Therefore, a language feature and a fundamental abstraction must be designed not to waste a single byte or a single processor cycle compared to equivalent alternatives.
This is known as the zero-overhead principle.
These are Draconian principles, but essential in some (but obviously not all) contexts.
In particular, the zero-overhead principle repeatedly led Cplus_plus to simpler, more elegant, and more powerful facilities than were ﬁrst envisioned.
The STL is an example (4_0_1_0_1, 4_0_4, 4_0_5, Chapter 31, Chapter 32, Chapter 33).
These principles have been essential in the effort to raise the level of programming.
Please don't look at an individual language feature as a solution, but as one building brick from a varied set which can be combined to express solutions.
The general ideals for design and programming can be expressed simply:.
Express ideas directly in code.
Express independent ideas independently in code.
Represent relationships among ideas directly in code.
Combine ideas expressed in code freely – where and only where combinations make sense.
Express simple ideas simply.
These are ideals shared by many people, but languages designed to support them can differ dramatically.
A fundamental reason for that is that a language embodies a set of engineering tradeoffs reﬂecting differing needs, tastes, and histories of various individuals and communities.
Cplus_plus's answers to the general design challenges were shaped by its origins in systems programming (going back to C and BCPL [Richards,1980]), its aim to address issues of program complexity through abstraction (going back to Simula), and its history.
Generic programming However, the emphasis is on the support of effective combinations of those.
The best (most maintainable, most readable, smallest, fastest, etc_0_) solution to most nontrivial problems tends to be one that combines aspects of these styles.
As is usual with important terms in the computing world, a wide variety of deﬁnitions of these terms are popular in various parts of the computing industry and academia.
For example, what I refer to as a "programming style," others call a "programming technique" or a "paradigm_0_" I prefer to use "programming technique" for something more limited and language-speciﬁc.
I feel uncomfortable with the word "paradigm" as pretentious and (from Kuhn's original deﬁnition) having implied claims of exclusivity.
My ideal is language facilities that can be used elegantly in combination to support a continuum of programming styles and a wide variety of programming techniques.
Procedural programming: This is programming focused on processing and the design of suitable data structures.
It is what C was designed to support (and Algol, and Fortran, as well as many other languages).
Cplus_plus's support comes in the form of the built-in types, operators, statements, functions, structs, unions, etc.
With minor exceptions, C is a subset of Cplus_plus.
Compared to C, Cplus_plus provides further support for procedural programming in the form of many additional language constructs and a stricter, more ﬂexible, and more supportiv e type system.
Data abstraction: This is programming focused on the design of interfaces, hiding implementation details in general and representations in particular.
Cplus_plus supports concrete and abstract classes.
The facilities for deﬁning classes with private implementation details, constructors and destructors, and associated operations directly support this.
The notion of an abstract class provides direct support for complete data hiding.
Object-oriented programming: This is programming focused on the design, implementation, and use of class.
In addition to allowing the deﬁnition lattices of classes, Cplus_plus provides a variety of features for navigating class lattices and for simplifying the deﬁnition of a class out of existing ones.
Class  provide run-time polymorphism (20_0_3_0_2, 21_0_2) and encapsulation (20_0_4, 20_0_5).
Generic programming: This is programming focused on the design, implementation, and use of general algorithms.
Here, "general" means that an algorithm can be designed to accept a wide variety of types as long as they meet the algorithm's requirements on its arguments.
The template is Cplus_plus's main support for generic programming.
Templates provide (compiletime) parametric polymorphism.
Just about anything that increases the ﬂexibility or efﬁciency of classes improves the support of all of those styles.
Thus, Cplus_plus could be (and has been) called class oriented.
Each of these styles of design and programming has contributed to the synthesis that is Cplus_plus.
Focusing exclusively on one of these styles is a mistake: except for toy examples, doing so leads to wasted development effort and suboptimal (inﬂexible, verbose, poorly performing, unmaintainable, etc_0_) code.
The former misses the fact that all the styles mentioned have contributed something signiﬁcant to the synthesis; the latter denies the validity of the synthesis.
The styles mentioned are not distinct alternatives: each contributes techniques to a more expressive and effective style of programming, and Cplus_plus provides direct language support for their use in combination.
From its inception, the design of Cplus_plus aimed at a synthesis of programming and design styles.
Even the earliest published account of Cplus_plus [Stroustrup,1982] presents examples that use these different styles in combination and presents language features aimed at supporting such combinations:.
Classes support all of the mentioned styles; all rely on the user representing ideas as userdeﬁned types or objects of user-deﬁned types.
Public/private access control supports data abstraction and object-oriented programming by making a clear distinction between interface and implementation.
Member functions, constructors, destructors, and user-deﬁned assignment provide a clean functional interface to objects as needed by data abstraction and object-oriented programming.
They also provide a uniform notation as needed for generic programming.
More general overloading had to wait until 1984 and uniform initialization until 2010.
Function declarations provide speciﬁc statically checked interfaces to member functions as well as freestanding functions, so they support all of the mentioned styles.
At the time, C lacked "function prototypes" but Simula had function declarations as well as member functions.
Generic functions and parameterized types (generated from functions and classes using macros) support generic programming.
Templates had to wait until 1988.
Base and derived classes provide the foundation for object-oriented programming and some forms of data abstraction.
Virtual functions had to wait until 1983.
Inlining made the use of these facilities affordable in systems programming and for building run-time and space efﬁcient libraries.
These early features are general abstraction mechanisms, rather than support for disjoint programming styles.
Today's Cplus_plus provides much better support for design and programming based on lightweight abstraction, but the aim of elegant and efﬁcient code was there from the very beginning.
The developments since 1981 provide much better support for the synthesis of the programming styles ("paradigms") originally considered and signiﬁcantly improve their integration.
The fundamental object in Cplus_plus has identity; that is, it is located in a speciﬁc location in memory and can be distinguished from other objects with (potentially) the same value by comparing addresses.
Expressions denoting such objects are called lvalues (6_0_4).
However, even from the earliest days of Cplus_plus's ancestors [Barron,1963] there have also been objects without identity (objects for which an address cannot be safely stored for later use).
In Cplus_plus11, this notion of rvalue has been developed into a notion of a value that can be moved around cheaply (3_0_3_0_2, 6_0_4_0_1, 7_0_7_0_2).
Such objects are the basis of techniques that resemble what is found in functional programming (where the notion of objects with identity is viewed with horror).
This nicely complements the techniques and language features (e_0_g_0_, lambda expressions) developed primarily for [Stroustrup,1984] B.
Stroustrup: Operator Overloading in Cplus_plus.
IFIP WG2_0_4 Conference on System Implementation Languages: Experience & Assessment.
Stroustrup: An Extensible I/O Facility for Cplus_plus.
Summer 1985 USENIX Conference.
Stroustrup: Multiple Inheritance for Cplus_plus.
EUUG Spring Conference.
Stroustrup and J.
Shopiro: A Set of C Classes for Co-Routine Style Programming.
USENIX Cplus_plus Conference.
Santa Fe, New Mexico.
Stroustrup: Parameterized Types for Cplus_plus.
USENIX Cplus_plus Conference, Denver.
Stroustrup: The Cplus_plus Programming Language (Second Edition).
Stroustrup: A History of Cplus_plus: 1979-1991.
ACM History of Programming Languages conference (HOPL-2).
ACM Sigplan Notices.
Stroustrup: The Design and Evolution of Cplus_plus.
Stroustrup: The Cplus_plus Programming Language, Third Edition.
Hardcover ("Special") Edition.
Stroustrup: C and Cplus_plus: Siblings, C and Cplus_plus: A Case for Compatibility, and C and Cplus_plus: Case Studies in Compatibility.
The C/Cplus_plus Users Journal.
Stroustrup: Evolving a language in and for the real world: Cplus_plus 1991-2006.
Stroustrup: Programming – Principles and Practice Using Cplus_plus.
Stroustrup: The Cplus_plus11 FAQ.
Stroustrup: The Cplus_plus0x "Remove Concepts" Decision.
Stroustrup and A.
Sutton: A Concept Design for the STL.
Stroustrup: Software Development for Infrastructure.
Sutton and B.
Stroustrup: Design of Concept Libraries for Cplus_plus.
SLE 2011 (International Conference on Software Language Engineering).
Tanenbaum: Modern Operating Systems, Third Edition.
Upper Saddle River, New Jersey.
Research Version, Tenth Edition.
AT&T Bell Laboratories, Murray Hill, New Jersey.
Josuttis: Cplus_plus Templates: The Complete Guide.
Veldhuizen: Cplus_plus Templates are Turing Complete.
Indiana University Computer Science Technical.
ACM Transactions on Mathematical Software, Vol.
Manning Publications Co.
Wilson and Paul Lu (editors): Parallel Programming Using Cplus_plus.
The MIT Press.
Woodward and S.
Bond: Algol 68-R Users Guide.
Her Majesty's Stationery Ofﬁce.
The Basics Hello, World_0_; Types, Variables, and Arithmetic; Constants; Tests and Loops; Pointers, Arrays, and Loops.
User-Deﬁned Types Structures; Classes; Enumerations.
Modularity Separate Compilation; Namespaces; Error Handling.
Advice 2_0_1 Introduction The aim of this chapter and the next three is to give you an idea of what Cplus_plus is, without going into a lot of details.
This chapter informally presents the notation of Cplus_plus, Cplus_plus's model of memory and computation, and the basic mechanisms for organizing code into a program.
These are the language facilities supporting the styles most often seen in C and sometimes called procedural programming.
Chapter 3 follows up by presenting Cplus_plus's abstraction mechanisms.
Chapter 4 and Chapter 5 give examples of standard-library facilities.
The assumption is that you have programmed before.
If not, please consider reading a textbook, such as Programming: Principles and Practice Using Cplus_plus [Stroustrup,2009], before continuing here.
Even if you have programmed before, the language you used or the applications you.
There is only one nullptr shared by all pointer types: double∗  = nullptr; Link<>∗  = nullptr; // pointer to a Link to a int  = nullptr; // error : nullptr is a pointer not an integer It is often wise to check that a pointer argument that is supposed to point to something, actually points to something: //  the number of occurrences of  in [].
The deﬁnition of count_x() assumes that the char∗ is a C-style string, that is, that the pointer points to a zero-terminated array of char.
In older code, 0 or NULL is typically used instead of nullptr (7_0_2_0_2).
However, using nullptr eliminates potential confusion between integers (such as 0 or NULL) and pointers (such as nullptr).
Cplus_plus's set of built-in types and operations is rich, but deliberately low-level.
They directly and efﬁciently reﬂect the capabilities of conventional computer hardware.
However, they don't provide the programmer with high-level facilities to conveniently write advanced applications.
Instead, Cplus_plus augments the built-in types and operations with a sophisticated set of abstraction mechanisms out of which programmers can build such highlevel facilities.
The Cplus_plus abstraction mechanisms are primarily designed to let programmers design and implement their own types, with suitable representations and operations, and for programmers to simply and elegantly use such types.
Types built out of the built-in types using Cplus_plus's abstraction mechanisms are called user-deﬁned types.
They are referred to as classes and enumerations.
Most of this book is devoted to the design, implementation, and use of user-deﬁned types.
The rest of this chapter presents the simplest and most fundamental facilities for that.
Chapter 3 is a more complete description of the abstraction mechanisms and the programming styles they support.
Chapter 4 and Chapter 5 present an overview of the standard library, and since the standard library mainly consists of user-deﬁned types, they provide examples of what can be built using the language facilities and programming techniques presented in Chapter 2 and Chapter 3.
A variable of  Vector can be deﬁned like this: Vector ; However, by itself that is not of much use because 's  pointer doesn't point to anything.
To be useful, we must give  some elements to point to.
For example, we can construct a Vector like this:.
The & in Vector& indicates that we pass  by non-const reference (2_0_2_0_5, 7_0_7); that way, vector_init() can modify the vector passed to it.
The new  allocates memory from an area called the free store (also known as dynamic memory and heap; 11_0_2).
In particular, a user of Vector has to know every detail of Vector's representation.
The rest of this chapter and the next gradually improve Vector as an example of language features and techniques.
Chapter 4 presents the standard-library vector, which contains many nice improvements, and Chapter 31 presents the complete vector in the context of other standard-library facilities.
I use vector and other standard-library components as examples.
Don't reinvent standard-library components, such as vector and string; use them.
However, a tighter connection between the representation and the operations is needed for a user-deﬁned  to have all the properties expected of a "real _0_" In particular, we often want to keep the representation inaccessible to users, so as to ease use, guarantee consistent use of the data, and allow us to later improve the representation.
To do that we have to distinguish between the interface to a  (to be used by all) and its implementation (which has access to the otherwise inaccessible data).
The language mechanism for that is called a class.
A class is deﬁned to have a set of members, which can be data, function, or  members.
The interface is deﬁned by the public members of a class, and private members are accessible only through that interface.
For example: ptg10564057 Section 2_0_3_0_2 Classes 49 class Vector {.
The number of elements (6 in the example) can vary from Vector object to Vector object, and a Vector object can have a different number of elements at different times (3_0_2_0_1_0_3).
However, the Vector object itself is always the same size.
This is the basic technique for handling varying amounts of information in Cplus_plus: a ﬁxed-size handle referring to a variable amount of data "elsewhere" (e_0_g_0_, on the free store allocated by ; 11_0_2).
Here, the representation of a Vector (the members  and ) is accessible only through the example from 2_0_3_0_1 simpliﬁes to:.
So, the constructor, Vector(), replaces vector_init() from 2_0_3_0_1.
Unlike an ordinary function, a constructor is guaranteed to be used to initialize objects of its class.
Thus, deﬁning a constructor eliminates the problem of uninitialized variables for a class.
In particular, it states that it needs an integer to do that.
That integer is used as the number of elements.
The constructor initializes the Vector members using a member initializer list: :{ [s]}, {s} That is, we ﬁrst initialize  with a pointer to s elements of   obtained from the free store.
Then, we initialize  to s.
Access to elements is provided by a subscript function, called [].
It returns a reference to the appropriate element (a &).
The size() function is supplied to give users the number of elements.
Obviously, error handling is completely missing, but we'll return to that in 2_0_4_0_3.
Similarly, we did not provide a mechanism to "give back" the array of doubles acquired by ; 3_0_2_0_1_0_2 shows how to use a destructor to elegantly do that.
Note that enumerators (e_0_g_0_, red) are in the scope of their enum class, so that they can be used repeatedly in different enum classes without confusion.
For example, ::red is 's red which is different from ::red.
Enumerations are used to represent small sets of integer values.
They are used to make code more readable and less error-prone than it would have been had the symbolic (and mnemonic) enumerator names not been used.
The class after the enum speciﬁes that an enumeration is strongly typed and that its enumerators are scoped.
Being separate types, enum classes help prevent accidental misuses of constants.
In particular, we cannot mix  and  values: = red; // error : which red.
By default, an enum class has only assignment, initialization,  comparisons (e_0__0_, ==  <; 2_0_2_0_2) deﬁned.
However, an enumeration is a user-deﬁned  so we can deﬁne operators for it: ptg10564057 Section 2_0_3_0_3 Enumerations 51.
Cplus_plus also offers a less strongly typed "plain" enum (8_0_4_0_2).
The key to managing this is to clearly deﬁne the interactions among those parts.
The ﬁrst  most important step is to distinguish between the interface to a part its implementation.
At the language level, Cplus_plus represents interfaces by declarations.
A declaration speciﬁes all that's needed to use a function or a.
For example: sqrt(); // the square root function takes a   returns a.
We must deﬁne Vector's functions, but not sqrt() because it is part of the standard library.
Howev er, that makes no real difference: a library is simply some "other code we happen to use" written with the same language facilities as we use.
The deﬁnitions of those types  functions are in separate source ﬁles  compiled separately.
This can be used to organize a program into a set of semi-independent code fragments.
Such separation can be used to minimize compilation times  to strictly enforce separation of logically distinct parts of a program (thus minimizing the chance of errors).
A library is often a separately compiled code fragments (e_0__0_, functions).
Typically, we place the declarations that specify the interface to a module in a ﬁle with a name indicating its intended use.
The code in user_0_cpp  Vector_0_cpp shares the Vector interface information presented in Vector_0_h, but the two ﬁles are otherwise independent  can be separately compiled.
Graphically, the program fragments can be represented like this: Vector interface deﬁne Vector Vector_0_h: user_0_cpp: Vector_0_cpp: Strictly speaking, using separate compilation isn' a language issue; it is an issue of how best to take advantage of a particular language implementation.
However, it is of great practical importance.
The best approach is to maximize modularity, represent that modularity logically through language features,  then exploit the modularity physically through ﬁles for effective separate compilation (Chapter 14, Chapter 15).
For example, I might want to experiment with my own complex number type (3_0_2_0_1_0_1, 18_0_3, 40_0_4):.
By putting my code into the namespace My_code, I make sure that my names do not conﬂict with the standard-library names in namespace std (4_0_1_0_2).
The precaution is wise, because the standard library does provide support for complex arithmetic (3_0_2_0_1_0_1, 40_0_4).
The simplest way to access a name in another namespace is to qualify it with the namespace name (e_0__0_, std::  My_code::main).
The " main()" is deﬁned in the global namespace, that is, not local to a deﬁned namespace, class, or function.
To gain access to names in the standard-library namespace, we can use a using-directive (14_0_2_0_3): using namespace std; Namespaces are primarily used to organize larger program components, such as libraries.
They simplify the composition of a program out of separately developed parts.
However, Cplus_plus provides a few features to help.
The major tool is the type system itself.
Instead of painstakingly building up our applications from the built-in types (e_0__0_, char, int,  )  statements (e_0__0_, if, while,  for), we build more types that are appropriate for our applications (e_0__0_, string, map,  regex)  algorithms (e_0__0_, sort(), ﬁnd_if(),  draw_all()).
Such higher level constructs simplify our programming, limit our opportunities for mistakes (e_0__0_, you are unlikely to try to apply a tree traversal to a dialog box), ptg10564057 Section 2_0_4_0_3 Error Handling 55 and increase the compiler's chances of catching such errors.
The majority of Cplus_plus constructs are dedicated to the design and implementation of elegant and efﬁcient abstractions (e_0_g_0_, user-deﬁned types and algorithms using them).
One effect of this modularity and abstraction (in particular, the use of libraries) is that the point where a run-time error can be detected is separated from the point where it can be handled.
As programs grow, and especially when libraries are used extensively, standards for handling errors become important.
What ought to be done when we try to access an element that is out of range for the vector from 2_0_3_0_2.
The writer of Vector doesn't know what the user would like to hav e done in this case (the writer of Vector typically doesn't even know in which program the vector will be running).
The user of Vector cannot consistently detect the problem (if the user could, the out-of-range access wouldn't happen in the ﬁrst place).
The solution is for the Vector implementer to detect the attempted out-of-range access and then tell the user about it.
The user can then take appropriate action.
For example, Vector::operator[]() can detect an attempted out-of-range access and throw an out_of_range exception:.
Therefore, the catch-clause providing a handler for out_of_range will be entered.
The out_of_range type is deﬁned in the standard library and is in fact used by some standard-library container access functions.
Use of the exception-handling mechanisms can make error handling simpler, more systematic, and more readable.
See Chapter 13 for further discussion, details, and examples.
Had we formally speciﬁed Vector's subscript operator, we would have said something like "the index must be in the [0:()) range," and that was in fact what we tested in our operator[]().
Whenever we deﬁne a function, we should consider what its preconditions are and if feasible test them (see 12_0_4, 13_0_4).
However, operator[]() operates on objects of type Vector and nothing it does makes any sense unless the members of Vector have "reasonable" values.
In particular, we did say "elem points to an array of sz doubles" but we only said that in a comment.
Such a statement of what is assumed to be true for a class is called a class invariant, or simply an invariant.
It is the job of a constructor to establish the invariant for its class (so that the member functions can rely on it) and for the member functions to make sure that the invariant holds when they exit.
Unfortunately, our Vector constructor only partially did its job.
It properly initialized the Vector members, but it failed to check that the arguments passed to it made sense.
Consider: Vector v(−27); This is likely to cause chaos.
You  deﬁne your own classes to be used as exceptions and have them carry arbitrary information from a point where an error is detected to a point where it  be handled (13_0_5).
Often, a function has no way of completing its assigned task after an exception is thrown.
Then, "handling" an exception simply means doing some minimal local cleanup and rethrowing the exception (13_0_5_0_2_0_1).
The notion of invariants underlies Cplus_plus' notions of resource management supported by constructors (2_0_3_0_2) and destructors (3_0_2_0_1_0_2, 5_0_2).
If an error  be found at compile time, it is usually preferable to do so.
That' what much of the type system and the facilities for specifying the interfaces to user-deﬁned types are for.
Howev er, we  also perform simple checks on other properties that are known at compile time and report failures as compiler error messages.
For example: (4<=sizeof(int), "integers are too small"); // check integer This will write integers are too small  4<=sizeof(int) does not hold, that is,  an int on this system does not have at least 4 bytes.
We call such statements of expectations assertions.
The  mechanism  be used for anything that  be expressed in terms of constant expressions (2_0_2_0_3, 10_0_4).
In general, (A,S) prints S as a compiler error message  A is not true.
The most important uses of  come when we make assertions about types used as parameters in generic programming (5_0_4_0_2, 24_0_3).
For runtime-checked assertions, see 13_0_4.
Those are the parts of Cplus_plus that underlie all programming techniques and styles supported by Cplus_plus.
Experienced  and Cplus_plus programmers, please note that this foundation does not closely correspond to the  or Cplus_plus98 subsets of Cplus_plus (that is, Cplus_plus11).
All will become clear in time; 2_0_1.
Classes Concrete Types; Abstract Types; Virtual Functions; Class Hierarchies.
Copy and Move Copying Containers; Moving Containers; Resource Management; Suppressing Operations.
Templates Parameterized Types; Function Templates; Function Objects; Variadic Templates; Aliases.
Advice 3_0_1 Introduction This chapter aims to give you an idea of Cplus_plus' support for abstraction and resource management without going into a lot of detail.
It informally presents ways of deﬁning and using new types (user-deﬁned types).
In particular, it presents the basic properties, implementation techniques, and language facilities used for concrete classes, abstract classes, and class hierarchies.
Templates are introduced as a mechanism for parameterizing types and algorithms with (other) types and algorithms.
Computations on user-deﬁned and built-in types are represented as functions, sometimes generalized to template functions and function objects.
These are the language facilities supporting the programming styles known as object-oriented programming and generic programming.
The next two chapters follow up by presenting examples of standard-library facilities and their use.
The assumption is that you have programmed before.
If not, please consider reading a textbook, such as Programming: Principles and Practice Using Cplus_plus [Stroustrup,2009], before continuing here.
Even  you have programmed before, the language you used or the applications you.
Huge hierarchies, with hundreds of classes, that are both deep and wide are common.
As a semirealistic classic example, let's consider shapes on a screen: Shape Circle Triangle Smiley arrows represent inheritance relationships.
For example,  Circle is derived from Shape.
To represent that simple diagram in code, we must ﬁrst specify a  that deﬁnes the general properties of all shapes: ptg10564057 Section 3_0_2_0_4 Class 69 Shape {.
Templates are a compile-time mechanism, so their use incurs no run-time overhead compared to "handwritten code" (23_0_2_0_2).
In particular, they are extensively used for parameterization of both types  algorithms in the standard library (4_0_4_0_5, 4_0_5_0_5).
For example, we can write a function that calculates the sum of the element values of any container like this: ptg10564057 80 A Tour of Cplus_plus: Abstraction Mechanisms Chapter 3 template<typename Container, typename Value>.
Note how the types of the template arguments for sum<,V> are deduced from the function arguments.
Fortunately, we do not need to explicitly specify those types.
This sum() is a simpliﬁed version of the standard-library accumulate() (40_0_6).
For example: template<typename > class  { const  val;.
Similarly, a more systematic description of the standard library starts in Chapter 30.
Doing this allows me to give better examples in the following chapters.
As in Chapter 2  Chapter 3, you are strongly encouraged not to be distracted or discouraged by an incomplete understanding of details.
The purpose of this chapter is to give you a taste of what is to come to convey a basic understanding of the most useful library facilities.
The speciﬁcation of the standard library is almost two thirds of the ISO Cplus_plus standard.
Explore it,  prefer it to home-made alternatives.
Much though have gone into its design, more still into its implementations,  much effort will go into its maintenance  extension.
The standard-library facilities described in this book are part of every complete Cplus_plus implementation.
In addition to the standard-library components, most implementations offer "graphical user interface" systems (GUIs), Web interfaces, database interfaces, etc.
Similarly, most application development /or execution environments.
Here, I do not describe such systems  libraries.
The intent is to provide a self-contained description of Cplus_plus as deﬁned by the standard  to keep the examples portable, except where speciﬁcally noted.
Naturally, a programmer is encouraged to explore the more extensive facilities available on most systems.
Run-time language support (e_0_g_0_, for allocation  run-time type information); see 30_0_3.
The C standard library (with very minor modiﬁcations to minimize violations of the type system); see Chapter 43.
Strings and I/O streams (with support for international character sets and localization); see Chapter 36, Chapter 38, and Chapter 39.
I/O streams is an extensible framework to which users can add their own streams, buffering strategies, and character sets.
A framework of containers (such as vector and map) and algorithms (such as ﬁnd(), sort(), and merge()); see 4_0_4, 4_0_5, Chapters 31-33.
This framework, conventionally called the STL [Stepanov,1994], is extensible so users can add their own containers and algorithms.
Support for numerical computation (such as standard mathematical functions, complex numbers, vectors with arithmetic operations, and random number generators); see 3_0_2_0_1_0_1 and Chapter 40.
Support for regular expression matching; see 5_0_5 and Chapter 37.
Support for concurrent programming, including threads and locks; see 5_0_3 and Chapter 41.
The concurrency support is foundational so that users can add support for new  of concurrency as libraries.
Utilities to support template metaprogramming (e_0_g_0_, type traits; 5_0_4_0_2, 28_0_2_0_4, 35_0_4), STL-style generic programming (e_0_g_0_, pair; 5_0_4_0_3, 34_0_2_0_4_0_1), and general programming (e_0_g_0_, clock; 5_0_4_0_1, 35_0_2).
Special-purpose containers, such as array (34_0_2_0_1), bitset (34_0_2_0_2), and tuple (34_0_2_0_4_0_2).
Essentially, the Cplus_plus standard library provides the most common fundamental data structures together with the fundamental algorithms used on them.
For example: #<string> #<> This makes the standard string and  available.
For example: #<string> // make the standard string facilities accessible.
However, in this book, I use the standard library almost exclusively and it is good to know what it offers.
So, I don't preﬁx every use of a standard library name with std::.
Nor do I # the appropriate headers in every example.
Here is a selection of standard-library headers, all supplying declarations in namespace std: <algorithm> 32_0_2 iso_0_25 <array> array 34_0_2_0_1 iso_0_23_0_3_0_2 <chrono> duration, time_point 35_0_2 iso_0_20_0_11_0_2 <cmath> 40_0_3 iso_0_26_0_8 <complex> 40_0_4 iso_0_26_0_8 <fstream> fstream, ifstream, ofstream 38_0_2_0_1 iso_0_27_0_9_0_1 <future> future, promise 5_0_3_0_5 iso_0_30_0_6 <iostream> istream, ostream, cin, cout 38_0_1 iso_0_27_0_4 ptg10564057 90 A Tour of Cplus_plus: Containers and Algorithms Chapter 4 <map> map, multimap 31_0_4_0_3 iso_0_23_0_4_0_4 <memory> unique_ptr, shared_ptr, allocator 5_0_2_0_1 iso_0_20_0_6 <random> default_random_engine, normal_distribution 40_0_7 iso_0_26_0_5 <regex> regex, smatch Chapter 37 iso_0_28_0_8 <string> string, basic_string Chapter 36 iso_0_21_0_3 <set> set, multiset 31_0_4_0_3 iso_0_23_0_4_0_6 <sstream> istrstream, ostrstream 38_0_2_0_2 iso_0_27_0_8 <thread> thread 5_0_3_0_1 iso_0_30_0_3 <unordered_map> unordered_map, unordered_multimap 31_0_4_0_3_0_2 iso_0_23_0_5_0_4 <utility> move(), swap(), pair 35_0_5 iso_0_20_0_1 <vector> vector 31_0_4 iso_0_23_0_3_0_6 This listing is far from complete; see 30_0_2 for more information.
The string type provides a variety of useful string operations, such as concatenation.
Here,  is initialized to  character sequence dmr@bell−labs_0_com.
You can concatenate a string, a string literal, a C-style string, or a character to a string.
The standard string has a move constructor so returning even long strings by value is efﬁcient (3_0_3_0_2).
In many applications,  most common form of concatenation is adding something to  end of a string.
This is directly supported by  += operation.
The two ways of adding   end of a string are semantically equivalent, but I prefer  latter because it is more explicit about what it does, more concise,  possibly more efﬁcient.
A string is mutable.
In addition  =  +=, subscripting (using [])  substring operations are supported.
The standard-library string is described in Chapter 36.
Among other useful features, it provides  ability  manipulate substrings.
For example: ptg10564057 Section 4_0_2 Strings 91.
The substr() operation returns a string that is a copy of  substring indicated by its arguments.
The ﬁrst argument is an index into  string (a position),   second is  length of  desired substring.
Since indexing starts from 0,  gets  value Stroustrup.
The replace() operation replaces a substring with a value.
In this case,  substring starting at 0 with length 5 is Niels; it is replaced by nicholas.
Finally, I replace  initial character with its uppercase equivalent.
Thus,  ﬁnal value of  is Nicholas Stroustrup.
Note that  replacement string need not be  same size as  substring that it is replacing.
Naturally, strings can be compared against each other  against string literals.
The string library is described in Chapter 36.
The most common techniques for implementing string are presented in  String example (19_0_3).
The input operations are typed  extensible  handle user-deﬁned types.
This section is a very brief introduction   use of iostreams; Chapter 38 is a reasonably complete description of iostream library facilities.
Other forms of user interaction, such as graphical I/O, are handled through libraries that are not part of  ISO standard  therefore not described here.
Further, it is easy  deﬁne output of a user-deﬁned type (4_0_3_0_3).
The operator << ("put ") is used as an output operator on objects of ptg10564057 92 A Tour of Cplus_plus: Containers  Algorithms Chapter 4 type ostream;  is  standard output stream  cerr is  standard stream for reporting errors.
By default, values written   are converted  a sequence of characters.
For example,  output decimal number 10, we can write:.
Like ostreams, istreams deal with character string representations of built-in types  can easily be extended  cope with user-deﬁned types.
The operator >> ("get from")  used as an input operator; cin   standard input stream.
The type of  right-hand operand of >> determines what input  accepted  what   target of input operation.
This reads  number, such as 1234, from  standard input into  integer variable    ﬂoatingpoint number, such as 12_0_34e5, into  double-precision ﬂoating-point variable d.
Often, we want  read  sequence of characters.
A convenient way of doing that   read into string.
If you type in Eric  response : , Eric.
By default,  whitespace character (7_0_3_0_2), such as  space, terminates  read, so if you enter Eric Bloodaxe pretending  be  ill-fated king of York,  response  still: , Eric.
You can read  whole line (including  terminating newline character) using  getline() function.
With this program,  input Eric Bloodaxe yields  desired output: , Eric Bloodaxe.
The standard strings have  nice property of expanding  hold what you put in them; you don't hav e  precalculate  maximum size.
So, if you enter  couple of megabytes of semicolons, program will echo pages of semicolons back at you.
For example, consider  simple type Entry that we might use represent entries in  telephone book:.
A user-deﬁned output  takes its output stream (by reference) as its ﬁrst argument returns it as its result.
See 38_0_4_0_2 for details.
The corresponding input   more complicated because it has  check for correct formatting  deal with errors:.
For example, when used as  condition, >> means "Did we succeed at reading from.
An ifstream is an istream that can be attached to a ﬁle, and an ofstream is an ostream that can be attached to a ﬁle.
The 's second argument is used to delimit output values.
Actually, this program is longer than it needs to be.
We read the strings into a , then we sort() them, and then we write them out, eliminating duplicates.
A more elegant solution is not to ptg10564057 108 A Tour of Cplus_plus: Containers and Algorithms Chapter 4 store duplicates at all.
This can be done by keeping the strings in a , which does not keep duplicates and keeps its elements in order (31_0_4_0_3).
That way, we could replace the two lines using a with one using a  and replace unique_copy() with the simpler copy():.
Here, we "forgot" to delete  if <99 or if <77.
On the other hand,  ensures that its object is properly destroyed whichever way we exit f() (by throwing an exception, by executing return, or by "falling off the end").
Ironically, we could have solved the problem simply by not using a pointer  not using :.
Unfortunately, overuse of  ( of pointers  references) seems to be an increasing problem.
However, when you really need the semantics of pointers,  is a very lightweight mechanism with no space or time overhead compared to correct use of a built-in pointer.
Its further uses include passing free-store allocated objects in  out of functions:.
A  is a handle to an individual object (or an array) in much the same way that a vector is a handle to a sequence of objects.
Both control the lifetime of other objects (using RAII)  both rely on move semantics to make return simple  efﬁcient.
The  is similar to  except that shared_ptrs are copied rather than moved.
The shared_ptrs for an object share ownership of an object  that object is destroyed when the last of its shared_ptrs is destroyed.
Note that f() or g() may spawn a task holding a copy of fp or in some other way store a copy that outlives user().
Thus,  provides a form of garbage collection that respects the destructor-based resource management of the memory-managed objects.
This is neither cost free nor exorbitantly expensive, but does make the lifetime of the shared object hard to predict.
Use  only if you actually need shared ownership.
Given   , we can implement a complete "no naked " policy (3_0_2_0_1_0_2) for many programs.
However, these "smart pointers" are still conceptually pointers therefore only my second choice for resource management – after containers  other types that manage their resources at a higher conceptual level.
In particular, shared_ptrs do not in themselves provide any rules for which of their owners can read /or write the shared object.
Data races (41_0_2_0_4)  other forms of confusion are not addressed simply by eliminating the resource management issues.
Where do we use "smart pointers" (such as ) rather than resource handles with operations designed speciﬁcally for the resource (such as vector or thread).
Unsurprisingly, the answer.
When we share an object, we need pointers (or references) to refer to the shared object, so a becomes the obvious choice (unless there is an obvious single owner).
When we refer to a polymorphic object, we need a pointer (or a reference) because we don't know the exact type of the object referred to or even its size), so a  becomes the obvious choice.
A shared polymorphic object typically requires shared_ptrs.
We do not need to use a pointer to return a collection of objects from a function; a container that is a resource handle will do that simply  efﬁciently (3_0_3_0_2).
All modern programming languages provide support for this.
The support provided by the Cplus_plus standard library is a portable  type-safe variant of what has been used in Cplus_plus for more than 20 years  is almost universally supported by modern hardware.
The standard-library support is primarily aimed at supporting systems-level concurrency rather than directly providing sophisticated higher-level concurrency models; those can be supplied as libraries built using the standard-library facilities.
The standard library directly supports concurrent execution of multiple threads in a single address space.
To allow that, Cplus_plus provides a suitable memory model (41_0_2)  a set of atomic operations (41_0_3).
However, most users will see concurrency only in terms of the standard library libraries built on top of that.
This section brieﬂy gives examples of the main standard-library concurrency support facilities: threads, mutexes, lock() operations, packaged_tasks,  futures.
These features are built directly upon what operating systems offer  do not incur performance penalties compared with those.
A thread is the system-level representation of a task in a program.
A task to be executed concurrently with other tasks is launched by constructing a std::thread (found in <thread>) with the task as its argument.
A task is a function or a function object:.
The ISO Cplus_plus Standard Implementations; The Basic Source Character Set.
Types Fundamental Types; Booleans; Character Types; Integer Types; Floating-Point Types; Preﬁxes  Sufﬁxes; void; Sizes; Alignment.
Declarations The Structure of Declarations; Declaring Multiple Names; Names; Scope; Initialization;.
Objects  Values Lvalues  Rvalues; Lifetimes of Objects.
Advice 6_0_1 The ISO Cplus_plus Standard The Cplus_plus language and standard library are deﬁned by their ISO standard: ISO/IEC 14882:2011.
In this book, references to the standard are of the form iso_0_23_0_3_0_6_0_1.
In cases where the text of this book is considered imprecise, incomplete, or possibly wrong, consult the standard.
But don't expect the standard to be a tutorial or to be easily accessible by non-experts.
Strictly adhering to the Cplus_plus language and library standard doesn't by itself guarantee good code or even portable code.
The standard doesn't say whether a piece of code is good or bad; it simply says what a programmer can and cannot rely on from an implementation.
It is easy to write perfectly awful standard-conforming programs, and most real-world programs rely on features that the standard does not guarantee to be portable.
They do so to access system interfaces and ptg10564057 136 Types and Declarations Chapter 6 hardware features that cannot be expressed directly in Cplus_plus or require reliance on speciﬁc implementation details.
Many important things are deemed implementation-deﬁned by the standard.
This means that each implementation must provide a speciﬁc, well-deﬁned behavior for a construct and that behavior must be documented.
For example: unsigned char 1 = 64; // well deﬁned: a char has at least 8 bits and can always hold 64 unsigned char 2 = 1256; // implementation-deﬁned: truncation if a char has only 8 bits The initialization of 1  well deﬁned because a char must be at least 8 bits.
However, the behavior of the initialization of 2  implementation-deﬁned because the number of bits in a char  implementation-deﬁned.
If the char has only 8 bits, the value 1256 will be truncated to 232 (10_0_5_0_2_0_1).
Most implementation-deﬁned features relate to differences in the hardware used to run a program.
Other behaviors are unspeciﬁed; that , a range of possible behaviors are acceptable, but the implementer  not obliged to specify which actually occur.
Usually, the reason for deeming something unspeciﬁed  that the exact behavior  unpredictable for fundamental reasons.
For example, the exact value returned by new  unspeciﬁed.
So  the value of a variable assigned to from two threads unless some synchronization mechanism has been employed to prevent a data race (41_0_2).
When writing real-world programs, it  usually necessary to rely on implementation-deﬁned behavior.
Such behavior  the price we pay for the ability to operate effectively on a large range of systems.
For example, Cplus_plus would have been much simpler if all characters had been 8 bits and all pointers 32 bits.
However, 16-bit and 32-bit character sets are not uncommon, and machines with 16-bit and 64-bit pointers are in wide use.
To maximize portability, it  wise to be explicit about what implementation-deﬁned features we rely on and to isolate the more subtle examples in clearly marked sections of a program.
A typical example of this practice  to present all dependencies on hardware sizes in the form of constants and type deﬁnitions in some header ﬁle.
To support such techniques, the standard library provides numeric_limits (40_0_2).
Many assumptions about implementation-deﬁned features can be checked by stating them as static assertions (2_0_4_0_3_0_3).
For example: (4<=sizeof(int),"siz eof(int) too small"); Undeﬁned behavior  nastier.
A construct  deemed undeﬁned by the standard if no reasonable behavior  required by an implementation.
Typically, some obvious implementation technique will.
Plausible outcomes of this code fragment include overwriting unrelated data and triggering a hardware error/exception.
An implementation  not required to choose among plausible outcomes.
Where powerful optimizers are used, the actual effects of undeﬁned behavior can become quite unpredictable.
If a set of plausible and easily implementable alternatives exist, a feature  deemed ptg10564057 Section 6_0_1 The ISO Cplus_plus Standard 137 unspeciﬁed or implementation-deﬁned rather than undeﬁned.
It  worth spending considerable time and effort to ensure that a program does not use something deemed unspeciﬁed or undeﬁned by the standard.
In many cases, tools exist to help do this.
A hosted implementation includes all the standard-library facilities as described in the standard (30_0_2) and in this book.
A freestanding implementation may provide fewer standard-library facilities, as long as the following are provided: Freestanding Implementation Headers Types <cstddef> 10_0_3_0_1 Implementation properties <cﬂoat> <limits> <climits> 40_0_2 Integer types <cstdint> 43_0_7 Start and termination <cstdlib> 43_0_7 Dynamic memory management <new> 11_0_2_0_3 Type identiﬁcation <typeinfo> 22_0_5 Exception handling <exception> 30_0_4_0_1_0_1 Initializer lists <initializer_list> 30_0_3_0_1 Other run-time support <cstdalign> <cstdarg> <cstdbool> 12_0_2_0_4, 44_0_3_0_4 Type traits <type_traits> 35_0_4_0_1 Atomics <atomic> 41_0_3 Freestanding implementations are meant for code running with only the most minimal operating system support.
Many implementations also provide a (non-standard) option for not using exceptions for really minimal, close-to-the-hardware, programs.
This can cause problems for people who use Cplus_plus in an environment with a different character set:.
ASCII contains punctuation characters and operator symbols (such as ], {, and _0_) that are not available in some character sets.
We need a notation for characters that do not have a convenient character representation (such as newline and "the character with value 17").
ASCII doesn't contain characters (such as ñ, Þ, and Æ) that are used for writing languages other than English.
To use an extended character set for source code, a programming environment can map the extended character set into the basic source character set in one of several ways, for example, by using universal character names (6_0_2_0_3_0_2).
That is, the programmer must specify that entities named , , and f exist and that they are of types for = (assignment), + (addition), and () (function call), respectively, are meaningful.
Every name (identiﬁer) in a Cplus_plus program has a type associated with it.
This type determines what operations can be applied to the name (that is, to the entity referred to by the name) and how.
Because  is declared to be an int, it can be assigned to, used as an operand for +, etc.
On the other hand, f is declared to be a function that takes an int as its argument, so it can be called given the interger 2.
This chapter presents fundamental types (6_0_2_0_1) and declarations (6_0_3).
Its examples just demonstrate language features; they are not intended to do anything useful.
More extensive and realistic examples are saved for later chapters.
This chapter simply provides the most basic elements from  Cplus_plus programs are constructed.
You must know these elements, plus the terminology and simple syntax that go with them, in order to complete a real project in Cplus_plus and especially to read code written by others.
However, a thorough understanding of every detail mentioned in this chapter is not a requirement for understanding the following chapters.
Consequently, you may prefer to skim through this chapter, observing the major concepts, and return later as the need for understanding more details arises.
The integral and are called user-deﬁned types because they must be deﬁned by users rather than being available for use without previous declaration, the way fundamental types are.
In contrast, fundamental types, pointers, and references are collectively referred to as built-in types.
The standard library provides many user-deﬁned types (Chapter 4, Chapter 5).
The integral and ﬂoating-point types are provided in a variety of sizes to give the programmer a choice of the amount of storage consumed, the precision, and the range available for computations (6_0_2_0_8).
The assumption is that a computer provides bytes for holding characters, words for holding and computing integer values, some entity most suitable for ﬂoating-point computation, and addresses for referring to those entities.
The Cplus_plus fundamental types together with pointers and arrays present these machine-level notions to the programmer in  reasonably implementation-independent manner.
For most applications, we could use bool for logical values, char for characters, int for integer values, and double for ﬂoating-point values.
The remaining fundamental types are variations for optimizations, special needs, and compatibility that are best ignored until such needs arise.
A Boolean is used to express the results of logical operations.
A common use of bool is as the type of the result of  function that tests some condition ( predicate).
For example: bool is_open(File∗); bool greater(int , int ) { return >; }.
If you prefer to use the {}-initializer syntax to prevent narrowing, yet still want to convert an int to bool, you can be explicit: ptg10564057 140 Types and Declarations Chapter 6.
I prefer if () over if (_0_=nullptr) because it more directly expresses the notion "if  is valid" and also because it is shorter.
The shorter form leaves fewer opportunities for mistakes.
Cplus_plus provides  variety of character types that reﬂect that – often bewildering – variety:.
A char is used for the implementation's character set and is usually 8 bits.
The size of wchar_t is implementation-deﬁned and large enough to hold the largest character set supported by the implementation's locale (Chapter 39).
These are six distinct types (despite the fact that the _t sufﬁx is often used to denote aliases; 6_0_5).
On each implementation, the char type will be identical to that of either signed char or unsigned ptg10564057 Section 6_0_2_0_3 Character Types 141 char, but these three names are still considered separate types.
A char variable can hold  character of the implementation's character set.
For example: char  = ''; Almost universally,  char has 8 bits so that it can hold one of 256 different values.
Typically, the character set is  variant of ISO-646, for example ASCII, thus providing the characters appearing on your keyboard.
Many problems arise from the fact that this set of characters is only partially standardized.
Serious variations occur between character sets supporting different natural languages and between character sets supporting the same natural language in different ways.
Here, we are interested only in how such differences affect the rules of Cplus_plus.
The larger and more interesting issue of how to program in  multilingual, multi-character-set environment is beyond the scope of this book, although it is alluded to in several places (6_0_2_0_3, 36_0_2_0_1, Chapter 39).
It is safe to assume that the implementation character set includes the decimal digits, the 26 alphabetic characters of English, and some of the basic punctuation characters.
It is not safe to assume that:.
There are no more than 127 characters in an 8-bit character set (e_0_g_0_, some sets provide 255 characters).
There are no more alphabetic characters than English provides (most European languages provide more, e_0_g_0_, æ, þ, and ß).
The alphabetic characters are contiguous (EBCDIC leaves  gap between '' and 'j').
Every character used to write Cplus_plus is available (e_0_g_0_, some national character sets do not provide {, }, [, ], |, and \).
A char ﬁts in 1 byte.
There are embedded processors without byte accessing hardware for which  char  4 bytes.
Also, one could reasonably use  16-bit Unicode encoding for the basic chars.
Whenever possible, we should avoid making assumptions about the representation  objects.
This general rule applies even to characters.
Each character has an integer value in the character set used by the implementation.
For example, the value  ''  98 in the ASCII character set.
Here   loop that outputs the the integer value any character you care to input:.
The possibility  converting  char to an integer raises the question:   char signed or unsigned.
The 256 values represented by an 8-bit byte can be interpreted as the values 0 to 255 or as the values −127 to 127.
No, not −128 to 127 as one might expect: the Cplus_plus standard leaves open the possibility  one's-complement hardware and that eliminates one value; thus,  use  −128  nonportable.
Unfortunately, the choice  signed or unsigned for  plain char  implementationdeﬁned.
Cplus_plus provides two types for which the answer  deﬁnite: signed char, which can hold at least the values −127 to 127, and unsigned char, which can hold at least the values 0 to 255.
Values outside that range stored in  plain char can lead to subtle portability problems.
See 6_0_2_0_3_0_1 if you need to use more than one type  char or if you store integers in char variables.
Note that the character types are integral types (6_0_2_0_1) so that arithmetic and bitwise logical operations (10_0_3) apply.
The character literal '0'  converted to its integer value and   added.
The resulting int  then converted to  char and written to.
Plain '0'+ an int, so if I had left out the <char>, the output would have been something like 48, 49, and so on, rather than 0, 1, and so on.
This opens the possibility for some nasty surprises and implementation dependencies.
For example: char  = 255; // 255  "all ones,' ' hexadecimal 0xFF int  = ; What will be the value.
Unfortunately, the answer  undeﬁned.
On an implementation with 8-bit bytes, the answer depends on the meaning  the "all ones" char bit pattern when extended into an int.
On  machine where  char  unsigned, the answer  255.
On  machine where  char signed, the answer  −1.
In this case, the compiler might warn about the conversion  the literal 255 to the char value −1.
Howev er, Cplus_plus does not offer  general mechanism for detecting this kind problem.
One solution  to avoid plain char and use the speciﬁc char types only.
Unfortunately, some standard-library functions, such as strcmp(), take plain chars only (43_0_4).
A char must behave identically to either a signed char or an unsigned char.
Howev er, the three.
The type a character literal  char.
A character literal can be implicitly converted to its integer value in the character set  the machine on which the Cplus_plus program  to run.
For example, if you are running on a machine using the ASCII character set, the value  '0'  48.
The use  character literals rather than decimal notation makes programs more portable.
A few characters have standard names that use the backslash, \ , as an escape character: Name ASCII Name Cplus_plus Name Newline \n Horizontal tab HT \t Vertical tab VT \v Backspace BS \b Carriage return CR \r Form feed FF \f Alert BEL \a Backslash \ \\ Question mark.
Single quote ' \' Double quote.
For example, we can set aside uninitialized storage for some type X like this:.
As can be seen from these examples,  declaration can do more than simply associate  type with Most of these declarations are also deﬁnitions.
A deﬁnition is  declaration that supplies all that is needed in  program for the use of an entity.
In particular, if it takes memory to represent something, that memory is set aside by its deﬁnition.
A different terminology deems declarations parts of an interface and deﬁnitions parts of an implementation.
When taking that view, we try to compose interfaces out of declarations that can be replicated in separate ﬁles (15_0_2_0_2); deﬁnitions that set aside memory do not belong in interfaces.
Assuming that these declarations are in the global scope (6_0_3_0_4), we have: char ch; // set aside memory for  char and initialize it to 0 auto  = 1; // set aside memory for an int initialized to 1 const char∗  = "Njal"; // set aside memory for  pointer to char.
In this, standard Cplus_plus differs from early versions of C and Cplus_plus that allowed  ﬁrst two examples by considering int to be  type when none was speciﬁed (44_0_3).
This "implicit int" rule was a source of subtle errors and much confusion.
Some types have names composed out of multiple keywords, such as long long and volatile int.
Some type names don't even look much like names, such as decltype(f(x)) ( return type of a call f(x); 6_0_3_0_6_0_3).
The volatile speciﬁer is described in 41_0_4.
The alignas() speciﬁer is described in 6_0_2_0_9.
The declaration simply contains a list of comma-separated declarators.
For example, we can declare two integers like this: int x, y; // int x; int y; ptg10564057 Section 6_0_3_0_2 Declaring Multiple Names 155 Operators apply to individual names only – and not to any subsequent names in  same declaration.
The ﬁrst character must be a letter.
The underscore character, _, is considered a letter.
Cplus_plus imposes no limit on  number of characters in a.
However, some parts of an implementation are not under  control of  compiler writer (in particular,  linker), and those parts, unfortunately, sometimes do impose limits.
Some run-time environments also make it necessary to extend  restrict  set of characters accepted in an identiﬁer.
Extensions (e_0__0_, allowing  character $ in a ) yield nonportable programs.
A Cplus_plus keyword (6_0_3_0_3_0_1), such as new  int, cannot be used as a  of a user-deﬁned entity.
Examples of names are: hello this_is_a_most_unusually_long_identiﬁer_that_is_better_avoided DEFINED foO bAr u_name HorseSense var0 var1 CLASS _class ___ Examples of character sequences that cannot be used as identiﬁers are: 012 a fool $sys class 3var pay_0_due foo˜bar _0_name if Nonlocal names starting with an underscore are reserved for special facilities in the implementation and the run-time environment, so such names should not be used in application programs.
Similarly, names starting with a double underscore (__)  an underscore followed by an uppercase letter (e_0_g_0_, _Foo) are reserved (iso_0_17_0_6_0_4_0_3).
When reading a program, the compiler always looks for the longest string of characters that could make up a name.
Hence, var10 is a single name, not the name var followed by the number 10.
Also, elseif is a single name, not the keyword else followed by the keyword if.
Uppercase and lowercase letters are distinct, so Count and count are different names, but it is often unwise to choose names that differ only by capitalization.
In general, it is best to avoid names that differ only in subtle ways.
For example, in some fonts, the uppercase "o" (O) and zero (0) can be hard to tell apart, as can the lowercase "L" (l), uppercase "i" (I), and one (1).
Consequently, l0, lO, l1, ll, and I1l are poor choices for identiﬁer names.
Not all fonts have the same problems, but most have some.
Names from a large scope ought to have relatively long and reasonably obvious names, such as vector, Window_with_border, and Department_number.
Howev er, code is clearer if names used only in a small scope have short, conventional names such as x, i, and p.
Functions (Chapter 12), classes (Chapter 16), and namespaces (14_0_3_0_1) can be used to keep scopes small.
It is often useful to keep frequently used names relatively short and reserve really long names for infrequently used entities.
For example, phone_book is better than number_vector ev en if the phone numbers happen to be stored in a vector (4_0_4).
Do not encode type information in a name (e_0_g_0_, pcname for a name that's a char∗  icount for a count that's an int) as is sometimes done in languages with dynamic  weak type systems:.
Encoding types in names lowers the abstraction level of the program; in particular, it prevents generic programming (which relies on a name being able to refer to entities of different types).
The compiler is better at keeping track of types than you are.
If you want to change the type of a name (e_0_g_0_, use a std::string to hold the name), you'll have to change every use of the name ( the type encoding becomes a lie).
Any system of type abbreviations you can come up with will become overelaborate and cryptic as the variety of types you use increases.
Choosing good names is an art.
Try to maintain a consistent naming style.
For example, capitalize names of user-deﬁned types and start names of non-type entities with a lowercase letter (for example, Shape and current_token).
Also, use all capitals for macros (if you must use macros (12_0_6); for example, HACK) and never for non-macros (not even for non-macro constants).
Use underscores to separate words in an identiﬁer; number_of_elements is more readable than numberOfElements.
Howev er, consistency is hard to achieve because programs are typically composed of fragments from different sources and several different reasonable styles are in use.
Be consistent in your use of abbreviations and acronyms.
Note that the language and the standard library use lowercase for types; this can be seen as a hint that they are part of the standard.
Local : A name declared in a function (Chapter 12) or lambda (11_0_4) is called a local name.
Its  extends from its point of declaration to the end of the block in which its declaration occurs.
A block is a section of code delimited by a {} pair.
Function and lambda parameter names are considered local names in the outermost block of their function or lambda.
Class : A name is called a member name (or a class member name) if it is deﬁned in a class outside any function, class (Chapter 16), enum class (8_0_4_0_1), or other namespace.
Its extends from the opening { of the class declaration to the end of the class declaration.
Namespace : A name is called a namespace member name if it is deﬁned in a namespace (14_0_3_0_1) outside any function, lambda (11_0_4), class (Chapter 16), enum class (8_0_4_0_1), or other namespace.
Its  extends from the point of declaration to the end of its namespace.
A namespace name may also be accessible from other translation units (15_0_2).
Global : A name is called a global name if it is deﬁned outside any function, class (Chapter 16), enum class (8_0_4_0_1), or namespace (14_0_3_0_1).
The  of a global name extends from the point of declaration to the end of the ﬁle in which its declaration occurs.
A global name may also be accessible from other translation units (15_0_2).
Technically, the global namespace is considered a namespace, so a global name is an example of a namespace member name.
Statement : A name is in a statement  if it is deﬁned within the () part of a for-, while-, if-, or switch-statement.
Its  extends from its point of declaration to the end of its statement.
All names in statement  are local names.
Function : A label (9_0_6) is in  from its point of declaration until the end of the function.
A declaration of a name in a block can hide a declaration in an enclosing block or a global name.
That is, a name can be redeﬁned to refer to a different entity within a block.
After exit from the block, the name resumes its previous meaning.
However, a human reader can easily fail to notice that a name has been hidden (also known as shadowed).
Because such errors are relatively rare, they can be very difﬁcult to ﬁnd.
Consequently, name hiding should be minimized.
Using names such as i and  for global variables or for local variables in a large function is asking for trouble.
A hidden global name can be referred to using the  resolution operator, ::.
There is no way to use a hidden local name.
The  of a name that is not a class member starts at its point of declaration, that is, after the complete declarator and before the initializer.
This implies that a name can be used even to specify its own initial value.
It is possible to use a single name to refer to two different objects in a block without using the :: operator.
For example: int  = 11;.
Names introduced in a for-statement are local to that statement (in statement ).
This allows us to use conventional names for loop variables repeatedly in a function.
This contains no name clashes.
A declaration is not allowed as the only statement on the branch of an if-statement (9_0_4_0_1).
An initializer can  one of four syntactic styles:.
Of these, only the ﬁrst can be used  every context, and I strongly recommend its.
It is clearer and less error-prone than the alternatives.
However, the ﬁrst form (used for 1) is new  Cplus_plus11, so the other three forms are what you ﬁnd  older code.
The two forms  = are what you C.
Old habits die hard, so I sometimes (inconsistently)  = when initializing  simple variable with  simple value.
For example: int 1 = 0; char 1 = 'z'; However, anything much more complicated than that is better done  {}.
Initialization  {}, initialization, does not allow narrowing (iso_0_8_0_5_0_4).
An integer cannot be converted to another integer that cannot hold its value.
For example, char to int is allowed, but not int to char.
A ﬂoating-point value cannot be converted to another ﬂoating-point type that cannot hold its value.
For example, ﬂoat to double is allowed, but not double to ﬂoat.
A ﬂoating-point value cannot be converted to an integer type.
An integer value cannot be converted to  ﬂoating-point type.
There is no advantage to  {} initialization, and one trap, when  auto to get the type determined by the initializer.
The trap is that if the initializer is  {}-, we may not want its type deduced (6_0_3_0_6_0_2).
It is possible to deﬁne  class so that an object can be initialized by   of values and alternatively be constructed given  couple of arguments that are not simply values to be stored.
The classical example is   of integers: <int> v1 {99}; // v1 is   of 1 element with the value 99 <int> v2(99);.
For integral types, the default value is  suitable representation of zero.
For pointers, the default value is nullptr (7_0_2_0_2).
For user-deﬁned types, the default value (if any) is determined by the type's constructors (17_0_3_0_3).
For user-deﬁned types, there can be  distinction between direct initialization (where implicit conversions are allowed) and copy initialization (where they are not); see 16_0_2_0_6.
Initialization of particular kinds of objects is discussed where appropriate:.
Classes: 17_0_3_0_1 (not  constructors), 17_0_3_0_2 ( constructors), 17_0_3_0_3 (default),.
User-deﬁned containers: 17_0_3_0_4 6_0_3_0_5_0_1 Missing Initializers For many types, including all built- types, it is possible to leave out the initializer.
If you do that – and that has unfortunately been common – the situation is more complicated.
If you don't like the complications, just initialize consistently.
The only really good case for an uninitialized variable is  large input buffer.
For example: constexpr int  = 1024∗1024; char buf[];.
Avoid such low-level  of buffers where you can, and don't leave such buffers uninitialized unless you know (e_0_g_0_, from measurement) that the optimization compared to  an initialized array is signiﬁcant.
If no initializer is speciﬁed,  global (6_0_3_0_4), namespace (14_0_3_0_1), local static (12_0_1_0_8), or static member (16_0_2_0_12) (collectively called static objects) is initialized to {} of the appropriate.
A member of an array or  class is default initialized if the array or structure is.
More complicated objects can require more than one value as an initializer.
This is primarily handled by initializer.
For C-style initialization of arrays, see 7_0_3_0_1.
For C-style structures, see 8_0_2.
For user-deﬁned types with constructors, see 2_0_3_0_2 or 16_0_2_0_5.
For initializer-list constructors, see 17_0_3_0_4.
In  cases above,  = is redundant.
However, some  to add it to emphasize that  set of values are used to initialize  set of member variables.
In some cases, function-style argument lists can also be used (2_0_3, 16_0_2_0_5).
The deduction done here is very simple: auto and decltype() simply report  type  an expression already known to  compiler.
Instead, we can let  variable have  type  its initializer.
Aliases are used when we want to insulate our code from details of the underlying machine.
The 32 indicates that we want it to represent a 32-bit integer.
Having written our code in terms of 32, rather than "plain ," we can port our code to a machine with sizeof()==2 by redeﬁning the single occurrence of 32 in our code to use a longer integer: using 32 = long; The  sufﬁx is conventional for aliases ("typedefs").
The 16, 32,  other such aliases can be found in <stdint> (43_0_7).
Note that naming a type after its representation rather than its purpose is not necessarily a good idea (6_0_3_0_3).
The using keyword can also be used to introduce a template alias (23_0_6).
For example: template<typename T> using  = std::<T, <T>>;.
Pointers void∗; nullptr.
Arrays Array Initializers; String Literals.
Pointers into Arrays Navigating Arrays; Multidimensional Arrays; Passing Arrays.
Pointers and const.
Pointers and Ownership.
References Lvalue References; Rvalue References; References to References; Pointers and References.
Advice 7_0_1 Introduction This chapter deals with  basic language mechanisms for referring to memory.
Obviously, we can refer to an object by name, but in Cplus_plus (most) objects "have identity_0_" That is, they reside at a speciﬁc address in memory, and an object can be accessed if you know its address and its type.
The language constructs for holding and using addresses are pointers and references.
For example: char  = 'a'; char∗  = &; //  holds  address of ; & is  address-of operator or graphically: & 'a' : : The fundamental operation on a pointer is dereferencing, that is, referring to  object pointed to unary ∗.
For example: char  = 'a'; char∗  = &; //  holds  address of ; & is  address-of operator char 2 = ∗; // 2 == 'a'; * is  dereference operator The object pointed to by  is , and  value stored in  is 'a', so  value of ∗ assigned to 2 is 'a'.
It is possible to perform some arithmetic operations on pointers to array elements (7_0_4).
The implementation of pointers is intended to map directly to  addressing mechanisms of machine on which  program runs.
Most machines can address a byte.
Those that can't tend to have hardware to extract bytes from words.
On  other hand, few machines can directly address an individual bit.
Consequently,  smallest object that can be independently allocated and pointed to using a built-in pointer type is a char.
Note that a bool occupies at least as much space as a char (6_0_2_0_8).
To store smaller values more compactly, you can use  bitwise logical operations (11_0_1_0_1), bit-ﬁelds in structures (8_0_2_0_7), or a bitset (34_0_2_0_2).
The ∗, meaning "pointer to," is used as a sufﬁx for a type name.
Unfortunately, pointers to arrays and pointers to functions need a more complicated notation: int∗ pi; // pointer to int char∗∗ ppc; // pointer to pointer to char int∗ ap[15]; // array of 15 pointers to ints int (∗fp)(char∗); // pointer to function taking a char* argument; returns an int int∗ f(char∗); // function taking a char* argument; returns a pointer to int See 6_0_3_0_1 for an explanation of  declaration syntax and iso_0_A for  complete grammar.
Pointers to functions can be useful; they are discussed in 12_0_5.
Pointers to class members are presented in 20_0_6.
You can read ptg10564057 Section 7_0_2_0_1 void∗ 173 A pointer to any type of object can be assigned to a variable of type void∗, but a pointer to function (12_0_5) or a pointer to member (20_0_6) cannot.
In addition, a void∗ can be assigned to another void∗, void∗s can be compared for equality and inequality, and a void∗ can be explicitly converted to another type.
Other operations would be unsafe because  compiler cannot know what kind of object is really pointed to.
Consequently, other operations result in compile-time errors.
To use a void∗, we must explicitly convert it to a pointer to a speciﬁc type.
In general, it is not safe to use a pointer that has been converted ("cast") to a type that differs from the type of the object pointed to.
For example, a machine may assume that every double is allocated on an 8-byte boundary.
If so, strange behavior could arise if  pointed to an int that wasn't allocated that way.
This form of explicit type conversion is inherently unsafe and ugly.
Consequently, the notation used,  (11_0_5_0_2), was designed to be ugly and easy to ﬁnd in code.
The primary use for void∗ is for passing pointers to functions that are not allowed to make assumptions about the type of the object and for returning untyped objects from functions.
To use such an object, we must use explicit type conversion.
Functions using void∗ pointers typically exist at the very lowest level of the system, where real hardware resources are manipulated.
For example: void∗ my_alloc(siz e_t n); // allocate n bytes from my special heap Occurrences of void∗s at higher levels of the system should be viewed with great suspicion because they are likely indicators of design errors.
Where used for optimization, void∗ can be hidden behind a type-safe interface (27_0_3_0_1).
Pointers to functions (12_0_5) and pointers to members (20_0_6) cannot be assigned to void∗s.
It can be assigned to any pointer type, but not to other built-in types: int∗  = nullptr; double∗  = nullptr; int  = nullptr; // error :  is not a pointer There is just one nullptr, which can be used for every pointer type, rather than a null pointer for each pointer type.
For example: int∗  = 0; //  gets the value nullptr No object is allocated with the address 0, and 0 (the all-zeros bit pattern) is the most common representation of nullptr.
Zero (0) is an int.
Howev er, the standard conversions (10_0_5_0_2_0_3) allow 0 to be used as a constant of pointer or pointer-to-member type.
It has been popular to deﬁne a macro NULL to represent the null pointer.
For example: int∗  = NULL; // using the macro NULL However, there are differences in the deﬁnition of NULL in different implementations; for example, NULL might be 0 or 0L.
In C, NULL is typically (void∗)0, which makes it illegal in Cplus_plus (7_0_2_0_1): int∗  = NULL; // error : can't assign a void* to an int* Using nullptr makes code more readable than alternatives and avoids potential confusion when a function is overloaded to accept either a pointer or an integer (12_0_3_0_1).
For example: ﬂoat v[3]; // an array of three ﬂoats: v[0], v[1], v[2] char∗ a[32];.
Access out of the range of an array is undeﬁned and usually disastrous.
In particular, run-time range checking is neither guaranteed nor common.
The number of elements of the array, the array bound, must be a constant expression (10_0_4).
If you need variable bounds, use a  (4_0_4_0_1, 31_0_4).
An array is Cplus_plus's fundamental way of representing a sequence of objects in memory.
If what you want is a simple ﬁxed-length sequence of objects of a given type in memory, an array is the ideal solution.
For every other need, an array has serious problems.
There is no array assignment, and the name of an array implicitly converts to a pointer to its ﬁrst element at the slightest provocation (7_0_4).
In particular, avoid arrays in interfaces (e_0_g_0_, as function arguments; 7_0_4_0_3, 12_0_2_0_2) because the implicit conversion to pointer is the root cause of many common errors in C code and C-style Cplus_plus code.
If you allocate an array on the free store, be sure to delete[] its pointer once only and only after its last use (11_0_2_0_2).
That's most easily and most reliably done by having the lifetime of the free-store array controlled by a resource handle (e_0_g_0_, string (19_0_3, 36_0_3),  (13_0_6, 34_0_2), or unique_ptr (34_0_3_0_1)).
If you allocate an array statically or on the stack, be sure never to delete[] it.
Obviously, C programmers cannot follow these pieces of advice because C lacks the ability to encapsulate arrays, but that doesn't make the advice bad in the context of Cplus_plus.
One of the most widely used kinds of arrays is a zero-terminated array of char.
That's the way C stores strings, so a zero-terminated array of char is often called a C-style string.
Cplus_plus string literals follow that convention (7_0_3_0_2), and some standard-library functions (e_0_g_0_, strcpy() and strcmp(); 43_0_4) rely on it.
Often, a char∗ or a const char∗ is assumed to point to a zero-terminated sequence of characters.
For example: 1[] = { 1, 2, 3, 4 }; char 2[] = { 'a', 'b', 'c', 0 }; When an array is declared without a speciﬁc size, but with an initializer list, the size is calculated by counting the elements of the initializer list.
If a size is explicitly speciﬁed, it is an error to give surplus elements in an initializer list.
You cannot initialize one array with another (not ev en of exactly the same type), and there is no array assignment: 6 = 5; // error : no array assignment Similarly, you can't pass arrays by value.
When you need assignment to a collection of objects, use a  (4_0_4_0_1, 13_0_6, 34_0_2), an array (8_0_2_0_4), or a valarray (40_0_5) instead.
An array of characters can be conveniently initialized by a string literal (7_0_3_0_2).
For example: sizeof("")==5 The type of a string literal is "array of the appropriate number of const characters," so "" is of type const char[5].
In C and in older Cplus_plus code, you could assign a string literal to a non-const char∗:.
It would obviously be unsafe to accept that assignment.
It was (and is) a source of subtle errors, so please don't grumble too much if some old code fails to compile for this reason.
Having string literals immutable is not only obvious but also allows implementations to do signiﬁcant optimizations in the way string literals are stored and accessed.
If we want a string that we are guaranteed to be able to modify, we must place the characters in a non-const array:.
Whether two identical string literals are allocated as one array or as two is implementationdeﬁned (6_0_1).
The empty string is written as a pair of adjacent double quotes, "", and has the type const char[1].
The one character of the empty string is the terminating '\0'.
The backslash convention for representing nongraphic characters (6_0_2_0_3_0_2) can also be used within a string.
This makes it possible to represent the double quote (") and the escape character backslash (\) within a string.
The most common such character by far is the newline character, '\n'.
For example: <<"beep at end of message\a\n"; The escape character, '\a', is the ASCII character BEL (also known as alert), which causes a sound to be emitted.
It is not possible to have a "real" newline in a (nonraw) string literal: "this is not a string "ABCDEFGHIJKLMNOPQRSTUVWXYZ"; The compiler will concatenate adjacent strings, so  could equivalently have been initialized by the single string "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"; It is possible to have the null character in a string, but most programs will not suspect  there are characters after it.
For example, the string "Jens\000Munk" will be treated as "Jens" by standardlibrary functions such as strcpy() and strlen(); see 43_0_4.
That's logical and in most cases quite simple.
However, if we need a lot of backslashes and a lot of quotes in string literals, this simple technique becomes unmanageable.
In particular, in regular expressions a backslash is used both as an escape character and to introduce characters ptg10564057 178 Pointers, Arrays, and References Chapter 7 representing character classes (37_0_1_0_1).
This is a convention shared by many programming languages, so we can't just change it.
Therefore, when you write regular expressions for use with the standard regex library (Chapter 37), the fact  a backslash is an escape character becomes a notable source of errors.
Consider how to write the pattern representing two words separated by a backslash (\): string  = "\\w\\\\w"; // I hope I got  right To prevent the frustration and errors caused by this clash of conventions, Cplus_plus provides raw string literals.
A raw string literal is a string literal where a backslash is just a backslash (and a double quote is just a double quote) so  our example becomes: string  = R"(\w\\w)"; // I'm pretty sure I got  right Raw string literals use the R"(ccc)" notation for a sequence of characters ccc.
The initial R is there to distinguish raw string literals from ordinary string literals.
The parentheses are there to allow ("unescaped") double quotes.
For example: So, how do we get the character sequence )" into a raw string literal.
Fortunately, ' a rare problem, but "( and )" is only the default delimiter pair.
We can add delimiters before the ( and after the ) in "(_0__0__0_)".
For example: The character sequence after the ) must be identical to the sequence before the (.
This way we can cope with (almost) arbitrarily complicated patterns.
Unless you work with regular expressions, raw string literals are probably just a curiosity (and one more thing to learn), but regular expressions are useful and widely used.
Consider a real-world example: "('(_0_:[ˆ\\\\']|\\\\_0_)∗'|\"(_0_:[ˆ\\\\\"]|\\\\_0_)∗\")|" // Are the ﬁve backslashes correct or not.
With examples like , even experts easily become confused, and raw string literals provide a signiﬁcant service.
In contrast to nonraw string literals, a raw string literal can contain a newline.
For example: string counts {R"(1 22 333)"}; is equivalent to string x {"1\n22\n333"}; 7_0_3_0_2_0_2 Larger Character Sets A string with the preﬁx L, such as L"angst", is a string of wide characters (6_0_2_0_3).
Its type is const wchar_t[].
Similarly, a string with the preﬁx LR, such as LR"(angst)", is a raw string (7_0_3_0_2_0_1) of wide characters of type const wchar_t[].
Such a string is terminated by a L'\0' character.
This sounds excessive, but there are three major encodings of Unicode: UTF-8, UTF-16, and UTF-32.
For each of these three alternatives, both raw and "ordinary" strings are supported.
All three UTF encodings support all Unicode characters, so which you use depends on the system you need to ﬁt into.
Essentially all Internet applications (e_0_g_0_, browsers and email) rely on one or more of these encodings.
UTF-8 is a variable-width encoding: common characters ﬁt into 1 byte, less frequently used characters (by some estimate of use) into 2 bytes, and rarer characters into 3 or 4 bytes.
In particular, the ASCII characters ﬁt into 1 byte with the same encodings (integer values) in UTF-8 as in ASCII.
The various Latin alphabets, Greek, Cyrillic, Hebrew, Arabic, and more ﬁt into 2 bytes.
A UTF-8 string is terminated by '\0', a UTF-16 string by u'\0', and a UTF-32 string by U'\0'.
We can represent an ordinary English character string in a variety of ways.
Consider a ﬁle name using a backslash as the separator: "folder\\ﬁle" // implementation character set string R"(folder\ﬁle)".
Obviously, the real purpose of Unicode strings is to be able to put Unicode characters into them.
For example: Printing  string appropriately gives you The ofﬁcial vowels in Danish are: a, e, i, o, u, æ, ø, å and y.
The hexadecimal number after the \u is a Unicode code point (iso_0_2_0_14_0_3) [Unicode,1996].
Such a code point is independent of the encoding used and will in fact have different representations (as bits in bytes) in different encodings.
For example, u'0430' (Cyrillic lowercase letter "a") is the 2-byte hexadecimal value D0B0 in UTF-8, the 2-byte hexadecimal value 0403 in UTF-16, and the 4-byte hexadecimal value 00000403 in UTF-32.
These hexadecimal values are referred to as universal character names.
The order of the us and Rs and their cases are signiﬁcant: RU and Ur are not valid string preﬁxes.
The name of an array can be used as a pointer to its initial element.
For example: ptg10564057 180 Pointers, Arrays, and References Chapter 7.
This is important for many algorithms (4_0_5, 33_0_1).
However, since such a pointer does not in fact point to an element of the array, it may not be used for reading or writing.
The result of taking the address of the element before the initial element or beyond one-past-the-last element is undeﬁned and should be avoided.
The same value is passed to the standard-library function strlen() in both calls.
The snag is that it is impossible to avoid the implicit conversion.
In other words, there is no way of declaring a function so that the array  is copied when the function is called.
Fortunately, there is no implicit or explicit conversion  a pointer to an array.
The implicit conversion of the array argument to a pointer means that the size of the array is lost to the called function.
However, the called function must somehow determine the size to perform a relies on zero to indicate end-of-string; strlen() returns the number of characters up to and not including the terminating 0.
This is all pretty low-level.
The standard-library vector (4_0_4_0_1, 13_0_6, 31_0_4), array (8_0_2_0_4, 34_0_2_0_1), and string (4_0_2) don't suffer  this problem.
These library types give their number of elements as their size() without having to count elements each time.
Access can be achieved either through a pointer to an array plus an index or through a pointer to an element.
There is no inherent reason why one version should be faster than the other.
With modern compilers, identical code should be (and usually is) generated for both examples.
Programmers can choose between the versions on logical and aesthetic grounds.
Subscripting  built-in array is deﬁned in terms of the pointer operations + and ∗.
For every built-in array  and integer  within the range of , we hav e: [] == ∗(&[0]+) == ∗(+) == ∗(+) == [] It usually surprises people to ﬁnd that []==[].
Such cleverness has no place in production code.
These equivalences are pretty low-level and do not hold for standard-library containers, such as array and vector.
The result of applying the arithmetic operators +, −, plus_plus, or −− to pointers depends on the type of the object pointed to.
When an arithmetic operator is applied to  pointer  of type T∗,  is assumed to point to an element of an array of objects of type T; +1 points to the next element of that array, larger than the integer value of.
For example: template<typename T>.
This shows that on my implementation, sizeof(short) is 2 and sizeof(int) is 4.
Subtraction of pointers is deﬁned only when both pointers point to elements of the same array (although the language has no fast way of ensuring that is the case).
When subtracting  pointer another pointer q, q−, the result is the number of array elements in the sequence [:q) (an integer).
One can add an integer to  pointer or subtract an integer   pointer; in both cases, the result is  pointer value.
If that value does not point to an element of the same array as the original pointer or one beyond, the result of using that value is undeﬁned.
Complicated pointer arithmetic is usually unnecessary and best avoided.
Addition of pointers makes no sense and is not allowed.
Arrays are not self-describing because the number of elements of an array is not guaranteed to be stored with the array.
This implies that to traverse an array that does not contain  terminator the way C-style strings do, we must somehow supply the number of elements.
Most advantages of the built-in array and few of the disadvantages can be obtained through the use of the standard-library container array (8_0_2_0_4, 34_0_2_0_1).
Some Cplus_plus implementations offer optional range checking for arrays.
However, such checking can be quite expensive, so it is often used only as  development aid (rather than being included in production code).
If you are not using range checking for individual accesses, try to maintain  consistent policy of accessing elements only in well-deﬁned ranges.
That is best done when arrays are manipulated through the interface of  higher-level container type, such as vector, where it is harder to get confused about the range of valid elements.
In particular, there is no single object in memory that is the matrix ma – only the elements are stored.
The dimensions 3 and 5 exist in the compiler source only.
When we write code, it is our job to remember them somehow and supply the dimensions where needed.
For example, we might print ma like this:.
Fortunately, most mistakes are caught by the compiler.
For example: int bad[3,5]; // error : comma not allowed in constant expression.
Instead, an array is passed as  pointer to its ﬁrst element.
For example: void comp(double arg[10]).
The function could equivalently have been written as.
When used as  function argument, the ﬁrst dimension of an array is simply treated as  pointer.
Any array bound speciﬁed is simply ignored.
This implies that if you want to pass  sequence of elements without losing size information, you should not pass  built-in array.
Instead, you can place the array inside  class as  member (as is done for std::array) or deﬁne  class that acts as  handle (as is done for std::string and std::vector).
If you insist on using arrays directly, you will have to deal with bugs and confusion without getting noticeable advantages in return.
Consider deﬁning  function to manipulate  two-dimensional matrix.
If the dimensions are known at compile time, there is no problem:.
The ﬁrst dimension of an array is irrelevant to ﬁnding the location of an element; it simply states how many elements (here, 3) of the appropriate type (here, int[5]) are present.
For example, look at the layout of ma above and note that by knowing only that the second dimension is 5, we can locate ma[][5] for any.
The ﬁrst dimension can therefore be passed as an argument:.
Fortunately, the argument declaration m[][] is illegal because the second dimension of a multidimensional array must be known in order to ﬁnd the location of an element.
However, the expression m[][] is (correctly) interpreted as ∗(∗(m+)+), although that is unlikely to be what the programmer intended.
A correct solution is:.
Note the use of &[0][0] for the last call; [0] would do because it is equivalent, but  would be a type error.
This kind of subtle and messy code is best hidden.
If you must deal directly with multidimensional arrays, consider encapsulating the code relying on it.
In that way, you might ease the task of the next programmer to touch the code.
Providing a multidimensional array type with a proper subscripting operator saves most users from having to worry about the layout of the data in the array (29_0_2_0_2, 40_0_5_0_2).
The standard vector (31_0_4) doesn't suffer from these problems.
Basically, constexpr's role is to enable and ensure compile-time evaluation, whereas const's primary role is to specify immutability in interfaces.
This section is primarily concerned with the second role: interface speciﬁcation.
Many objects don't hav e their values changed after initialization:.
Symbolic constants lead to more maintainable code than using literals directly in code.
Many pointers are often read through but never written through.
Most function parameters are read but not written to.
To express this notion of immutability after initialization, we can add const to the deﬁnition of an object.
To declare a pointer itself, rather than the object pointed to, to be a constant, we use the declarator operator ∗const instead of plain ∗.
This is particularly useful for function arguments.
By declaring a pointer argument const, the function is prohibited from modifying the object pointed to.
For example: const char∗ strchr(const char∗ p, char c); // ﬁnd ﬁrst occurrence of c in p char∗ strchr(char∗ p, char c); // ﬁnd ﬁrst occurrence of c in p The ﬁrst version is used for strings where the elements mustn't be modiﬁed and returns a pointer to const that does not allow modiﬁcation.
The second version is used for mutable strings.
You can assign the address of  non-const variable to  pointer to constant because no harm can come from that.
However, the address of  constant cannot be assigned to an unrestricted pointer because this would allow the object' value to be changed.
For example: ptg10564057 188 Pointers, Arrays, and References Chapter 7.
Memory acquired by new.
In this case, obviously f() must manage the lifetime of the object it creates on the free store, but in general keeping track of what needs to be deleted in  large program requires simple and consistent strategy.
It is usually  good idea to immediately place  pointer that represents ownership in  resource handle class, such as vector, string, and unique_ptr.
That way, we can assume that every pointer that is not within  resource handle is not an owner and must not be deleted.
Chapter 13 discusses resource management in greater detail.
The type of the pointer determines what can be done to the data through the pointer.
Using  pointer differs from using the name of an object in few ways:.
We use  different syntax, for example, ∗ instead of obj and −>m rather than obj_0_m.
We can make  pointer point to different objects at different times.
We must be more careful when using pointers than when using an object directly:  pointer may be  nullptr or point to an object that wasn't the one we expected.
These differences can be annoying; for example, some programmers ﬁnd f(&x) ugly compared to f(x).
Worse, managing pointer variables with varying values and protecting code against the possibility of nullptr can be  signiﬁcant burden.
Finally, when we want to overload an operator, say +, we want to write x+y rather than &x+&y.
The language mechanism addressing these problems is called  reference.
Like  pointer,  reference is an alias for an object, is usually implemented to hold  machine address of an object, and does not impose performance overhead compared to pointers, but it differs from  pointer in that:.
You access  reference with exactly the same syntax as the name of an object.
A reference always refers to the object to which it was initialized.
There is no "null reference," and we may assume that  reference refers to an object (7_0_7_0_4).
A reference is an alternative name for an object, an alias.
The main use of references is for specify in particular.
For example: template<class T> class vector {.
The ﬁrst two are both called lvalue references.
Here, plus_plusrr does not increment the reference rr; rather, plus_plus is applied to the  to which rr refers, that is, to.
Consequently, the value of  reference cannot be changed after initialization; it always refers to the object it was initialized to denote.
To get  pointer to the object denoted by  reference rr, we can write &rr.
Thus, we cannot have  pointer to  reference.
Furthermore, we cannot deﬁne an array of references.
In that sense,  reference is not an object.
The obvious implementation of  reference is as  (constant) pointer that is dereferenced each time it is used.
It doesn't do much harm to think about references that way, as long as one remembers that  reference isn't an object that can be manipulated the way  pointer is: ptg10564057 Section 7_0_7_0_1 Lvalue References 191 1 ii: &ii : rr: In some cases, the compiler can optimize away a reference so that there is no object representing that reference at run time.
Initialization of a reference is trivial when the initializer is an lvalue (an object whose address you can take; see 6_0_4).
The initializer for a "plain" T& must be an lvalue of type T.
The initializer for a const T& need not be an lvalue or even of type T.
In such cases: [1] First, implicit type conversion to T is applied if necessary (see 10_0_5).
References to variables and references to constants are distinguished because introducing a temporary for a variable would have been highly error-prone; an assignment to the variable would become an assignment to the – soon-to-disappear – temporary.
No such problem exists for references to constants, and references to constants are often important as function arguments (18_0_2_0_4).
A reference can be used to specify a function argument so that the function can change the value of an object passed to it.
The semantics of argument passing are deﬁned to be those of initialization, so when called, increment's argument aa became another name for.
To keep a program readable, it is often best to avoid functions that modify their arguments.
Instead, you can return a value from the function explicitly: ptg10564057 192 Pointers, Arrays, and References Chapter 7.
The increment() notation doesn't giv e a clue to the reader that 's value is being modiﬁed, the way =next() does.
Consequently, "plain" reference arguments should be used only where the name of the function gives a strong hint that the reference argument is modiﬁed.
This is mostly used to deﬁne functions that can be used on both the left-hand and right-hand sides of an assignment.
A Map is a good example.
For example: template<class K, class V> class Map { // a simple map class.
Similarly, I return the value by reference because it too might be of a type that is expensive to copy.
I use a const reference for  because I don't want to modify it and because I might want to use a literal or a temporary object as an argument.
I return the result by non-const reference because the user of a  might very well want to modify the found value.
For example: ptg10564057 Section 7_0_7_0_1 Lvalue References 193 int main() // count the number of occurrences of each word on input {.
Finally, the resulting table of different words in the input, each with its number of occurrences, is printed.
For example, given the input aa bb bb aa aa bb aa aa this program will produce aa: 5 bb: 3 The range- for loop works for this because  deﬁned begin() and end(), just as is done for the standard-library map.
A non-const lvalue reference refers to an object, to which the user of the reference can write.
A const lvalue reference refers to a constant, which is immutable from the point of view of the user of the reference.
An rvalue reference refers to a temporary object, which the user of the reference can (and typically will) modify, assuming that the object will never be used again.
We want to know if a reference refers to a temporary, because if it does, we can sometimes turn an expensive copy operation into a cheap move operation (3_0_3_0_2, 17_0_1, 17_0_5_0_2).
An object (such as a string or a list) that is represented by a small descriptor pointing to a potentially huge amount of information can be simply and cheaply moved if we know that the source isn't going to be used again.
The classic example is a return value where the compiler knows that a local variable returned will never again be used (3_0_3_0_2).
An rvalue reference can bind to an rvalue, but not to an lvalue.
In that, an rvalue reference is exactly opposite to an lvalue reference.
Both a const lvalue reference and an rvalue reference can bind to an rvalue.
However, the purposes will be fundamentally different:.
We use rvalue references to implement a "destructive read" for optimization of what would otherwise have required a copy.
We use a const lvalue reference to prevent modiﬁcation of an argument.
An object referred to by an rvalue reference is accessed exactly like an object referred to by an lvalue reference or an ordinary variable name.
There are two kinds of enumerations: [1] enum classes, for which the enumerator names (e_0_g_0_, red) are local to the enum and their values do not implicitly convert to other types [2] "Plain enums," for which the enumerator names are in the same scope as the enum and their values implicitly convert to integers In general, prefer the enum classes because they cause fewer surprises.
An enumeration is represented by some integer  and each enumerator by some integer We call the  used to represent an enumeration its underlying.
The underlying must be one of the signed or unsigned integer types (6_0_2_0_4); the default is int.
We could be about that: If we considered that too wasteful of space, we could instead use  char:.
A human might notice that  was missing, and  compiler might issue  warning because only three out of four  values are handled.
An enumerator can be initialized by  constant expression (10_0_4) of integral  (6_0_2_0_1).
For example: enum class Printer_ﬂags { acknowledg =1, =2, =4, =8, =16, // }; The values for the Printer_ﬂags enumerators are chosen so that they can be combined by bitwise.
The result of such conversion is undeﬁned unless the  is within the range of the enumeration' underlying.
The last assignments show why there is no implicit conversion from an integer to an enumeration; most integer values do not have  representation in  particular enumeration.
We can extract that value explicitly.
The notion of  range of values for an enumeration differs from the enumeration notion in the Pascal family of languages.
However, bit-manipulation examples that require values outside the set of enumerators to be well deﬁned (_0_g_0_, the Printer_ﬂags example) have  long history in C and Cplus_plus.
The sizeof an enum class is the sizeof of its underlying.
In particular, if the underlying is not explicitly speciﬁed, the size is sizeof(int).
The enumerators of  plain enum are exported into the enum' scope, and they implicitly convert to values of some integer.
Consider the examples from 8_0_4_0_1 with the "class" removed:.
The compiler accepts the ==, which is almost certainly  bug.
The injection of names into an enclosing scope (as enums, but not enum classes or classes, do) is namespace pollution and can be major problem in larger programs (Chapter 14).
You can specify the underlying type of  plain enumeration, just as you can for enum classes.
If you do, you can declare the enumerations without deﬁning them until later.
For example: enum Trafﬁc_light : char { tl_red, tl_yellow, tl_green };.
If you don't specify the underlying type, you can't declare the enum without deﬁning it, and its underlying type is determined by  relatively complicated algorithm: when all enumerators are nonnegative, the range of the enumeration is [0:2k-1] where 2k is the smallest power of 2 for which all enumerators are within the range.
If there are negative enumerators, the range is [-2k:2k-1].
This deﬁnes the smallest bit-ﬁeld capable of holding the enumerator values using the conventional two's complement representation.
The sizeof an enumeration is the sizeof its underlying type.
If the underlying type isn't explicitly speciﬁed, it is some integral type that can hold its range and not larger than sizeof(), unless an enumerator cannot be represented as an  or as an unsigned.
For example, sizeof(1) could be 1 or maybe 4 but not 8 on  machine where sizeof()==4.
For example: enum { =1, arrow_down, arrow_sideways }; We use that when all we need is  set of integer constants, rather than  type to use for variables.
Declarations as Statements.
Selection Statements if Statements; switch Statements; Declarations in Conditions.
Iteration Statements Range-for Statements; for Statements; while Statements; do Statements; Loop exit.
Comments and Indentation.
Advice 9_0_1 Introduction Cplus_plus offers  conventional and ﬂexible set of statements.
Basically all that is either interesting or complicated is found in expressions and declarations.
Note that  declaration is  statement and that an expression becomes  statement when you add  semicolon at its end.
Unlike an expression,  statement does not have  value.
Instead, statements are used to specify the order of execution.
For example: = +c; // expression statement // if-statement = 9; // execute if and only if ==9 , =+c is executed before the if, as everyone would expect.
A compiler may reorder code to improve performance as long as the result is identical to that of the simple order of execution.
A name declared in  block goes out of scope at the end of its block (6_0_3_0_4).
A declaration is  statement and there is no assignment statement or procedure-call statement; assignments and function calls are expressions.
A for-init-statement must be either  declaration or an expression-statement.
Note that both end with  semicolon.
A for-init-declaration must be the declaration of  single uninitialized variable.
The statements for handling exceptions, try-blocks, are described in 13_0_5.
Unless  variable is declared static, its initializer is executed whenever the thread of control passes through the declaration (see also 6_0_4_0_2).
The reason for allowing declarations wherever  statement can be used (and  few other places; 9_0_4_0_3, 9_0_5_0_2) is to enable the programmer to minimize the errors caused by uninitialized variables and to allow better locality in code.
There is rarely  reason to introduce  variable before there is  value for it to hold.
The ability to place declarations after executable code is essential for many constants and for single-assignment styles of programming where  value of an object is not changed after initialization.
For user-deﬁned types, postponing the deﬁnition of  variable until  suitable initializer is available can also lead to better performance.
Input variables are among the few reasonable examples of that:.
I assume that error() does not return; if it does, this code may cause  buffer overﬂow.
Often, push_back() (3_0_2_0_1_0_3, 13_0_6, 31_0_3_0_6) provides  better solution to such examples.
If  condition evaluates to something different from  Boolean, it is – if possible – implicitly converted to  bool.
This implies that any arithmetic or pointer expression can be used as  condition.
For example, if  is an integer, then if () // _0__0_.
Note that  "plain" enum can be implicitly converted to an integer and then to  bool, whereas an enum class cannot (8_0_4_0_1).
For example: ptg10564057 Section 9_0_4_0_1 if Statements 229.
The operators && and || will not evaluate their second argument unless doing so is necessary.
This tests 1<−> only if  is not nullptr.
For choosing between two alternatives each of which produces a value, a conditional expression.
If we need to introduce a name in a branch, it must be enclosed in a block (9_0_2).
For example: ptg10564057 230 Statements Chapter 9.
The expression in the case labels must be a constant expression of integral or enumeration type.
A value may not be used more than once for case-labels in a switch-statement.
This makes the switch-statement easier to read for nontrivial examples.
It typically also leads to the generation of better code because there is no reason to repeatedly check individual values.
Instead, a jump table can be used.
Consider: switch () { // beware.
For example: switch (action) {.
A break is the most common way of terminating a case, but a return is often useful (10_0_2_0_1).
When should a switch-statement have a default.
There is no single answer that covers all situations.
One use is for the default to handle the most common case.
Another common use is the exact opposite: the default: action is simply a way to catch errors; every valid alternative is covered by the cases.
However, there is one case where a default should not be used: if a switch is intended to have one case for each enumerator of an enumeration.
If so, leaving out the default gives the compiler a chance to warn against a set of cases that almost but not quite match the set of enumerators.
For example, this is almost certainly an error:.
Testing for an "impossible"  value is best done separately.
However, it is not possible to bypass an initialization.
Here, if ==1, the thread of execution would bypass the initializations of  and , so f() will not compile.
Unfortunately, because an int needn't be initialized, the declaration of  is not an error.
Howev er, its use is an error: we read an uninitialized variable.
Unfortunately, compilers often give just a warning for the use of an uninitialized variable and cannot reliably catch all such misuses.
As usual, avoid uninitialized variables (6_0_3_0_5_0_1).
If we need a variable within a switch-statement, we can limit its scope by enclosing its declaration and its use in a block.
For an example, see prim() in 10_0_2_0_1.
In particular, it is usually best to delay the deﬁnition of a local variable until one can give it an initial value.
That way, one cannot get into trouble by using the variable before its initial value is assigned.
One of the most elegant applications of these two principles is to declare a variable in a condition.
Here,  is declared and initialized and the value of  after initialization is tested as the value of the condition.
The scope of  extends from its point of declaration to the end of the statement that the condition controls.
For example, had there been an else-branch to the if-statement,  would be in scope on both branches.
However, this opens the scope (literally) for the use of  before its initialization or after its intended useful life:.
A declaration in a condition must declare and initialize a single variable or const.
Note that both end with a semicolon.
The statement of a for-statement (called the controlled statement or the loop body) is executed repeatedly until the condition becomes false or the programmer breaks out of the loop some other way (such as a break, a return, a throw, or a goto).
More complicated loops can be expressed as an algorithm plus a lambda expression (11_0_4_0_2).
The scope of the variable naming the element (here, x) is the for-statement.
The expression after the colon must denote a sequence (a range); that is, it must yield a value for which we can call v_0_begin() and v_0_end() or begin(v) and end(v) to obtain an iterators (4_0_5): [1] the compiler ﬁrst looks for members begin and end and tries to use those.
If a begin or an end is found that cannot be used as a range (e_0_g_0_, because a member begin is a variable rather than a function), the range-for is an error.
If none is found or if what is found cannot be used (e_0_g_0_, because the begin did not take an argument of the sequence' type), the range-for is an error.
The compiler uses v and v+N as begin(v) and end(v) for a built-in array T v[N].
The <iterator> header provides begin(c) and end(c) for built-in arrays and for all standard-library containers.
For sequences of our own design, we can deﬁne begin() and end() in the same way as it is done for standard-library containers (4_0_4_0_5).
The controlled variable, x in the example, that refers to the current element is equivalent to ∗ when using an equivalent for-statement:.
For example, using it you can't touch two elements at the same time and can't effectively traverse two ranges simultaneously.
For that we need a general for-statement.
The loop variable, the termination condition, and the expression that updates the loop variable are explicitly presented "up front" on a single line.
If that initializer is a declaration, the variable (or variables) it introduced is in scope until the end of the for-statement.
It is not always obvious what is the right type to use for a controlled variable in a for loop, so auto often comes in handy: for (auto  = begin(); _0_=end(); plus_plusp) { // _0__0_.
If no initialization is needed, the initializing statement can be empty.
If the expression that is supposed to increment the loop variable is omitted, we must update some form of loop variable elsewhere, typically in the body of the loop.
If the loop isn't of the simple "introduce a loop variable, test the condition, update the loop variable" variety, it is often better expressed as a while-statement.
However, consider this elegant variant: v_0_push_back(); Here, the reading and testing for termination and combined in cin>>, so we don't need an explicit loop variable.
On the other hand, the use of for, rather than while, allows us to limit the scope of the "current element," , to the loop itself (the for-statement).
A for-statement is also useful for expressing a loop without an explicit termination condition:.
A for-statement (9_0_5_0_2) is easily rewritten into an equivalent while-statement and vice versa.
This might be called like this: print_backwards(,strlen()); but it is all too easy to make a horrible mistake.
For example, what if  was the empty string.
In my experience, the do-statement is a source of errors and confusion.
The reason is that its body is always executed once before the condition is evaluated.
However, for the body to work correctly, something very much like the condition must hold even the  time through.
More often than I would have guessed, I have found that condition not to hold as expected either when the program was  written and tested or later after the code preceding it has been modiﬁed.
I also prefer the condition "up front where I can see it_0_" Consequently, I recommend avoiding do-statements.
A break "breaks out of" the ptg10564057 Section 9_0_5_0_5 Loop Exit 237 nearest enclosing switch-statement (9_0_4_0_2) or iteration-statement.
We use a break when we need to leave the loop body "in the middle_0_" Unless it warps the logic of a loop (e_0_g_0_, requires the introduction of an extra varible), it is usually better to have the complete exit condition as the condition of a while-statement or a for-statement.
Sometimes, we don't want to exit the loop completely, we just want to get to the end of the loop body.
A continue skips the rest of the body of an iteration-statement.
This implies that you can use goto to jump both into and out of blocks.
The only restriction is that you cannot jump past an initializer or into an exception handler (13_0_5).
One of the few sensible uses of goto in ordinary code is to break out from a nested loop or switch-statement (a break breaks out of only the innermost enclosing loop or switch-statement).
For example: // do something to a two-dimensional matrix called mn {.
It does not introduce a new  or enter a new.
That makes it the least troublesome and least confusing use of a goto.
Several different consistent styles of indentation are in use.
I see no fundamental reason to prefer one over another (although, like most programmers, I have my preferences, and this book reﬂects them).
The same applies to styles of comments.
Comments can be misused in ways that seriously affect the readability of a program.
The compiler does not understand the contents of a comment, so it has no way of ensuring that a comment.
Most programs contain comments that are incomprehensible, ambiguous, and just plain wrong.
Bad comments can be worse than no comments.
If something can be stated in the language itself, it should be, and not just mentioned in a comment.
This remark is aimed at comments such as these: // variable "v" must be initialized // function "f(int _0__0__0_)" takes two or three arguments Such comments can typically be rendered unnecessary by proper use of Cplus_plus.
Once something has been stated clearly in the language, it should not be mentioned  second time in  comment.
For example: = b+; //  becomes b+ countplus_plus; // increment the counter Such comments are worse than simply redundant.
They increase the amount of text the reader has to look at, they often obscure the structure of the program, and they may be wrong.
Note, however, that such comments are used extensively for teaching purposes in programming language textbooks such as this.
This is one of the many ways  program in  textbook differs from  real program.
A good comment states what  piece of code is supposed to do (the intent of the code), whereas the code (only) states what it does (in terms of how it does it).
Preferably,  comment is expressed at  suitably high level of abstraction so that it is easy for  human to understand without delving into minute details.
A comment for each source ﬁle stating what the declarations in it have in common, references to manuals, the name of the programmer, general hints for maintenance, etc.
A comment for each class, template, and namespace.
A comment for each nontrivial function stating its purpose, the algorithm used (unless it is obvious), and maybe something about the assumptions it makes about its environment.
A comment for each global and namespace variable and constant.
A few comments where the code is nonobvious and/or nonportable.
Very little else For example: // tbl_0_: Implementation of the symbol table.
See Ralston: "A ﬁrst course _0__0__0_" pg 411.
Bjar ne Stroustr up, Feb 29 2013 A well-chosen and well-written set of comments is an essential part of  good program.
Writing good comments can be as difﬁcult as writing the program itself.
It is an art well worth cultivating.
For example: /* remove expensive check if (check(p,q)) error("bad p q") /* should never happen */ ∗/ This nesting should give an error for an unmatched ﬁnal ∗/.
A Desk Calculator The Parser; Input; Low-Level Input; Error Handling; The Driver; Headers; Command-Line Arguments; A Note on Style.
Operator Summary Results; Order of Evaluation; Operator Precedence; Temporary Objects.
Constant Expressions Symbolic Constants; consts in Constant Expressions; Literal Types; Reference Arguments; Address Constant Expressions.
Implicit Type Conversion Promotions; Conversions; Usual Arithmetic Conversions.
Advice 10_0_1 Introduction This chapter discusses expressions in some detail.
In Cplus_plus, an assignment is an expression,  function call is an expression, the construction of an object is an expression, and so are many other operations that go beyond conventional arithmetic expression evaluation.
To giv e an impression of how expressions are used and to show them in context, I ﬁrst present a small complete program, a simple "desk calculator_0_" Next, the complete set of operators is listed and their meaning for builtin types is brieﬂy outlined.
The operators that require more extensive explanation are discussed in Chapter 11.
The user can also deﬁne variables.
For example, given the input = 2_0_5 = pi ∗  ∗ (pi is predeﬁned) the calculator program will write 2_0_5 19_0_635 where 2_0_5 is the result of the ﬁrst line of input and 19_0_635 is the result of the second.
The calculator consists of four main parts: a parser, an input function, a symbol table, and a driver.
Actually, it is a miniature compiler in which the parser does the syntactic analysis, the input function handles input and lexical analysis, the symbol table holds permanent information, and the driver handles initialization, output, and errors.
We could add many features to this calculator to make it more useful, but the code is long enough as it is, and most features would just add code without providing additional insight into the use of Cplus_plus.
The basic units of an expression are numbers, names,  the operators ∗, /, +, − (both unary  binary),  = (assignment).
Names need not be declared before use.
I use a style of syntax analysis called recursive descent; it is a popular  straightforward topdown technique.
In a language such as Cplus_plus, in which function calls are relatively cheap, it is also efﬁcient.
For each production in the grammar, there is a function that calls other functions.
Terminal symbols (for example, end, number, +,  −) are recognized by a lexical analyzer  nonterminal symbols are recognized by the syntax analyzer functions, expr(), term(),  prim().
As soon as both operands of a (sub)expression are known, the expression is evaluated; in a real compiler, code could be generated at this point.
For input, the parser uses a Token_stream that encapsulates the reading of characters  their composition into Tokens.
That is, a Token_stream "tokenizes": it turns streams of characters, such as 123_0_45, into Tokens.
A Token is a {kind-of-token,value} pair, such as {number,123_0_45}, where the 123_0_45 has been turned into a ﬂoating point value.
The main parts of the parser need only to know the  of the Token_stream, ts,  how to get Tokens from it.
To read the next Token, it calls ts_0_get().
To get the most recently read Token (the "current token"), it calls ts_0_current().
In addition to providing tokenizing, the Token_stream hides the actual source of the characters.
We'll see that they can come directly from a user typing to cin, from a program command line, or from any other input stream (10_0_2_0_7).
The deﬁnition of Token looks like this: enum class Kind : char {.
Representing each token by the integer value of its character is convenient  efﬁcient  can be a help to people using debuggers.
This works as long as no character used as input has a value used as an enumerator –  no current character set I know of has a printing character with a singledigit integer value.
The interface to Token_stream looks like this: class Token_stream { public:.
Each parser function takes a bool (6_0_2_0_2) argument, called get, indicating whether the function ptg10564057 244 Expressions Chapter 10 expression  returns the value.
The function expr() handles addition  subtraction.
In a manner typical of higher-level functions in a large program, it calls other functions to do the work.
If  value tested does not match any case label,  default is chosen.
Note that an expression such as 2−3+4 is evaluated as (2−3)+4, as speciﬁed in  grammar.
However, +=term(true)  −=term(true) are not only shorter but also express  intended operation directly.
Each assignment operator is  separate lexical token, so  + = 1; is  syntax error because of  space between  +   =.
Cplus_plus provides assignment  for  binary : + − ∗ / % & | ˆ << >> so that  following assignment  are possible: = += −= ∗= /= %= &= |= = <<= >>= % is  modulo, or remainder, operator; &, |,   are  bitwise logical  , or, exclusive or; <<  >> are   shift  right shift ; 10_0_3 summarizes their meanings.
For  binary operator @ applied to operands of built-in types, an expression @=y means =@y, except that  is evaluated once only.
We therefore test for 0 before dividing  call error() if we detect  zero divisor.
Consequently,  division assignment /= are done if  only if  is nonzero.
Similarly, when  Token that is  name (however deﬁned; see 10_0_2_0_2 10_0_2_0_3) is seen, its value is placed in its string_value.
Note that prim() always reads one more Token than it uses to analyze its primary expression.
In  cases where  parser function simply wants to move ahead to next Token, it doesn't use  return value from ts_0_get().
That's ﬁne because we can get result from ts_0_current().
Had ignoring  return value of get() bothered me, I' hav  either added read() function that just updated current() without returning  value or explicitly "thrown away" result: void(ts_0_g et()).
Before doing anything to  name,  calculator must ﬁrst look ahead to see if it is being assigned to or simply read.
In both cases,  symbol table is consulted.
For example, if  user enters = 6378_0_388; calculator will reach case Kind::name  execute double&  = table[""]; // _0__0_.
Chapter 14  Chapter 15 discuss how to org anize  program as  set of modules.
However, with one exception,  declarations for this calculator example can be ordered so that everything is declared exactly once  before it is used.
This loop of calls must be broken somehow.
A declaration double expr(bool); before  deﬁnition of prim() will do nicely.
To communicate with  person,  program must cope with that person's whims, conventions,  seemingly random errors.
Trying to force person to behave in  manner more suitable for  machine is often (rightly) considered offensive.
These tokens are then  units of input for higher-level routines.
Here, low-level input is done by ts_0_get().
Writing  low-level input routine need not be an everyday task.
Many systems provide standard functions for this.
First we need to see  complete deﬁnition of Token_stream: class Token_stream {.
We initialize a Token_stream with an input stream (4_0_3_0_2, Chapter 38) from which it gets its characters.
The Token_stream implements the convention that it  (and eventually deletes; 3_0_2_0_1_0_2, 11_0_2) an istream passed as a pointer, but not an istream passed as a reference.
This may be a bit elaborate for this simple program, but it is a useful and general technique for classes that hold a pointer to a resource requiring destruction.
A Token_stream holds three values: a pointer to its input stream (), a Boolean (), indicating ownership of the input stream, and the current token (ct).
I gav  ct a default value because it seemed sloppy not to.
People should not call current() before get(), but if they do, they get a well-deﬁned Token.
I chose Kind::end as the initial value for ct so that a program that misuses current() will not get a value that wasn't on the input stream.
I present Token_stream::g et() in two stages.
First, I provide a deceptively simple version that imposes a burden on the user.
Next, I modify it into a slightly less elegant, but much easier to use, version.
The idea for get() is to read a character, use that character to decide what  of token needs to be composed, read more characters when needed, and then return a Token representing the characters read.
Assignment is an operator, and the result of the assignment is the value of the variable assigned to.
This allows me to assign the value Kind::end to curr_tok and return it in the same statement.
Having a single statement rather than two is useful in maintenance.
If the assignment and the return became separated in the code, a programmer might update the one and forget to update the other.
That's good if we care about the last two members of the Token and not so good if we are worried about performance.
Neither is the case here, but in general dealing with complete objects is clearer and less error-prone than manipulating data members individually.
The cases below giv  examples of the other strategy.
Consider some of the cases separately before considering the complete function.
The expression terminator, ';', the parentheses, and the operators are handled simply by returning their values: ';': // end of expression; print '∗': '/': '+': '−': '(': ')': '=': return ={<Kind>()}; The  (11_0_5_0_2) is needed because there is no implicit conversion from char to Kind (8_0_4_0_1); only some characters correspond to Kind values, so we have to "certify" that in this does.
Numbers are handled like this: '0':  '1':  '2':  '3':  '4':  '5':  '6':  '7':  '8':  '9': '_0_': ptg10564057 Section 10_0_2_0_2 Input 249 −>putback(); // put the ﬁrst digit (or _0_) back into the input stream ∗ >> _0_number_value; // read the number into _0_=Kind::number; return ; Stacking  labels horizontally rather than vertically is generally not a good idea because this arrangement is harder to read.
However, having one line for each digit is tedious.
Because operator >> is already deﬁned for reading ﬂoating-point values into a double, the code is trivial.
First the initial character (a digit or a dot) is put back into cin.
Then, the ﬂoating-point value can be read into _0_number_value.
If the token is not the end of input, an operator, a punctuation character, or a  number, it must be a.
A  is handled similarly to a number: default: // ,  =, or error if (isalpha()) { −>putback();.
Operator >> applied to a string (in this , string_value) reads until it hits whitespace.
This is less than ideal, so we will return to this problem in 10_0_2_0_3.
Here, ﬁnally, is the complete input function:.
The conversion of an  to its Token value is trivial because the  of an  was deﬁned as the integer value of the  (10_0_2_0_1).
It is tedious to remember to add a semicolon after an expression in order to get its value printed, and having a  terminated by whitespace only is a real nuisance.
For example, =7 is an identiﬁer – rather than the identiﬁer followed by the  = and the number 7.
To get what we (usually) want, we would have to add whitespace after :  =7.
Both problems are solved by replacing the type-oriented default input operations in get() with code that reads individual characters.
First, we'll make a newline equivalent to the semicolon used to mark the end-of-expression:.
The call ip−>get() reads a single character from the input stream succeeds if no character can be read from cin; in this , Kind::end is returned to terminate the calculator session.
The test is implemented as a table lookup, so using isspace() is much faster than testing for the individual whitespace characters.
Similar functions test if a character is a digit (isdigit()), a letter (isalpha()), or a digit or letter (isalnum()).
After whitespace has been skipped, the next character is used to determine what  of lexical token is coming.
The problem caused by >> reading into a string until whitespace is encountered is solved by reading one character at a time until a character that is not a letter or a digit is found: default: // , =, or error if (isalpha()) {.
Constructing programs so that improvements can be implemented through local modiﬁcations only is an important design aim.
You might worry that adding characters to the end of a string one by one would be inefﬁcient.
It would be for very long strings, but all modern string implementations provide the "small string optimization" (19_0_3_0_3).
That means that handling the  of strings we are likely to use as names in a calculator (or even in a compiler) doesn't inv olve any inefﬁcient operations.
In particular, using a short string doesn't require any use of free store.
The maximum number of characters for a short string is implementation-dependent, but 14 would be a good guess.
However, for this program, a simple  handling strategy sufﬁces.
The () function simply counts the errors, writes out an  message,.
The stream  is an unbuffered output stream usually used to report errors (38_0_1).
The reason for returning a value is that errors typically occur in the middle of the evaluation of an expression, so we should either abort that evaluation entirely or return a value that is unlikely to ptg10564057 252 Expressions Chapter 10 kept track of the line numbers, () could have informed the user approximately where the occurred.
This would be useful when the calculator is used noninteractively.
A more stylized and general -handling strategy would separate  detection from recovery.
This can be implemented using exceptions (see 2_0_4_0_3_0_1, Chapter 13), but what we have here is quite suitable for a 180-line calculator.
I decided on two functions: main() to do setup and  reporting and calculate() to handle the actual calculation:.
Conventionally, main() returns zero if the program terminates normally and nonzero otherwise (2_0_2_0_1).
Returning the number of errors accomplishes this nicely.
As it happens, the only initialization needed is to insert the predeﬁned names into the symbol table.
The primary task of the main loop (in calculate()) is to read expressions and write out the answer.
This is achieved by the line: << expr() << '\n'; The argument  tells expr() that it does not need to call ts_0_get() to read a token on which to work.
Testing for Kind::end ensures that the loop is correctly exited when ts_0_get() encounters an input or an end-of-ﬁle.
A break-statement exits its nearest enclosing switch-statement or loop (9_0_5).
Testing for Kind::print (that is, for '\n' and ';') relieves expr() of the responsibility for handling empty expressions.
A continue-statement is equivalent to going to the very end of a loop.
Therefore, appropriate headers must be #included to complete the program:.
Chapter 14 and Chapter 15 discuss ways of organizing this calculator into modules using namespaces and how to org anize it into source ﬁles.
My most common use was to evaluate a single expression.
If that expression could be presented as a command-line argument, a few keystrokes could be avoided.
A program starts by calling main() (2_0_2_0_1, 15_0_4).
When this is done, main() is given two arguments specifying the number of arguments, conventionally called , and an array of arguments, conventionally called argv.
The arguments are C-style character strings (2_0_2_0_5, 7_0_3), so the type of argv is char∗[+1].
The  of the program (as it occurs on the command line) is passed as argv[0], so  is always at least 1.
The list of arguments is zero-terminated; that is, argv[]==0.
For example, for the command dc 150/1_0_1934 the arguments have these values: 2 : argv: 0 Because the conventions for calling main() are shared with C, C-style arrays and strings are used.
The idea is to read from the command string in the same way that we read from the input stream.
A stream that reads from a string is unsurprisingly called an istringstream (38_0_2_0_2).
So to calculate expressions presented on the command line, we simply have to get our Token_stream to read from an appropriate istringstream: ptg10564057 254 Expressions Chapter 10.
It would be easy to modify main() to accept several command-line arguments, but this does not appear to be necessary, especially as several expressions can be passed as a single argument:.
Some characters from the basic source character set (6_0_1_0_2), such as |, are not convenient to type on some keywords.
Also, some programmers ﬁnd it odd to use of symbols, such as && and ˜, for basic logical operations.
Consequently,  set of alternative representation are provided as keywords: and and_eq bitand bitor compl not not_eq or or_eq xor xor_eq & &= & | ˜.
The overall aim is  produce  result of the "largest" operand type.
For example, if  binary operator has  ﬂoating-point operand, the computation is done using ﬂoating-point arithmetic  the result is  ﬂoating-point value.
Similarly, if it has  long operand, the computation is done using long integer arithmetic,  the result is  long.
Operands that are smaller than an int (such as bool  char) are converted  int before the operator is applied.
The meaning  result type of user-deﬁned  are determined by their declarations (18_0_2).
Where logically feasible, the result of an operator that takes an lvalue operand is an lvalue denoting that lvalue operand.
Preserving lvalues in this way allows greater ﬂexibility in using.
This is particularly useful when writing code that needs  work uniformly  efﬁciently with both built-in  user-deﬁned types (e_0_g_0_, when writing templates or programs that generate Cplus_plus code).
The result of sizeof is of an unsigned integral type called size_t deﬁned in <cstddef>.
The result of pointer subtraction is of a signed integral type called ptrdiff_t deﬁned in <cstddef>.
Implementations do not have  check for arithmetic overﬂow  hardly any do.
This will (eventually) try  increase  past the largest integer.
What happens then is undeﬁned, but typically the value "wraps around"  a neg ative number (on my machine −2147483648).
Similarly, the effect of dividing by zero is undeﬁned, but doing so usually causes abrupt termination of the program.
In particular, underﬂow, overﬂow,  division by zero do not throw standard exceptions (30_0_4_0_1_0_1).
In particular, you cannot assume that the expression is evaluated left--right.
For example: int  = f(2)+g(3); // undeﬁned whether f() or g() is called ﬁrst.
Compilers can warn about such ambiguities.
Unfortunately, most do not, so be careful not write an expression that reads or writes an object more than once, unless it does so using  single ptg10564057 260 Expressions Chapter 10 operator that makes it well deﬁned, such as plus_plus  +=, or explicitly express sequencing using , (comma), &&, or ||.
The  , (comma), && (logical ),  || (logical or) guarantee that their left-hand operand is evaluated before their right-hand operand.
For example, =(=2,+1) assigns 3.
Examples of the use of ||  && can be found in 10_0_3_0_3.
For built-in types, the second operand of && is evaluated only if its ﬁrst operand is true,  the second operand of || is evaluated only if its ﬁrst operand is false; this is sometimes called short-circuit evaluation.
Note that the sequencing operator , (comma) is logically different from the comma used  separate arguments in  function call.
The call of f1 has two arguments, []  iplus_plus,  the order of evaluation of the argument expressions is undeﬁned.
Order dependence of argument expressions is very poor style  has undeﬁned behavior.
The call of f2 has only one argument, the comma expression ([],iplus_plus), which is equivalent  iplus_plus.
That is confusing, so that too should be avoided.
Parentheses can be used  force grouping.
For example, ∗/c means (∗)/c, so parentheses must be used  get ∗(/c); ∗(/c) may be evaluated as (∗)/c only if the user cannot tell the difference.
In particular, for many ﬂoating-point computations ∗(/c)  (∗)/c are signiﬁcantly different, so  compiler will evaluate such expressions exactly as written.
However, parentheses should be used whenever  programmer is in doubt about those rules.
Use of parentheses becomes more common as the subexpressions become more complicated, but complicated subexpressions are  source of errors.
Therefore, if you start feeling the need for parentheses, you might consider breaking up the expression by using an extra variable.
There are cases when the operator precedence does not result in the "obvious" interpretation.
Fortunately, it is easy enough for  compiler warn about most such mistakes.
In this case, parentheses are important: ((&) == 0) // _0__0_.
It is worth noting that the following does not work the way  mathematician might expect: ptg10564057 Section 10_0_3_0_3 Operator Precedence 261 (0 <=  <= 99) // _0__0_.
This is legal, but it is interpreted  (0<=)<=99, where the result  the ﬁrst comparison is either true or false.
This Boolean value is then implicitly converted  1 or 0, which is then compared  99, yielding true.
To test whether  is in the range 0_0__0_99, we might (0<= && <=99) // _0__0_.
A common mistake for novices is   = (assignment) instead  == (equals) in  condition: //.
Again, it is easy for  compiler warn about most such mistakes –  many do.
I do not recommend warping your style  compensate for compilers with weak warnings.
In particular, I don't consider this style worthwhile: (7 == ) // tr y  protect against misuse  =; not recommended 10_0_3_0_4 Temporary Objects Often, the compiler must introduce an object  hold an intermediate result  an expression.
For example, for =+y∗z the result  y∗z has  be put somewhere before it is added.
For built-in types, this is all handled so that  temporary object (often referred   just  temporary) is invisible  the user.
Howev er, for  user-deﬁned type that holds  resource knowing the lifetime temporary can be important.
Unless bound to  reference or used to initialize  named object, temporary object is destroyed at the end  the full expression in which it was created.
A full expression is an expression that is not  subexpression  some other expression.
The standard-library string has  member () (36_0_3) that returns  C-style pointer to  zeroterminated array  characters (2_0_2_0_5, 43_0_4).
Also, the operator + is deﬁned to mean string concatenation.
These are useful facilities for strings.
However, in combination they can cause obscure.
Probably, your ﬁrst reaction is "But don't do that_0_"  I agree.
However, such code does get written, so it is worth knowing how it is interpreted.
A temporary string object is created to hold s1+s2.
Next,  pointer to  C-style string is extracted from that object.
Then – at the end  the expression – the temporary object is deleted.
However, the C-style string returned by () was allocated  part  the temporary object holding s1+s2,  that storage is not guaranteed to exist after that temporary is destroyed.
Consequently, points to deallocated storage.
The output operation << might work  expected, but that would be sheer luck.
A compiler can detect  warn against many variants  this problem.
The condition will work  expected the full expression in which the temporary holding 2+3 is created is the condition itself.
However, that temporary is destroyed before the controlled statement is entered, so any there is not guaranteed to work.
Please note that in this case,  in many others, the problems with temporaries arose from using high-level data type in  low-level way.
A cleaner programming style yields  more understandable program fragment  avoids the problems with temporaries completely.
The temporary is destroyed when "its" reference or named object goes out  scope.
Remember that returning  reference to  local variable is an error (12_0_1_0_4)  that  temporary object cannot be bound to  non-const lvalue reference (7_0_7).
A temporary object can also be created explicitly in an expression by invoking  constructor (11_0_5_0_1).
Basically, constexpr' role is to enable  ensure compile-time evaluation, whereas const' ptg10564057 Section 10_0_4 Constant Expressions 263 primary role is to specify immutability in interfaces.
This section is primarily concerned with the ﬁrst role: compile-time evaluation.
A constant expression is an expression that  compiler can evaluate.
It cannot  values that are not known at compile time and it cannot have side effects.
Ultimately,  constant expression must start out with an integral value (6_0_2_0_1),  ﬂoating-point value (6_0_2_0_5), or an enumerator (8_0_4), and we can combine those using operators and constexpr functions that in turn produce values.
In addition, some addresses can be used in some forms  constant expressions.
For simplicity, I discuss those separately in 10_0_4_0_5.
There are  variety  reasons why someone might want  named constant rather than  literal or value stored in  variable: [1] Named constants make the code easier to understand and maintain.
Also, data in read-only memory is immune to most system crashes.
Note that reasons [1], [2], [5], and (partly) [4] are logical.
We don't just  constant expressions an obsession with performance.
Often, the reason is that  constant expression is  more direct representation  our system requirements.
As part  the deﬁnition   data item (here, I deliberately avoid the word "variable"), constexpr expresses the need for compile-time evaluation.
If the initializer for  constexpr can't be evaluated at compile time, the compiler will give an error.
For example: int 1 = 7;.
A clever compiler could deduce that the value  1 in the initializer for 3 was 7.
Howev er, we prefer  to rely on degrees  cleverness in compilers.
In a large program, determining the values variables at compile time is typically either very difﬁcult or impossible.
We can use integer, ﬂoating-point, and enumeration values.
We can use any operator that doesn't modify state (e_0_g_0_, +, _0_:, and [], but  = or plus_plus).
We can use constexpr functions (12_0_1_0_6) and literal types (10_0_4_0_3) to provide a signiﬁcant level of type safety and expressive power.
It is almost unfair to compare this to what is commonly done with macros (12_0_6).
The conditional-expression operator _0_: is the means of selection in a constant expression.
For example, we can compute an integer square root at compile time:.
The condition of a _0_: is evaluated and then the selected alternative is evaluated.
The alternative selected is  evaluated and might even  be a constant expression.
Similarly, operands of && and || that are  evaluated need  be constant expressions.
This feature is primarily useful in constexpr functions that are sometimes used as constant expressions and sometimes.
Consider: ptg10564057 320 Functions Chapter 12 <class T>.
It is not possible to eliminate every form of confusion in overload resolution (for example, see 4_0_4, 17_0_3_0_4_0_1), but giving  parameters priority for {}-list arguments seems to minimize confusion.
The call f({1,"MKS"}) was an example of that.
Note that these rules apply to std::<T> arguments only.
There are no special rules for std::<T>& or for other types that just happen to be called  (in some other scope).
To implement such interfaces, we have three choices: [1] Use  variadic  (28_0_6): this allows us to handle an arbitrary number of arbitrary types in  type-safe manner by writing  small  metaprogram that interprets the argument list to determine its meaning and take appropriate actions.
This allows us to handle an arbitrary number of arguments of  single type in  type-safe manner.
In many contexts, such homogeneous lists are the most common and important case.
This solution is not inherently type-safe and can be hard to use with sophisticated user-deﬁned types.
However, this mechanism has been used from the earliest days of C.
The ﬁrst two mechanisms are described elsewhere, so I describe only the third mechanism (even though I consider it inferior to the others for most uses).
For example: int printf(const char∗ _0__0__0_);.
Such  function must rely on information not available to the compiler when interpreting its argument list.
In the case of printf(), the ﬁrst argument is  format string containing special character sequences that allow printf() to handle other arguments correctly; %s means "expect  char∗ argument" and % means "expect an int argument_0_" Howev er, the compiler cannot in general ensure that the expected arguments are really provided in  call or that an argument is of the expected type.
This is not valid code, but most compilers will not catch this error.
At best, it will produce some strange-looking output (try it_0_).
In that case,  char or short is passed as an int and  ﬂoat is passed as  double.
This is not necessarily what the programmer expects.
A well-designed program needs at most  few functions for which the argument types are not completely speciﬁed.
Overloaded functions, functions using default arguments, functions taking arguments, and variadic templates can be used to take care of type checking in most cases when one would otherwise consider leaving argument types unspeciﬁed.
Only when both the number of arguments and the types of arguments vary and  variadic  solution is deemed undesirable is the ellipsis necessary.
The most common use of the ellipsis is to specify an interface to C library functions that were deﬁned before Cplus_plus provided alternatives:.
A standard set of macros for accessing the unspeciﬁed arguments in such functions can be found in <cstdarg>.
Consider writing an error function that takes one integer argument indicating the severity of the error followed by an arbitrary number of strings.
The idea is to compose the error message by passing each word as  separate C-style string argument.
The list of string arguments should be terminated by the null pointer:.
I always pass argv[0] because that, conventionally, is the name of the program.
Note that using the integer 0 as the terminator would not have been portable: on some implementations, the integer 0 and the null pointer do not have the same representation (6_0_2_0_8).
This illustrates the subtleties and extra work that face the programmer once type checking has been suppressed using the ellipsis.
First, a va_list is deﬁned and initialized by a call of va_star t().
The macro va_star t takes the name of the va_list and the name of the last formal argument as arguments.
The macro va_arg() is used to assumes that an actual argument of that type has been passed, but it typically has no way of ensuring that.
Before returning  a function in which va_star t() has been used, va_end() must be called.
The reason is that va_star t() may modify the stack in such a way that a return cannot successfully be done; va_end() undoes any such modiﬁcations.
Alternatively, error() could have been deﬁned using a standard-library :.
If I didn't hav e to mimic C style, I would further simplify the code by passing a container as a single argument: void error(int severity, const <string>& err) // almost as before.
That would allow later improvements of error().
The use of the <string> is far less error-prone than any use of an unspeciﬁed number of arguments.
In particular, functions that construct objects (16_0_2_0_5) often provide several options for ﬂexibility.
Consider class complex  3_0_2_0_1_0_1: class complex { double re, im;.
The actions of complex' constructors are quite trivial, but logically there is something odd about having three functions (here, constructors) doing essentially the same task.
Also, for many classes, ptg10564057 Section 12_0_2_0_5 Default Arguments 325 constructors do more work and the repetitiveness is common.
We could deal with the repetitiveness by considering one of the constructors "the real one" and forward to that (17_0_4_0_3): complex(double , double ) :re{}, im{} {} // construct complex  two scalars.
Say we wanted to add some debugging, tracing, or statistics-gathering code to complex; we now have a single place to do so.
However, this can be abbreviated further: complex(double  ={}, double  ={}) :re{}, im{} {} // construct complex  two scalars This makes it clear that if a user supplies fewer than the two arguments needed, the default is used.
The intent of having a single constructor plus some shorthand notation is now explicit.
A default argument is type checked at the time of the function declaration and evaluated at the time of the call.
For example: class  {.
Using  same name for operations on different types is called overloading.
The technique is already used for  basic operations in Cplus_plus.
That is, there is only one name for addition, +, yet it can be used to add values of integer and ﬂoating-point types and combinations of such types.
This idea is easily extended to functions deﬁned by  programmer.
For example: void print(); // print an void print(const ∗); // print a C-style string As far as  compiler is concerned,  only thing functions of  same name have in common is that name.
Presumably,  functions are in some sense similar, but  language does not constrain or aid  programmer.
Thus, overloaded function names are primarily a notational convenience.
This convenience is  for functions with conventional names such as sqrt, print, and open.
When a name is semantically , this convenience becomes essential.
This happens, for example, with operators such as +, ∗, and <<, in  case of constructors (16_0_2_0_5, 17_0_1), and in generic programming (4_0_5, Chapter 32).
Templates provide a systematic way of deﬁning sets of overloaded functions (23_0_5).
This is done by comparing  types of  actual arguments with  types of  parameters of all functions in scope called fct.
The idea is to invoke  function that is  best match to arguments and give a compile-time error if no function is  best match.
The resolution rules are this elaborate primarily to take into account  elaborate C and Cplus_plus rules for built-in numeric types (10_0_5).
The reason to distinguish between conversions and promotions is that we want to prefer safe promotions, such as  to , over unsafe conversions, such as  to.
Overload resolution is independent of  order of declaration of  functions considered.
Function templates are handled by applying  overload resolution rules to  result of specialization based on a set of arguments (23_0_5_0_3).
There are separate rules for overloading when a {}-list is used (initializer lists take priority; 12_0_2_0_3, 17_0_3_0_4_0_1) and for rvalue reference template arguments (23_0_5_0_2_0_1).
Overloading relies on a relatively complicated set of rules, and occasionally a programmer will be surprised which function is called.
Consider  alternative to overloading.
Often, we need similar operations performed on objects of several types.
Without overloading, we must deﬁne several functions with different names: ptg10564057 328 Functions Chapter 12.
Compared to  overloaded print(), we hav e to remember several names and remember to use those correctly.
This can be tedious, defeats attempts to do generic programming (4_0_5), and generally encourages  programmer to focus on relatively low-level type issues.
Because there is no overloading, all standard conversions apply to arguments to these functions.
It can also lead to errors.
In  previous example, this implies that only one of  four calls with doubtful semantics is caught by  compiler.
In particular, two calls rely on error-prone narrowing (2_0_2_0_2, 10_0_5).
Thus, overloading can increase  chances that an unsuitable argument will be rejected by compiler.
The reason is to keep resolution for an individual operator (18_0_2_0_1, 18_0_2_0_5) or function call context-independent.
If  return type were taken into account, it would no longer be possible to look at a call of sqrt() in isolation and determine which function was called.
By default, that means  functions of a single scope; functions declared in different non-namespace scopes do not overload.
For example: ptg10564057 Section 12_0_3_0_3 Overloading and Scope 329.
Clearly, f() would have been  best match for f(1), but only f(double) is in scope.
In such cases, local declarations can be added or subtracted to get  desired behavior.
As always, intentional hiding can be a useful technique, but unintentional hiding is a source of surprises.
A base class and a derived class provide different scopes so that overloading between a base class function and a derived class function doesn't happen by default.
When overloading across class scopes (20_0_3_0_5) or namespace scopes (14_0_4_0_5) is wanted, usingdeclarations or using-directives can be used (14_0_2_0_2).
Argument-dependent lookup (14_0_2_0_4) can also lead to overloading across namespaces.
A function that is the best match for one argument and a better or equal match for all other arguments is called.
If no such function exists, the call is rejected as ambiguous.
The call is ambiguous because 2_0_0 is the best match for the ﬁrst argument of pow(double ,double) and 2 is the best match for the second argument of pow(int,int).
Often the problem can be solved by adding a version that resolves ambiguities.
For example, adding inline void f1(int n) { f1(long(n)); } would resolve all ambiguities similar to f1() in favor of the larger type long int.
One can also add an explicit type conversion to resolve a speciﬁc call.
For example: f2(<int∗>(0)); However, this is most often simply an ugly stopgap.
Soon another similar call will be made and have to be dealt with.
Some Cplus_plus novices get irritated by the ambiguity errors reported by the compiler.
More experienced programmers appreciate these error messages as useful indicators of design errors.
Some of these expectations are expressed in the argument types, but others depend on the actual values passed and on relationships among ptg10564057 Section 12_0_4 Pre- and Postconditions 331 argument values.
The compiler and linker can ensure that arguments are of the right types, but it is up to the programmer to decide what to do about "bad" argument values.
We call logical criteria that are supposed to hold when a function is called preconditions, and logical criteria that are supposed to hold when a function returns its postconditions.
For example: /* calculate the area of a rectangle precondition: len and wid are positive postcondition: the return value is positive postcondition: the return value is the area of a rectange with sides len and wid */ { return len∗wid; } Here, the statements of the pre- and postconditions are longer than the function body.
This may seem excessive, but the information provided is useful to the implementer, to the users of area(), and to testers.
For example, we learn that 0 and −12 are not considered valid arguments.
Furthermore, we note that we could pass a couple of huge values without violating the precondition, but if len∗wid overﬂows either or both of the postconditions are not met.
Yes, but what if the caller doesn't.
If so, how is an error to be handled.
There are several possible answers to these questions.
It is easy for a caller to make a mistake and fail to establish a precondition.
It is also difﬁcult for an implementer to cheaply, efﬁciently, and completely check preconditions.
We would like to rely on the caller to get the preconditions right, but we need a way to test for correctness.
For now, just note that some pre- and postconditions are easy to check (e_0_g_0_, len is positive and len∗wid is positive).
Others are semantic in nature and hard to test directly.
For example, how do we test "the return value is the area of a rectangle with sides len and wid".
This is a semantic constraint because we have to know the meaning of "area of a rectangle," and just trying to multiply len and wid again with a precision that precluded overﬂow could be costly.
It seems that writing out the pre- and postconditions for area() uncovered a subtle problem with this very simple function.
Writing out pre- and postconditions is a great design tool and provides good documentation.
Mechanisms for documenting and enforcing conditions are discussed in 13_0_4.
If a function depends only on its arguments, its preconditions are on its arguments only.
Howev er, we hav e to be careful about functions that depend on non-local values (e_0_g_0_, a member function that depends on the state of its object).
In essence, we have to consider every nonlocal value read as an implicit argument to a function.
Similarly, the postcondition of a function without side effects simply states that a value is correctly computed, but if a function writes to nonlocal objects, its effect must be considered and documented.
If a postconditon fails, there was either an unchecked precondition or a programming error.
We can have a pointer to a function just as we can have a pointer to an object.
However, for a variety of reasons – some related to machine architecture and others to system design – a pointer to function does not allow the code to be modiﬁed.
There are only two things one can do to a function: call it and take its address.
The pointer obtained by taking the address of a function can then be used to call the function.
For example: void error(string s) { /* _0__0_.
The rules for argument passing are the same for calls directly to a function and for calls to a function through a pointer.
You can convert a pointer to function to a different pointer-to-function type, but you must cast the resulting pointer back to its original type or strange things may happen:.
Macros can even be variadic.
For example: err_print("The ",54); The ellipsis (_0__0__0_) means that __VA_ARGS__ represents the arguments actually passed as  string, so the output is: error: The  54 12_0_6_0_1 Conditional Compilation One use of macros is almost impossible to avoid.
The directive #ifdef IDENTIFIER does nothing if IDENTIFIER is deﬁned, but if it is not, the directive causes all input to be ignored until  #endif directive is seen.
For example: f( #ifdef arg_two ,int #endif ); Unless  macro called arg_two has been #deﬁned , this produces: int f(int ); This example confuses tools that assume sane behavior from the programmer.
Names of the macros used to control #ifdef should be chosen carefully so that they don't clash with ordinary identiﬁers.
This innocent-looking source text will cause some confusion should someone write: #deﬁne arg_two Unfortunately, common and unavoidable headers contain many dangerous and unnecessary macros.
Its value is 201103L in  Cplus_plus11 program; previous Cplus_plus standards have lower values.
In addition,  few macros are conditionally deﬁned by the implementation:.
For example: <<  << "() in  " <<  << " on  " <<  << "\n"; In addition, most Cplus_plus implementations allow  user to deﬁne arbitrary macros on the command or in some other form of compile-time environment.
For example, NDEBUG is deﬁned unless the compilation is done in (some implementation-speciﬁc) "debug mode" and is used by the assert() macro (13_0_4).
This can be useful, but it does imply that you can't be sure of the meaning of  program just by reading its source text.
Obviously, the standard cannot specify how such facilities are provided, but one standard syntax is of tokens preﬁxed with the preprocessor directive #pragma.
For example: #pragma foo bar 666 foobar If possible, #pragmas are best avoided.
Error Handling Exceptions; Traditional Error Handling; Muddling Through; Alternative Views of Exceptions; When You Can't Use Exceptions; Hierarchical Error Handling; Exceptions and Efﬁciency.
Resource Management Finally.
Throwing and Catching Exceptions Throwing Exceptions; Catching Exceptions; Exceptions and Threads.
A vector Implementation A Simple vector; Representing Memory Explicitly; Assignment; Changing Size.
Advice 13_0_1 Error Handling This chapter presents error handling using exceptions.
For effective error handling, the language mechanisms must be used based on a strategy.
Consequently, this chapter presents the exceptionsafety guarantees that are central to recovery from run-time errors and the Resource Acquisition Is Initialization (RAII) technique for resource management using constructors and destructors.
Both the exception-safety guarantees and RAII depend on the speciﬁcation of invariants, so mechanisms for enforcement of assertions are presented.
The language facilities and techniques presented here address problems related to the handling of errors in software; the handling of asynchronous events is a different topic.
Such parts of a program are often separately developed.
Consequently, I often refer to a part of a program that is invoked to perform a task as "a library_0_" A library is just ordinary code, but in the context of a discussion of error handling it is worth remembering that a library designer often cannot even know what kind of programs the library will become part of:.
The author of a library can detect a run-time error but does not in general have any idea what to do about it.
The user of a library may know how to cope with a run-time error but cannot easily detect it (or else it would have been handled in the user's code and not left for the library to ﬁnd).
The discussion of exceptions focuses on problems that need to be handled in long-running systems, systems with stringent reliability requirements, and libraries.
Different kinds of programs have different requirements, and the amount of care and effort we expend should reﬂect that.
For example, I would not apply every technique recommended here to a two-page program written just for myself.
However, many of the techniques presented here simplify code, so I would use those.
A function that cannot cope with a problem throws an exception, hoping that its (direct or indirect) caller can handle the problem.
A function that wants to handle a kind of problem indicates that by catching the corresponding exception (2_0_4_0_3_0_1):.
A calling component indicates the kinds of failures that it is willing to handle by specifying those exceptions in a catch-clause of a try-block.
A called component that cannot complete its assigned task reports its failure to do so by throwing an exception using a throw-expression.
Consider a simpliﬁed and stylized example:.
If do_task() can do that job and return a correct , is prepared to handle a Some_error, but some other kind of exception may be thrown.
For example, do_task() may call other functions to do a lot of subtasks, and one of those may throw because it can't do its assigned subtask.
An exception different from Some_error indicates a failure of taskmaster() to do its job and must be handled by whatever code invoked taskmaster().
A called function cannot just return with an indication that an error happened.
If the program is to continue working (and not just print an error message and terminate), the returning function must leave the program in a good state and not leak any resources.
The exception-handling mechanism is integrated with the constructor/destructor mechanisms and the concurrency mechanisms to help ensure that (5_0_2).
The exception-handling mechanism:.
Is an alternative to the traditional techniques when they are insufﬁcient, inelegant, or errorprone.
Is complete; it can be used to handle all errors detected by ordinary code.
Supports a more regular style of error handling, thus simplifying cooperation between separately written program fragments An exception is an object thrown to represent the occurrence of an error.
It can be of any type that can be copied, but it is strongly recommended to use only user-deﬁned types speciﬁcally deﬁned for that purpose.
That way, we minimize the chances of two unrelated libraries using the same value, say 17, to represent different errors, thereby throwing our recovery code into chaos.
An exception is caught by code that has expressed interest in handling a particular type of exception (a catch-clause).
Thus, the simplest way of deﬁning an exception is to deﬁne a class speciﬁcally for a kind of error and throw that.
If that gets tedious, the standard library deﬁnes a small hierarchy of exception classes (13_0_5_0_2).
An exception can carry information about the error it represents.
Its type represents the kind of error, and whatever data it holds represents the particular occurrence of that error.
For example, the standard-library exceptions contain a string value, which can be used to transmit information such as the location of the throw (13_0_5_0_2).
Each conventional approach has problems, and none are general: ptg10564057 346 Exception Handling Chapter 13.
Terminate the program.
This is a pretty drastic approach.
For example: if (something_wrong) exit(1); For most errors, we can and must do better.
For example, in most situations we should at least write out a decent error message or log the error before terminating.
In particular, a library that doesn't know about the purpose and general strategy of the program in which it is embedded cannot simply exit() or abort().
A library that unconditionally terminates cannot be used in a program that cannot afford to crash.
Return an error value.
This is not always feasible because there is often no acceptable "error value_0_" For example: int get_int(); // get next integer from input For this input function, every int is a possible , so there can be no integer value representing an input failure.
At a minimum, we would have to modify get_int() to return a pair of values.
Even where this approach is feasible, it is often inconvenient because every call must be checked for the error value.
This can easily double the size of a program (13_0_1_0_7).
Also, callers often ignore the possibility of errors or simply forget to test a return value.
Consequently, this approach is rarely used systematically enough to detect all errors.
For example, printf() (43_0_3) returns a negative value if an output or encoding error occurred, but programmers essentially never test for that.
Finally, some operations simply do not have return values; a constructor is the obvious example.
Return a legal value and leave the program in an "error state_0_' ' This has the problem that the calling function may not notice that the program has been put in an error state.
For example, many standard C library functions set the nonlocal variable errno to indicate an error (43_0_4, 40_0_3): double  = sqrt(−1_0_0); Here, the value of  is meaningless and errno is set to indicate that −1_0_0 isn't an acceptable argument for a ﬂoating-point square root function.
However, programs typically fail to set and test errno and similar nonlocal state consistently enough to avoid consequential errors caused by values returned from failed calls.
Furthermore, the use of nonlocal variables for recording error conditions doesn't work well in the presence of concurrency.
Call an error-handler function.
For example: if (something_wrong) something_handler(); // and possibly continue here This must be some other approach in disguise because the problem immediately becomes "What does the error-handling function do_0_" Unless the error-handling function can completely resolve the problem, the error-handling function must in turn either terminate the program, return with some indication that an error had occurred, set an error state, or throw an exception.
Also, if the error-handling function can handle the problem without bothering the ultimate caller, why do we consider it an error.
Traditionally, an unsystematic combination of these approached co-exists in a program.
The traditional response has been to muddle through and hope for the best.
Thus, exception handling makes programs more "brittle" in the sense that more care and effort must be taken to get a program to run acceptably.
This is preferable, though, to getting wrong results later in the development process – or after the development process is considered complete and the program is handed over to innocent users.
Where termination is unacceptable, we can catch all exceptions (13_0_5_0_2_0_2).
Thus, an exception terminates a program only if a programmer allows it to terminate.
Typically, this is preferable to the unconditional termination that happens when a traditional incomplete recovery leads to a catastrophic error.
Where termination is an acceptable response, an uncaught exception will achieve that because it turns into a call of terminate() (13_0_5_0_2_0_5).
Also, a noexcept speciﬁer (13_0_5_0_1_0_1) can make that desire explicit.
Sometimes, people try to alleviate the unattractive aspects of "muddling through" by writing out error messages, putting up dialog boxes asking the user for help, etc.
Such approaches are primarily useful in debugging situations in which the user is a programmer familiar with the structure of the program.
In the hands of nondevelopers, a library that asks the (possibly absent) user/operator for help is unacceptable.
A good library doesn't "blabber" in this way.
If a user has to be informed, an exception handler can compose a suitable message (e_0_g_0_, in Finnish for Finnish users or in XML for an error-logging system).
Exceptions provide a way for code that detects a problem from which it cannot recover to pass the problem on to a part of the system that might be able to recover.
Only a part of the system that has some idea of the context in which the program runs has any chance of composing a meaningful error message.
Please recognize that error handling will remain a difﬁcult task and that the exception-handling mechanism – although more formalized than the techniques it replaces – is still relatively unstructured compared with language features involving only local control ﬂow.
The Cplus_plus exception-handling mechanism provides the programmer with a way of handling errors where they are most naturally handled, given the structure of a system.
Exceptions make the complexity of error handling visible.
However, exceptions are not the cause of that complexity.
Be careful not to blame the messenger for bad news.
The Cplus_plus exception-handling mechanism is designed to support handling of errors that cannot be handled locally ("exceptional conditions").
In particular, it is intended to support error handling in programs composed of independently developed components.
Given that there is nothing particularly exceptional about a part of a program being unable to perform its given task, the word "exception" may be considered a bit misleading.
Can an event that happens most times a program is run be considered exceptional.
Can an event that is planned for and handled be considered an error.
The answer to ptg10564057 348 Exception Handling Chapter 13 13_0_1_0_4_0_1 Asynchronous Events The mechanism is designed to handle only synchronous exceptions, such as array range checks and I/O errors.
Asynchronous events, such as keyboard interrupts and power failures, are not necessarily exceptional and are not handled directly by this mechanism.
Asynchronous events require mechanisms fundamentally different from exceptions (as deﬁned here) to handle them cleanly and efﬁciently.
Many systems offer mechanisms, such as signals, to deal with asynchrony, but because these tend to be system-dependent, they are not described here.
Exception throws should be infrequent compared to function calls or the structure of the system has been obscured.
However, we should expect most large programs to throw and catch at least some exceptions in the course of a normal and successful run.
If an exception is expected and caught so that it has no bad effects on the behavior of the program, then how can it be an error.
Only because the programmer thinks of it as an error and of the exception-handling mechanisms as tools for handling errors.
Alternatively, one might think of the exception-handling mechanisms as simply another control structure, an alternative way of returning a value to a caller.
Consider a binary tree search function:.
This actually has some charm, but it should be avoided because it is likely to cause confusion and inefﬁciencies.
When at all possible, stick to the "exception handling is error handling" view.
When this is done, code is clearly separated into two categories: ordinary code and error-handling code.
This makes code more comprehensible.
Furthermore, the implementations of the exception mechanisms are optimized based on the assumption that this simple model underlies the use of exceptions.
Error handling is inherently difﬁcult.
Anything that helps preserve a clear model of what is an error and how it is handled should be treasured.
However, we must reluctantly conclude that there are programs that for practical and historical reasons cannot use exceptions.
A time-critical component of an embedded system where an operation must be guaranteed to complete in a speciﬁc maximum time.
In the absence of tools that can accurately estimate the maximum time for an exception to propagate from a throw to a catch, alternative error-handling methods must be used.
A large old program in which resource management is an ad hoc mess (e_0_g_0_, free store is unsystematically "managed" using "naked" pointers, news, and deletes), rather than relying on some systematic scheme, such as resource handles (e_0_g_0_, string and vector; 4_0_2, 4_0_4).
In such cases, we are thrown back onto "traditional" (pre-exception) techniques.
Because such programs arise in a great variety of historical contexts and in response to a variety of constraints, I cannot give a general recommendation for how to handle them.
However, I can point to two popular techniques:.
To mimic RAII, give every class with a constructor an invalid() operation that returns some A useful convention is for ==0 to represent success.
If the constructor fails to establish the class invariant, it ensures that no resource is leaked and invalid() returns a nonzero.
This solves the problem of how to get an error condition out of a constructor.
A user can then systematically test invalid() after each construction of an object and engage in suitable error handling in case of failure.
To mimic a function either returning a value or throwing an exception, a function can return a pair<Value ,Error_code> (5_0_4_0_3).
A user can then systematically test the  after each function call and engage in suitable error handling in case of failure.
Variations of this scheme have been reasonably successful, but they are clumsy compared to using exceptions in a systematic manner.
The assumption is that the two parts of the program are written independently and that the part of the program that handles the exception often can do something sensible about the error.
To use handlers effectively in a program, we need an overall strategy.
That is, the various parts of the program must agree on how exceptions are used and where errors are dealt with.
The exception-handling mechanisms are inherently nonlocal, so adherence to an overall strategy is essential.
This implies that the error-handling strategy is best considered in the earliest phases of a design.
It also implies that the strategy must be simple (relative to the complexity of the total program) and explicit.
Something complicated would not be consistently adhered to in an area as inherently tricky as error recovery.
Successful fault-tolerant systems are multilevel.
Each level copes with as many errors as it can without getting too contorted and leaves the rest to higher levels.
Exceptions support that view.
Furthermore, terminate() supports this view by providing an escape if the exception-handling mechanism itself is corrupted or if it has been incompletely used, thus leaving exceptions uncaught.
Similarly, noexcept provides a simple escape for errors where trying to recover seems infeasible.
Not every function should be a ﬁrewall.
That is, not every function can test its preconditions well enough to ensure that no errors could possibly stop it from meeting its postcondition.
The reasons that this will not work vary from program to program and from programmer to programmer.
However, for larger programs: [1] The amount of work needed to ensure this notion of "reliability" is too great to be done consistently.
However, separating the program into distinct subsystems that either complete successfully or fail in well-deﬁned ways is essential, feasible, and economical.
Thus, major libraries, subsystems, and key interface functions should be designed in this way.
Furthermore, in most systems, it is feasible to design every function to ensure that it always either completes successfully or fails in a welldeﬁned manner.
Usually, we don't hav e the luxury of designing all of the code of a system from scratch.
Therefore, to impose a general error-handling strategy on all parts of a program, we must take into account program fragments implemented using strategies different from ours.
To do this we must address a variety of concerns relating to the way a program fragment manages resources and the state in which it leaves the system after an error.
The aim is to have the program fragment appear to follow the general error-handling strategy even if it internally follows a different strategy.
Occasionally, it is necessary to convert from one style of error reporting to another.
For example, we might check  and possibly throw an exception after a call to a C library or, conversely, catch an exception and set  before returning to a C program from a Cplus_plus library: ptg10564057 Section 13_0_1_0_6 Hierarchical Error Handling 351.
In such cases, it is important to be systematic enough to ensure that the conversion of error-report without a clear error-handling strategy and therefore difﬁcult to be systematic about.
Error handling should be – as far as possible – hierarchical.
If a function detects a run-time error, it should not ask its caller for help with recovery or resource acquisition.
Such requests set up cycles in the system dependencies.
That in turn makes the program hard to understand and introduces the possibility of inﬁnite loops in the error-handling and recovery code.
In addition, this can be done so that throwing an exception isn't all that expensive compared to calling a function.
Doing so without adding signiﬁcant memory overhead while maintaining compatibility with C calling sequences, debugger conventions, etc_0_, is possible, but hard.
However, please remember that the alternatives to exceptions are not free either.
It is not unusual to ﬁnd traditional systems in which half of the code is devoted to error handling.
Consider a simple function f() that appears to have nothing to do with exception handling:.
Had g() not thrown an exception, it would have had to report its error some other way.
Consequently, the comparable code using ordinary code to handle errors instead of exceptions isn't the plain code above, but something like:.
Using a local buffer for  would simplify the code by eliminating the calls to free(), but then we'd have range-checking code instead.
Complexity tends to move around rather than just disappear.
People don't usually handle errors this systematically, though, and it is not always critical to do so.
However, when careful and systematic handling of errors is necessary, such housekeeping is best left to a computer, that is, to the exception-handling mechanisms.
The noexcept speciﬁer (13_0_5_0_1_0_1) can be most helpful in improving generated code.
Consider: void g(int) noexcept; void h(const string&) noexcept; Now, the code generated for f() can possibly be improved.
No traditional C function throws an exception, so most C functions can be declared noexcept.
In particular, a standard-library implementer knows that only a few standard C library functions (such as atexit() and qsort()) can throw, and can take advantage of that fact to generate better code.
Before declaring a "C function" noexcept, take a minute to consider if it could possibly throw an exception.
For example, it might have been converted to use the Cplus_plus operator ,  can throw bad_alloc, or it might call a Cplus_plus library that throws an exception.
As ever, discussions about efﬁciency are meaningless in the absence of measurements.
Only then can recovery be meaningful.
Therefore, we call an operation exceptionsafe if that operation leaves the program in a valid state when the operation is terminated by throwing an exception.
However, for that to be meaningful and useful, we have to be precise about what we mean by "valid state_0_" For practical design using exceptions, we must also break down the overly general "exception-safe" notion into a few speciﬁc guarantees.
When reasoning about objects, we assume that a class has a class invariant (2_0_4_0_3_0_2, 17_0_2_0_1).
We assume that this invariant is established by its constructor and maintained by all functions with access to the object' representation until the object is destroyed.
So, by valid state we mean that a constructor has completed and the destructor has not yet been entered.
For data that isn't easily viewed as an object, we must reason similarly.
That is, if two pieces of nonlocal data are assumed to have a speciﬁc relationship, we must consider that an invariant and our recovery action must preserve it.
For example: namespace Points {.
However, that was only stated in a comment, and compilers do not read comments.
Such implicit invariants can be very hard to discover and maintain.
Before a throw, a function must place all constructed objects in valid states.
However, such a valid state may be one that doesn't suit the caller.
For example, a string may be left as the empty string or a container may be left unsorted.
Thus, for complete recovery, an error handler may have to produce values that are more appropriate/desirable for the application than the (valid) ones existing at the entry to a catch-clause.
The Cplus_plus standard library provides a generally useful conceptual framework for design for exception-safe program components.
The library provides one of the following guarantees for ev ery library operation:.
The basic guarantee for all operations: The basic invariants of all objects are maintained, and no resources, such as memory, are leaked.
In particular, the basic invariants of every built-in and standard-library type guarantee that you can destroy an object or assign to it after every standard-library operation (iso_0_17_0_6_0_3_0_1).
The strong guarantee for key operations: in addition to providing the basic guarantee, either the operation succeeds, or it has no effect.
This guarantee is provided for key operations, such as push_back(), single-element insert() on a list, and uninitialized_copy().
The nothrow guarantee for some operations: in addition to providing the basic guarantee, some operations are guaranteed not to throw an exception.
This guarantee is provided for a few simple operations, such as swap() of two containers and pop_back().
Violating a standard-library requirement, such as having a destructor exit by throwing an exception, is logically equivalent to violating a fundamental language rule, such as dereferencing a null pointer.
The practical effects are also equivalent and often disastrous.
Both the basic guarantee and the strong guarantee require the absence of resource leaks.
This is necessary for every system that cannot afford resource leaks.
In particular, an operation that throws an exception must not only leave its operands in well-deﬁned states but must also ensure that every resource that it acquired is (eventually) released.
For example, at the point where an exception is thrown, all memory allocated must be either deallocated or owned by some object,  in turn must ensure that the memory is properly deallocated.
Remember that memory isn't the only kind of resource that can leak.
I consider anything that has to be acquired from another part of the system and (explicitly or implicitly) given back to be a resource.
Files, locks, network connections, and threads are examples of system resources.
A function may have to release those or hand them over to some resource handler before throwing an exception.
The Cplus_plus language rules for partial construction and destruction ensure that exceptions thrown while constructing subobjects and members will be handled correctly without special attention from standard-library code (17_0_2_0_3).
This rule is an essential underpinning for all techniques dealing with exceptions.
In general, we must assume that every function that can throw an exception will throw one.
This implies that we must structure our code so that we don't get lost in a rat' nest of complicated control structures and brittle data structures.
When analyzing code for potential errors, simple, highly structured, "stylized" code is the ideal; 13_0_6 includes a realistic example of such code.
Often that "proper release" is achieved by having the function that acquired it release it before returning to its caller.
For example: ptg10564057 Section 13_0_3 Resource Management 355.
Exactly the same problem can occur in languages that do not support exception handling.
For example, the standard C library function longjmp() can cause the same problem.
Even an ordinary return-statement could exit use_ﬁle without closing.
A ﬁrst attempt to make use_ﬁle() fault-tolerant looks like this:.
The code using the ﬁle is enclosed in a try-block that catches every exception, closes the ﬁle, and rethrows the exception.
The problem with this solution is that it is verbose, tedious, and potentially expensive.
Worse still, such code becomes signiﬁcantly more complex when several resources must be acquired and released.
Fortunately, there is a more elegant solution.
The general form of the problem looks like this:.
It is typically important that resources are released in the reverse order of their acquisition.
This ptg10564057 356 Exception Handling Chapter 13 strongly resembles the behavior of local objects created by constructors and destroyed by destructors.
Thus, we can handle such resource acquisition and release problems using objects of classes with constructors and destructors.
For example, we can deﬁne a class File_ptr that acts like a ∗: class File_ptr {.
In either case, a File_ptr will be destroyed at the end of its scope and its destructor will close the ﬁle.
File_ptr throws an exception if it cannot open a ﬁle because otherwise every operation on the ﬁle handle would have to test for nullptr.
Our function now shrinks to this minimum:.
The destructor will be called independently of whether the function is exited normally or exited because an exception is thrown.
That is, the exception-handling mechanisms enable us to remove the error-handling code from the main algorithm.
The resulting code is simpler and less errorprone than its traditional counterpart.
This technique for managing resources using local objects is usually referred to as "Resource Acquisition Is Initialization" (RAII; 5_0_2).
This is a general technique that relies on the properties of constructors and destructors and their interaction with exception handling.
The problem with that approach is that you need to remember to "catch and correct" the problem wherever a resource is acquired in an undisciplined way (typically dozens or hundreds of places in a large program), whereas the handler class need be written only once.
An object is not considered constructed until its constructor has completed.
Then and only then will stack unwinding (13_0_5_0_1) call the destructor for the object.
An object composed of subobjects is constructed to the extent that its subobjects have been constructed.
An array is constructed to the extent that its elements have been constructed (and only fully constructed elements are destroyed during unwinding).
A constructor tries to ensure that its object is completely and correctly constructed.
When that cannot be achieved, a well-written constructor restores – as far as possible – the state of the system to what it was before creation.
Ideally, a well-designed constructor always achieves one of these alternatives and doesn't leave its object in some "half-constructed" state.
This can be simply achieved by applying the RAII technique to the members.
Consider a class  for which a constructor needs to acquire two resources: a ﬁle x and a mutex y (5_0_3_0_4).
This acquisition might fail and throw an exception.
Class 's constructor must never complete having acquired the ﬁle but not the mutex (or the mutex and not the ﬁle, or neither).
Furthermore, this should be achieved without imposing a burden of complexity on the programmer.
We use objects of two classes, File_ptr and std:: (5_0_3_0_4), to represent the acquired resources.
The acquisition of a resource is represented by the initialization of the local object that represents the resource: class Locked_ﬁle_handle {.
Now, as in the local object case, the implementation takes care of all of the bookkeeping.
The user doesn't hav e to keep track at all.
For example, if an exception occurs after  has been constructed but before lck has been, then the destructor for  but not for lck will be invoked.
This implies that where this simple model for acquisition of resources is adhered to, the author of the constructor need not write explicit exception-handling code.
The most common resource is memory,  string, vector,  the other standard containers use RAII to implicitly manage acquisition  release.
Compared to ad hoc memory management using  ( possibly also delete), this saves lots of work  avoids lots of errors.
When a pointer to an object, rather than a local object, is needed, consider using the standardlibrary types unique_ptr  shared_ptr (5_0_2_0_1, 34_0_3) to avoid leaks.
Again  again, people have inv ented "ﬁnally" language constructs for writing arbitrary code to clean up after an exception.
Such techniques are generally inferior to RAII because they are ad hoc, but if you really want ad hoc, RAII can supply that also.
First, we deﬁne a class that will execute an arbitrary action from its destructor.
In addition, the memory allocated  pointed to by    is appropriately deleted  free()d.
It is generally a good idea to place a guard close to the deﬁnition of whatever it is guarding.
That way, we can at a glance see what is considered a resource (even if ad hoc)  what is to be done at the end of its scope.
The connection between ﬁnally() actions  the resources they manip is far better than scattering cleanup code around in a block.
Basically, ﬁnally() does for a block what the increment part of a for-statement does for the forstatement (9_0_5_0_2): it speciﬁes the ﬁnal action at the top of a block where it is easy to be seen where it logically belongs from a speciﬁcation point of view.
It says what is to be done upon exit from a scope, saving the programmer from trying to write code at each of the potentially many places from which the thread of control might exit the scope.
Similarly, when a constructor cannot establish its class invariant (2_0_4_0_3_0_2, 17_0_2_0_1), the object is not usable.
In those cases, I typically throw exceptions.
However, there are programs for which throwing an exception is not an option (13_0_1_0_5),  there are people with different views of how to deal with the failure of a precondition ( similar conditions):.
Just don't do that: It is the caller's job to meet preconditions,  if the caller doesn't do that, let bad results occur – eventually those errors will be eliminated from the system through improved design, debugging,  testing.
Terminate the program: Violating a precondition is a serious design error,  the program must not proceed in the presence of such errors.
Hopefully, the total system can recover from the failure of one component (that program) – eventually such failures may be eliminated from the system through improved design, debugging,  testing.
Why would anyone choose one of these alternatives.
The ﬁrst approach often relates to the need for performance: systematically checking preconditions can lead to repeated tests of logically unnecessary conditions (for example, if a caller has correctly validated data, millions of tests in thousands of called functions may be logically redundant).
The cost in performance can be signiﬁcant.
It may be worthwhile to suffer repeated crashes during testing to gain that performance.
Obviously, this assumes that you eventually get all critical precondition violations out of the system.
For some systems, typically systems completely under the control of a single organization, that can be a realistic aim.
The second approach tends to be used in systems where complete  timely recovery from a precondition failure is considered infeasible.
That is, making sure that recovery is complete imposes unacceptable complexity on the system design  implementation.
On the other hand, ptg10564057 360 Exception Handling Chapter 13 termination of a program is considered acceptable.
For example, it is not unreasonable to consider program termination acceptable if it is easy to rerun the program with inputs  parameters that make repeated failure unlikely.
Some distributed systems are like this (as long as the program that terminates is only a part of the complete system),  so are many of the small programs we write for our own consumption.
Realistically, many systems use a mix of exceptions  these two alternative approaches.
All three share a common view that preconditions should be deﬁned  obeyed; what differs is how enforcement is done  whether recovery is considered feasible.
Program structure can be radically different depending on whether (localized) recovery is an aim.
In most systems, some exceptions are thrown without real expectation of recovery.
For example, I often throw an exception to ensure some error logging or to produce a decent error message before terminating or re-initializing a process (e_0_g_0_, from a catch(_0__0__0_) in main()).
A variety of techniques are used to express checks of desired conditions  invariants.
When we want to be neutral about the logical reason for the check, we typically use the word assertion, often abbreviated to an assert.
An assertion is simply a logical expression that is assumed to be true.
Howev er, for an assertion to be more than a comment, we need a way of expressing what happens if it is false.
Looking at a variety of systems, I see a variety of needs when it comes to expressing assertions:.
We need to choose between compile-time asserts (evaluated by the compiler)  run-time asserts (evaluated at run time).
For run-time asserts we need a choice of throw, terminate, or ignore.
No code should be generated unless some logical condition is true.
For example, some runtime asserts should not be evaluated unless the logical condition is true.
Usually, the logical condition is something like a debug ﬂag, a level of checking, or a mask to select among asserts to enforce.
Asserts should not be verbose or complicated to write (because they can be very common).
Not every system has a need for or supports every alternative.
The standard offers two simple mechanisms:.
In <cassert>, the standard library provides the assert(A) macro, which checks its assertion, A, at run time if and only if the macro NDEBUG ("not debugging") is not deﬁned (12_0_6_0_2).
If the assertion fails, the compiler writes out an error message containing the (failed) assertion, the source ﬁle name, and the source ﬁle line number and terminates the program.
The language provides static_assert(A,message), which unconditionally checks its assertion, A, at compile time (2_0_4_0_3_0_3).
If the assertion fails, the compiler writes out the message and the compilation fails.
Where assert() and static_assert() are insufﬁcient, we could use ordinary code for checking.
Evaluating a condition that is expected to be true for some calls and not for others.
Checking a precondition which should never fail.
What we would like is a recognizable mechanism for checking assertions.
What follows here is a (possibly slightly overelaborate) mechanism for expressing a variety of assertions and a variety of responses to failures.
First, I deﬁne mechanisms for deciding when to test and deciding what to do if an assertion fails:.
The idea is to test whenever an assertion has a "level" lower than or equal to.
If an assertion fails,  is used to choose among three alternatives.
The  and  are constants because the idea is to generate no code whatsoever for an assertion unless we have made a decision to do so.
Imagine CURRENT_MODE and CURRENT_LEVEL to be set in the build environment for a program, possibly as compiler options.
I chose the name Assert:: (meaning "evaluate at run time") to contrast with static_assert (meaning "evaluate at compile time"; 2_0_4_0_3_0_3).
Further implementation trickery could be used to minimize the amount of code generated.
Alternatively, we could do more of the testing at run time if more ﬂexibility is needed.
This Assert is not part of the standard and is presented primarily as an illustration of the problems and the implementation techniques.
I suspect that the demands on an assertion mechanism vary too much for a single one to be used everywhere.
We can use Assert:: like this:.
The __FILE__ and __LINE__ are macros that expand at their point of appearance in the source code (12_0_6_0_2).
I can't hide them from the user's view by placing them inside the implementation of Assert where they belong.
Assert::Error is the default exception, so we need not mention it explicitly.
Similarly, if we are willing to use the default assertion level, we don't need to mention the level explicitly: ptg10564057 Section 13_0_4 Enforcing Invariants 363.
It is possible to control the testing done and the response to testing through build options (e_0_g_0_, controlling conditional compilation) and/or through options in the program code.
That way, you can have a debug version of a system that tests extensively and enters the debugger and a production version that does hardly any testing.
I personally favor leaving at least some tests in the ﬁnal (shipping) version of a program.
For example, with Assert the obvious convention is that assertions marked as level zero will always be checked.
We nev er ﬁnd the last bug in a large program under continuous development and maintenance.
Also, ev en if all else works perfectly, having a few "sanity checks" left to deal with hardware failures can be wise.
Only the builder of the ﬁnal complete system can decide whether a failure is acceptable or not.
The writer of a library or reusable component usually does not have the luxury of terminating unconditionally.
I interpret that to mean that for general library code, reporting an error – preferably by throwing an exception – is essential.
As usual, destructors should not throw, so don't use a throwing Assert() in a destructor.
This temporary may be further copied several times before it is caught: the exception is passed (back) from called function to calling function until a suitable handler is found.
The type of the exception is used to select a handler in the catch-clause of some try-block.
The data in the exception object – if any – is typically used to produce error messages or to help recovery.
The process of passing the exception "up the stack" from the point of throw to a handler is called stack unwinding.
In each scope exited, the destructors are invoked so that every fully constructed object is properly destroyed.
After the throw in h(), all the strings that were constructed are destroyed in the reverse order of their construction: "not", "or", "excess", "in", but not "at all", which the thread of control never reached, and not "Byron", which was unaffected.
Exceptions containing a few words are very common.
The semantics of exception propagation are those of initialization, so objects of types with move semantics (e_0_g_0_, strings) are not expensive to throw.
Some of the most common exceptions carry no information; the name of the type is sufﬁcient to report the error.
To indicate that, we can declare such a function noexcept.
For example: double compute(double) noexcept; // may not throw an exception ptg10564057 366 Exception Handling Chapter 13 Now no exception will come out of compute().
Declaring a function noexcept can be most valuable for a programmer reasoning about a program and for a compiler optimizing a program.
The programmer need not worry about providing try-clauses (for dealing with failures in a noexcept function) and an optimizer need not worry about control paths from exception handling.
However, noexcept is not completely checked by the compiler and linker.
What happens if the programmer "lied" so that a noexcept function deliberately or accidentally threw an exception that wasn't caught before leaving the noexcept function.
The  constructor may fail to acquire memory for its ten doubles and throw a std::bad_alloc.
In that case, the program terminates.
It does not invoke destructors from calling functions.
It is implementation-deﬁned whether destructors from scopes between the throw and the noexcept (e_0_g_0_, for  in compute()) are invoked.
The program is just about to terminate, so we should not depend on any object anyway.
By adding a noexcept speciﬁer, we indicate that our code was not written to cope with a throw.
For example: template<typename T> void my_fct(T& x) noexcept(<T>()); The noexcept(<T>()) means that My_fct may not throw if the predicate <T>() is true but may throw if it is false.
I may want to write this if my_fct() copies its argument.
I know that copying a POD does not throw, whereas other types (e_0_g_0_, a string or a ) may.
The predicate in a noexcept() speciﬁcation must be a constant expression.
Plain noexcept means noexcept(true).
The standard library provides many type predicates that can be useful for expressing the conditions under which a function may throw an exception (35_0_4).
What if the predicate we want to use isn't easily expressed using type predicates only.
For example,  if the critical operation that may or may not throw is a function call f(x).
The noexcept() operator takes an expression as its argument and returns true if the compiler "knows" that it cannot throw and false otherwise.
For example: template<typename T>.
The operand of noexcept() is not evaluated, so in the example we do not get a run-time error if we pass call_f() with an empty.
A noexcept(expr) operator does not go to heroic lengths to determine whether expr can throw; it simply looks at every operation in expr and if they all have noexcept speciﬁcations that evaluate to true, it returns true.
A noexcept(expr) does not look inside deﬁnitions of operations used in expr.
Conditional noexcept speciﬁcations and the noexcept() operator are common and important in standard-library operations that apply to containers.
For example (iso_0_20_0_2_0_2): template<class T, siz e_t N> void swap(T (&a)[N], T (&b)[N]) noexcept(noexcept(swap(∗a, ∗b))); 13_0_5_0_1_0_3 Exception Speciﬁcations In older Cplus_plus code, you may ﬁnd exception speciﬁcations.
For example: void f(int) throw(Bad,Worse); // may only throw Bad or Worse exceptions void g(int) throw(); // may not throw An empty exception speciﬁcation throw() is deﬁned to be equivalent to noexcept (13_0_5_0_1_0_1).
That is, if an exception is thrown, the program terminates.
The meaning of a nonempty exception speciﬁcation, such as throw(Bad,Worse), is that if the function (here f()) throws any exception that is not mentioned in the list or publicly derived from an exception mentioned there, an unexpected handler is called.
The default effect of an unexpected exception is to terminate the program (30_0_4_0_1_0_3).
A nonempty throw speciﬁcation is hard to use well and implies potentially expensive run-time checks to determine if the right exception is thrown.
This feature has not been a success and is deprecated.
If you want to dynamically check which exceptions are thrown, use a try-block.
The handler is invoked: [1] If H is the same type as E [2] If H is an unambiguous public base of E [3] If H and E are pointer types and [1] or [2] holds for the types to which they refer [4] If H is a reference and [1] or [2] holds for the type  which H refers In addition, we can add const  the type used  catch an exception in the same way that we can ptg10564057 368 Exception Handling Chapter 13 add it  a function parameter.
This doesn't change the set of exceptions we can catch; it only restricts us from modifying the exception caught.
In principle, an exception is copied when it is thrown (13_0_5).
The implementation may apply a wide variety of strategies for storing and transmitting exceptions.
It is guaranteed, however, that there is sufﬁcient memory  allow new  throw the standard out-of-memory exception, bad_alloc (11_0_2_0_3).
Note the possibility of catching an exception by reference.
Exception types are often deﬁned as part of class hierarchies  reﬂect relationships among the kinds of errors they represent.
For examples, see 13_0_5_0_2_0_3 and 30_0_4_0_1_0_1.
The technique of organizing exception classes into hierarchies is common enough for some programmers  prefer  catch every exception by reference.
The {} in both the try-part and a catch-clause of a try-block are real scopes.
Consequently, if a name is  be used in both parts of a try-block or outside it, that name must be declared outside the.
The "catch everything" clause, catch(_0__0__0_), is explained in 13_0_5_0_2_0_2.
In that case, the handler typically does what can be done locally and then throws the exception again.
Thus, an error can be handled where it is most appropriate.
This is the case even when the information needed  best handle the error is not available in a single place, so that the recovery action is best distributed over sev eral handlers.
For example: ptg10564057 Section 13_0_5_0_2_0_1 Rethrow 369.
A rethrow is indicated by a throw without an operand.
A rethrow may occur in a catch-clause or in a function called from a catch-clause.
If a rethrow is attempted when there is no exception rethrow, std::terminate() (13_0_5_0_2_0_5) will be called.
A compiler can detect and warn about some, but not all, such cases.
The exception rethrown is the original exception caught and not just the part of it that was accessible as an exception.
For example, had an out_of_range been thrown, h() would catch it as a plain exception, but throw; would still rethrow it as an out_of_range.
Had I written throw err; instead of the simpler throw;, the exception would have been sliced (17_0_5_0_1_0_4) and h()'s caller could not have caught it as an out_of_range.
This catches every standard-library exception.
However, the standard-library exceptions are just one set of exception types.
Consequently, you cannot catch every exception by catching std::exception.
If someone (unwisely) threw an int or an exception from some application-speciﬁc hierarchy, it would not be caught by the handler for std::exception&.
However, we often need  deal with every kind of exception.
For example, if m() is supposed leave some pointers in the state in which it found them, then we can write code in the handler ptg10564057 370 Exception Handling Chapter 13 give them acceptable values.
As for functions, the ellipsis, _0__0__0_, indicates "any argument" (12_0_2_0_4),.
Because a derived exception can be caught by handlers for more than one exception type, the order in which the handlers are written in a trystatement is signiﬁcant.
The handlers are tried in order.
Here, the exception is never considered.
Even if we removed the "catch-all" handler, bad_cast wouldn't be considered because it is derived from exception.
Matching exception types  catchclauses is a (fast) run-time operation and is not as general as (compile-time) overload resolution.
For most functions, all we gain from using a function try-block is a bit of notational convenience.
However, a try-block allows us  deal with exceptions thrown by base-or-member initializers in constructors (17_0_4).
By default, if an exception is thrown in a base-or-member initializer, the exception is passed on  whatever inv oked the constructor for the member's class.
However, the constructor itself can catch such exceptions by enclosing the complete function body – including the member initializer list – in a try-block.
Similarly, we can catch exceptions thrown by member destructors in a destructor (though a destructor should never throw).
However, we cannot "repair" the object and return normally as if the exception had not happened: an exception from a member constructor means that the member may not be in a valid state.
Also, other member objects will either not be constructed or already have had their destructors invoked as part of the stack unwinding.
The best we can do in a catch-clause of a function try-block for a constructor or destructor is throw an exception.
The default action is  rethrow the original exception when we "fall off the end" of the catch-clause (iso_0_15_0_3).
There are no such restrictions for the try-block of an ordinary function.
The guiding principles are:.
If the -handling implementation catches you doing either, it will terminate your program.
If you managed to have two exceptions active at  time (in the same thread, which you can't), the system would have no idea which of the exceptions to try to handle: your new  or the  it was already trying to handle.
Note that an  is considered handled immediately upon entry into a catch-clause.
Rethrowing an  (13_0_5_0_2_0_1) or throwing a new  from within a catch-clause is considered a new  done after the original  has been handled.
You can  an  from within a destructor (even during stack unwinding) as long as you catch it before it leaves the destructor.
When no suitable handler was found for a thrown.
When a noexcept function tries to exit with a.
When a destructor invoked during stack unwinding tries to exit with a.
When code invoked to propagate an  (e_0_g_0_, a copy constructor) tries to exit with a.
When someone tries to rethrow (;) when there is no current  being handled.
When a destructor for a statically allocated or thread-local object tries to exit with a.
When an initializer for a statically allocated or thread-local object tries to exit with a.
When a function invoked as an atexit() function tries to exit with a In such cases, the function std::terminate() is called.
In addition, a user can call terminate() if less drastic approaches are infeasible.
By "tries to exit with a ," I mean that an  is thrown somewhere and not caught so that the run-time system tries to propagate it  a function to its caller.
By default, terminate() will call abort() (15_0_4_0_3).
This default is the correct choice for most users – especially during debugging.
If that is not acceptable, the user can provide a terminate handler function by a call std::set_terminate()  <>: ptg10564057 Section 13_0_5_0_2_0_5 Termination 373 using  = void(∗)();.
For example, a terminate handler could be used to abort a process or maybe to re-initialize a system.
The intent is for terminate() to be a drastic measure to be applied when the error recovery strategy implemented by the -handling mechanism has failed and it is time to go to another level of a fault tolerance strategy.
If a terminate handler is entered, essentially nothing can be assumed about a program's data structures; they must be assumed to be corrupted.
Even writing an error message using cerr must be assumed to be hazardous.
Also, note that as dangerous() is written, it is not -safe.
A  or even a return before set_terminate() will leave my_handler in place when it wasn't meant to be.
If you must mess with terminate(), at least use RAII (13_0_3).
A terminate handler cannot return to its caller.
If it tries to, terminate() will call abort().
Note that abort() indicates abnormal exit  the program.
The function exit() can be used to exit a program with a return value that indicates to the surrounding system whether the exit is normal or abnormal (15_0_4_0_3).
It is implementation-deﬁned whether destructors are invoked when a program is terminated because of an uncaught.
On some systems, it is essential that the destructors are not called so that the program can be resumed  the debugger.
On other systems, it is architecturally close to impossible not to invoke the destructors while searching for a handler.
If you want to ensure cleanup when an otherwise uncaught  happens, you can add a catch-all handler (13_0_5_0_2_0_2) to main() in addition to handlers for exceptions you really care about.
This will catch every , except those thrown by construction and destruction of namespace and thread-local variables (13_0_5_0_3).
There is no way of catching exceptions thrown during initialization or destruction of namespace and thread-local variables.
This is another reason to avoid global variables whenever possible.
When an  is caught, the exact point where it was thrown is generally not known.
This represents a loss of information compared to what a debugger might know about the state of a program.
In some Cplus_plus development environments, for some programs, and for some people, it might therefore be preferable not to catch exceptions  which the program isn't designed to recover.
See Assert (13_0_4) for an example of how  might encode the location of a  into the thrown.
So, if we don't want an error in a thread to stop the whole program, we must catch all errors  which we would like to recover and somehow report them to a part of the program that is interested in the results of the thread.
The "catch-all" construct catch(_0__0__0_) (13_0_5_0_2_0_2) comes in handy for that.
This is the basic technique used by packaged_task to handle exceptions  user code (5_0_3_0_5_0_2).
Obviously, a vector implementation relies on many language facilities provided to support the implementation and use of classes.
If you are not (yet) comfortable with Cplus_plus's classes and templates, you may prefer to delay studying this example until you have read Chapter 16, Chapter 25, and Chapter 26.
However, a good understanding of the use of exceptions in Cplus_plus requires a more extensive example than the code fragments so far in this chapter.
The tr y-block (13_0_5).
The support for the "Resource Acquisition Is Initialization" technique (13_0_3).
The general principles to follow are to.
Nev er let go of a piece of information before its replacement is ready for use.
Always leave objects in valid states when throwing or rethrowing an exception.
That way, we can always back out of an error situation.
The practical difﬁculty in following these principles is that innocent-looking operations (such  <, =, and sor t()) might throw exceptions.
Knowing what to look for in an application takes experience.
When you are writing a library, the ideal is to aim at the strong exception-safety guarantee (13_0_2) and always to provide the basic guarantee.
When writing a speciﬁc program, there may be less concern for exception safety.
For example, if I write a simple data analysis program for my own use, I'm usually quite willing to have the program terminate in the unlikely event of memory exhaustion.
Correctness and basic exception safety are closely related.
In particular, the techniques for providing basic exception safety, such  deﬁning and checking invariants (13_0_4), are similar to the techniques that are useful to get a program small and correct.
It follows that the overhead of providing the basic exception-safety guarantee (13_0_2) – or even the strong guarantee – can be minimal or even insigniﬁcant.
The default allocator (34_0_4_0_1) uses new  delete to acquire  release memory.
Here is a declaration of vector simpliﬁed to present only what is needed to discuss exception safety  avoidance of resource leaks: template<class T, class  = allocator<T>> class vector { private: T∗ elem; // star t of allocation T∗ space; // end of element sequence, star t of space allocated for possible expansion T∗ last; // end of allocated space alloc; // allocator ptg10564057 376 Exception Handling Chapter 13 public: using  = unsigned int;.
What about the copy of the allocator.
We can imagine that it throws, but the standard speciﬁcally requires that it does not do that (iso_0_17_0_6_0_3_0_5).
Anyway, I hav e written the code so that it wouldn't matter if it did.
In both cases of a throw, no  object is created, so 's destructor is not called (13_0_3).
When allocate() fails, the throw will exit before any resources are acquired, so all is well.
When 's copy constructor fails, we have acquired some memory that must be freed to avoid memory leaks.
Worse still, the copy constructor for  might throw an exception after correctly constructing a few elements but before constructing them all.
These  objects may own resources that then would be leaked.
Note that the declaration of  is outside the try-block; otherwise, we would not be able to access it in both the try-part  the catch-clause.
The overhead here is the overhead of the try-block.
In a good Cplus_plus implementation, this overhead is negligible compared to the cost of allocating memory  initializing elements.
For implementations where entering a try-block incurs a cost, it may be worthwhile to add a test if (n) before the try to explicitly handle the (very common) empty  case.
The main part of this constructor is a repeat of the implementation of std::uninitialized_ﬁll(): template<class , class >.
The curious construct &∗ takes care of iterators that are not pointers.
In that case, we need to take address of  element obtained by dereference to get a pointer.
Together with  explicitly ptg10564057 378 Exception Handling Chapter 13 is used to invoke  constructor,  not some user-deﬁned  ()  ∗s.
The calls to alloc_0_construct() in   constructors are simply syntactic sugar  this placement.
Similarly,  alloc_0_destroy() call simply hides explicit destruction (like (&∗)−>˜()).
This code is operating at a rather low lev el where writing truly general code can be difﬁcult.
Fortunately, we don't hav e to invent or implement uninitialized_ﬁll(), because  standard library provides it (32_0_5_0_6).
It is often essential to have initialization operations that either complete successfully, having initialized every element, or fail, leaving no constructed elements behind.
Conse (32_0_5_0_6), which offer  strong guarantee (13_0_2).
The uninitialized_ﬁll() algorithm does not protect against exceptions thrown by element destructors or iterator operations (32_0_5_0_6).
Doing so would be prohibitively expensive  probably impossible.
The uninitialized_ﬁll() algorithm can be applied to many kinds of sequences.
Consequently, it takes a forward iterator (33_0_1_0_2)  cannot guarantee to destroy elements in  reverse order of their construction.
Using uninitialized_ﬁll(), we can simplify our constructor:.
This is a signiﬁcant improvement on  ﬁrst version of this constructor, but  next section demonstrates how to further simplify it.
The constructor rethrows a caught exception.
The intent is to make  transparent to exceptions so that  user can determine  exact cause of a problem.
All standard-library containers layers of software.
This is in contrast to major parts of a system ("modules") that generally need to take responsibility  all exceptions thrown.
That is,  implementer of such a module must be able to list every exception that  module can throw.
Achieving this may involve grouping exceptions into hierarchies (13_0_5_0_2)  using catch(_0__0__0_) (13_0_5_0_2_0_2).
In fact, it is unnecessarily difﬁcult because there is an alternative: The ptg10564057 Section 13_0_6_0_2 Representing Memory Explicitly 379 "Resource Acquisition Is Initialization" technique (13_0_3) can be used to reduce  amount of code that must be written and to make  code more stylized.
In this case,  key resource required by   is memory to hold its elements.
By providing an auxiliary class to represent notion of memory used by a , we can simplify  code and decrease  chances of accidentally forgetting to release it: template<class , class  = allocator<> > struct vector_base { // memor y str ucture alloc; // allocator ∗ ; // star t of allocation ∗ ; //  of element sequence, star t of  allocated  possible expansion.
As long as  and  are correct,  can be destroyed.
Class  deals with memory  a type , not objects of type.
Consequently, a user of  must construct all objects explicitly in  allocated  and later destroy all constructed objects in a before   itself is destroyed.
The  is designed exclusively to be part of  implementation of.
It is always hard to predict where and how a class will be used, so I made sure that a  can't be copied and also that a move of a  properly transfers ownership of  memory allocated elements: template<class , class >.
There are no objects of type  to destroy:  deals with memory and leaves concerns about objects of type  to.
Given ,  can be deﬁned like this: template<class , class  = allocator<> >.
The  destructor explicitly invokes   destructor  every element.
This implies that if an element destructor throws an exception,   destruction fails.
This can be a disaster if it happens during stack unwinding caused by an exception and terminate() is called (13_0_5_0_2_0_5).
In case of normal destruction, throwing an exception from a destructor typically leads to resource leaks and unpredictable behavior of code relying on reasonable behavior of objects.
There is no really good way to protect against exceptions thrown from destructors, so  library makes no guarantees if an element destructor throws (13_0_2).
The uninitialized_ﬁll() algorithm and its cousins (13_0_6_0_1) provide equivalent guarantee  partially constructed sequences.
The move operations are even simpler:.
Just #includeing those headers causes a slurry of error messages: Line, Te xt, and open() are deﬁned twice in ways that a compiler cannot disambiguate.
Trying to use the libraries would give further error messages.
There are many techniques for dealing with such name clashes.
For example, some such problems can be addressed by placing all the facilities of a library inside a few classes, by using supposedly uncommon names (e_0_g_0_, Te xt_box rather than Te xt), or by systematically using a preﬁx for names from a library (e_0_g_0_, gl_shape and gl_line).
Each of these techniques (also known as "workarounds" and "hacks") works in some cases, but they are  general and can be inconvenient to use.
For example, names tend to become long, and the use of many different names inhibits generic programming (3_0_4).
The members of a namespace are in the same scope and can refer to each other without special notation, whereas access from outside the namespace requires explicit notation.
In particular, we can avoid name clashes by separating sets of declarations (e_0_g_0_, library interfaces) into namespaces.
For example, we might call the graph library Graph_lib:.
As long as we manage to pick distinct namespace names, such as Graph_lib and Te xt_lib (14_0_4_0_2), we can now compile the two sets of declarations together without name clashes.
A namespace should express some logical structure: the declarations within a namespace should together provide facilities that unite them in the eyes of their users and reﬂect a common set of design decisions.
They should be seen as a logical unit, for example, "the graphics library" or "the text manipulation library," similar to the way we consider the members of a class.
In fact, the entities declared in a namespace are referred to as the members of the namespace.
A namespace is a (named) scope.
You can access members deﬁned earlier in a namespace from later declarations, but you cannot (without special effort) refer to members from outside the namespace.
Here, the Word and Line in the declaration of Te xt_lib::operator+() refer to Te xt_lib::Word and Te xt_lib::Line.
That local name lookup is not affected by the global Line.
Conversely, the Glyph and lookup is not affected by Te xt_lib's Glyph and Line.
To refer to members of a namespace, we can use its fully qualiﬁed name.
For example, if we want a glyph() that uses deﬁnitions from Te xt_lib, we can write: Te xt_lib::Glyph glyph(Text_lib::Line& ln, int i); // ln[i] Other ways of referring to members from outside their namespace are using-declarations (14_0_2_0_2), using-directives (14_0_2_0_3), and argument-dependent lookup (14_0_2_0_4).
Members of a namespace must be introduced using this notation: namespace namespace−name {.
We cannot declare a new  of a namespace outside a namespace deﬁnition using the qualiﬁer syntax (iso_0_7_0_3_0_1_0_2).
The idea is to catch errors such as misspellings and type mismatches, and also to make it reasonably easy to ﬁnd all names in a namespace declaration.
For example: ptg10564057 Section 14_0_2_0_1 Explicit Qualiﬁcation 393.
A namespace is a scope.
The usual scope rules hold for namespaces.
Thus, "namespace" is a very fundamental and relatively simple concept.
The larger a program is, the more useful namespaces are to express logical separations of its parts.
The global scope is a namespace and can be explicitly referred to using ::.
Classes are namespaces (16_0_2).
Ideally, every entity in a program belongs to some recognizable logical unit ("module").
Therefore, every declaration in a nontrivial program should ideally be in some namespace named to indicate its logical role in the program.
The exception is main(), which must be global in order for the compiler to recognize it as special (2_0_2_0_1, 15_0_4).
That depends on how we decide to access code in other namespaces.
We can always access names from "our own" namespace exactly as we did before we introduced namespaces.
However, for names in other namespaces, we have to choose among explicit qualiﬁcation, using-declarations, and using-directives.
Parser::prim() provides a good test case for the use of namespaces in an implementation because it uses each of the other namespaces (except Driver).
If we use explicit qualiﬁcation, we get:.
I didn't use Parser:: because that would be redundant within namespace Parser.
If we use using-directives, we get: using namespace Lexer;.
I do not recommend such intricate use of header ﬁles unless it is really necessary.
The example above repeatedly violates the rules against including into a nonlocal scope  against having a syntactic construct span ﬁle boundaries (the use of inline); see 15_0_2_0_2.
Sadly, I hav e seen worse.
In most cases, we can achieve versioning by less intrusive means.
The only example I can think of that is completely impossible to do by other means is the specialization of a template explicitly using the  name (e_0_g_0_, Popular::<T∗>).
However, in many important cases "in most cases" isn't good enough.
Also, a solution based on a combination of other techniques is less obviously completely right.
For examples of nested namespaces in the standard library, see chrono (35_0_2)  rel_ops (35_0_5_0_3).
That is, the aim is to preserve locality of code rather than to present an interface to users.
In particular, unnamed namespaces in different translation units are different.
As desired, there is no way of naming a member of an unnamed namespace from another translation unit.
Breaking this program wouldn't be a good idea.
Making standard libraries special cases isn't a good idea either.
Consequently, the language rules for namespaces are designed to make it relatively easy to take a program written without namespaces  turn it into a more explicitly structured one using namespaces.
In fact, the calculator program (10_0_2) is an example of this.
One way to provide the standard  I/O facilities in a namespace would be to place the declarations from the  header stdio_0_h in a namespace std:.
I consider nonlocal using-directives primarily a transition tool.
I also use them for essential foundation libraries, such as the ISO Cplus_plus standard library (std).
Most code referring to names from other namespaces can be expressed more clearly with explicit qualiﬁcation  using-declarations.
The relationship between namespaces  linkage is described in 15_0_2_0_5.
Linkage File-Local Names; Header Files; The One-Deﬁnition Rule; Standard-Library Headers; Linkage to Non-Cplus_plus Code; Linkage and Pointers to Functions.
Using Header Files Single-Header Organization; Multiple-Header Organization; Include Guards.
Programs Initialization of Nonlocal Variables; Initialization and Concurrency; Program Termination.
Advice 15_0_1 Separate Compilation Any realistic program consists of many logically separate components (e_0_g_0_, namespaces; Chapter ﬁles where each ﬁle contains one or more logical components.
Our task is to devise a physical structure (set of ﬁles) for the program that represents the logical components in a consistent, comprehensible, and ﬂexible manner.
In particular, we aim for a clean separation of interfaces (e_0_g_0_, function declarations) and implementations (e_0_g_0_, function deﬁnitions).
A ﬁle is the traditional unit of storage (in a ﬁle system) and the traditional unit of compilation.
There are systems that do not store, compile, and present Cplus_plus programs to the programmer as sets of ﬁles.
However, the discussion here will concentrate on systems that employ the traditional use of ﬁles.
Having a complete program in one ﬁle is usually impossible.
In particular, the code for the standard libraries and the operating system is typically not supplied in source form as part of a ptg10564057 420 Source Files and Programs Chapter 15 user's program.
For realistically sized applications, even having all of the user's own code in a single ﬁle is both impractical and inconvenient.
The way a program is organized into ﬁles can help emphasize its logical structure, help a human reader understand the program, and help the compiler enforce that logical structure.
Where the unit of compilation is a ﬁle, all of the ﬁle must be recompiled whenever a  change (however small) has been made to it or to something on which it depends.
For even a moderately sized program, the amount of time spent recompiling can be signiﬁcantly reduced by partitioning the program into ﬁles of suitable size.
A user presents a source ﬁle to the compiler.
The ﬁle is then preprocessed; that is, macro processing (12_0_6) is done and # directives bring in headers (2_0_4_0_1, 15_0_2_0_2).
The result of preprocessing is called a translation unit.
This unit is what the compiler proper works on and what the Cplus_plus language rules describe.
In this book, I differentiate between source ﬁle and translation unit only where necessary to distinguish what the programmer sees from what the compiler considers.
To enable separate compilation, the programmer must supply declarations providing the type information needed to analyze a translation unit in isolation from the rest of the program.
The declarations in a program consisting of many separately compiled parts must be consistent in exactly the same way the declarations in a program consisting of a single source ﬁle must be.
Your system has tools to help ensure this.
In particular, the linker can detect many kinds of inconsistencies.
The linker is the program that binds together the separately compiled parts.
A linker is sometimes (confusingly) called a loader.
Linking can be done completely before a program starts to run.
Alternatively, new  can be added to the running program ("dynamically linked") later.
The organization of a program into source ﬁles is commonly called the physical structure of a program.
The physical separation of a program into separate ﬁles should be guided by the logical structure of the program.
The same dependency concerns that guide the composition of programs out of namespaces guide its composition into source ﬁles.
However, the logical and physical structures of a program need not be identical.
For example, it can be helpful to use several source ﬁles to store the functions from a single namespace, to store a collection of namespace deﬁnitions in a single ﬁle, or to scatter the deﬁnition of a namespace over sev eral ﬁles (14_0_3_0_3).
Here, we will ﬁrst consider some technicalities relating to linking and then discuss two ways of breaking the desk calculator (10_0_2, 14_0_3_0_1) into ﬁles.
It is the programmer's task to ensure that every namespace, class, function, etc_0_, is properly declared in every translation unit in which it appears and that all declarations referring to the same entity are consistent.
For example, consider two ﬁles: // ﬁle1_0_cpp: int  = 1; int f() { /* do something */ } ptg10564057 Section 15_0_2 Linkage 421.
The keyword extern indicates that the declaration of  in ﬁle2_0_cpp is (just) a declaration and not a deﬁnition (6_0_3).
Had  been initialized, extern would simply be ignored because a declaration with an initializer is always a deﬁnition.
An object must be deﬁned exactly once in a program.
It may be declared many times, but the types must agree exactly.
The #-directive replaces the line in which the # appears with the contents of the ﬁle to_be_included.
The content of to_be_included should be Cplus_plus source text because the compiler will proceed to read it.
To  standard-library headers, use the angle brackets, < and >, around the name instead of quotes.
Furthermore, most modern Cplus_plus implementations provide some form of (implicit or explicit) precompiling of header ﬁles to minimize the work needed to handle repeated compilation of the same header.
As  rule of thumb,  header may contain: Named namespaces namespace N { /∗ _0__0_.
It is simply reasonable way of using the # mechanism to express the physical structure of  program.
Conversely,  header should never contain: Ordinary function deﬁnitions char get(char∗ p) {return ∗pplus_plus; } Data deﬁnitions int ;.
Header ﬁles are conventionally sufﬁxed by _0_h, and ﬁles containing function or data deﬁnitions are sufﬁxed by _0_cpp.
They are therefore often referred to as "_0_h ﬁles" and "_0_cpp ﬁles," respectively.
Other conventions, such as _0_, _0_C, _0_cxx, _0_cc, _0_hh, and hpp are also found.
The manual for your compiler will be quite speciﬁc about this issue.
The reason for recommending that the deﬁnition of simple constants, but not the deﬁnition of aggregates, be placed in header ﬁles is that it is hard for implementations to avoid replication of aggregates presented in several translation units.
Furthermore, the simple cases are far more common and therefore more important for generating good code.
It is wise not to be too clever about the use of #.
Place all #includes before other code to minimize unintended dependencies.
Avoid macro magic.
Minimize the use of names (especially aliases) not local to a header in a header.
One of my least favorite activities is tracking down an error caused by a name being macro-substituted into something completely different by a macro deﬁned in an indirectly #included header that I hav e never even heard of.
From a practical point of view, this means that there must be exactly one deﬁnition of, say, a class residing in a single ﬁle somewhere.
Unfortunately, the language rule cannot be that simple.
For example, the deﬁnition of a class may be composed through macro expansion (ugh_0_), and a definition of a class may be textually included in two source ﬁles by # directives (15_0_2_0_2).
Consequently, the rule in the standard that says that there must be a unique deﬁnition of a class, , etc_0_, is phrased in a somewhat more complicated and subtle manner.
This rule is commonly referred to as the one-deﬁnition rule ("the ODR").
That is, two deﬁnitions of a class, , or inline function are accepted as examples of the same unique deﬁnition if and only if [1] they appear in different translation units, and [2] they are token-for-token identical, and [3] the meanings of those tokens are the same in both translation units.
The ODR says that this example is valid and that S refers to the same class in both source ﬁles.
However, it is unwise to write out a deﬁnition twice like that.
Someone maintaining ﬁle2_0_cpp will naturally assume that the deﬁnition of S in ﬁle2_0_cpp is the only deﬁnition of S and so feel free to change it.
This could introduce a hard-to-detect error.
The intent of the ODR is to allow inclusion of a class deﬁnition in different translation units from a common source ﬁle.
Here the two deﬁnitions of S3 are token-for-token identical, but the example is an error because the meaning of the name X has sneakily been made to differ in the two ﬁles.
Checking against inconsistent class deﬁnitions in separate translation units is beyond the ability of most Cplus_plus implementations.
Consequently, declarations that violate the ODR can be a source of subtle errors.
Unfortunately, the technique of placing shared deﬁnitions in headers and #includeing them doesn't protect against this last form of ODR violation.
Local type aliases and macros can change the meaning of #included declarations: // s_0_h:.
The best defense against this kind of hackery is to make headers as self-contained as possible.
For example, if class Point had been declared in the s_0_h header, the error would have been detected.
A template deﬁnition can be #included in sev eral translation units as long as the ODR is adhered to.
This applies even to function template deﬁnitions and to class templates containing member function deﬁnitions.
No sufﬁx is needed for standard-library headers; they are known to be headers because they are included using the #include<_0__0__0_> syntax rather than #include"_0__0__0_".
The absence of a _0_h sufﬁx does not imply anything about how the header is stored.
A header such as <map> is usually stored as a text ﬁle called map_0_h in some standard directory.
On the other hand, standard headers are not required to be stored in a conventional manner.
An implementation is allowed to take advantage of knowledge of the standard-library deﬁnition to optimize the standard-library implementation and the way standard headers are handled.
For example, an implementation might have knowledge of the standard math library (40_0_3) built in and treat #include<cmath> as a switch that makes the standard math functions available without actually reading any ﬁle.
For each C standard-library header <X_0_h>, there is a corresponding standard Cplus_plus header <cX>.
For example, #include<cstdio> provides what #include<stdio_0_h> does.
A typical stdio_0_h will look something like this: #ifdef __cplusplus namespace std { extern "C" { #endif /* _0__0_.
The macro __cplusplus is deﬁned by the Cplus_plus compiler (12_0_6_0_2) and can be used to distinguish Cplus_plus code from code intended for a C compiler.
Similarly, it is common for Cplus_plus code fragments to be used as parts of programs written mainly in some other language (e_0_g_0_, Python or Matlab).
Cooperation can be difﬁcult between program fragments written in different languages and even between fragments written in the same language but compiled with different compilers.
For example, different languages and different implementations of the same language may differ in their use of machine registers to hold arguments, the layout of arguments put on a stack, the layout of built-in types such as strings and integers, the form of names passed by the compiler to the linker, and the amount of type checking required from the linker.
To help, one can specify a linkage convention to be used in an extern declaration.
For example, this declares the C and Cplus_plus standard-library function strcpy() and speciﬁes that it should be linked according to the (system-speciﬁc) C linkage conventions: ptg10564057 Section 15_0_2_0_5 Linkage to Non-Cplus_plus Code 429 extern "C" char∗ strcpy(char∗, const char∗); The effect of this declaration differs from the effect of the "plain" declaration extern char∗ strcpy(char∗, const char∗); only in the linkage convention used for calling strcpy().
The extern "C" directive is particularly useful because of the close relationship between C and Cplus_plus.
Note that the C in extern "C" names a linkage convention and not a language.
Often, extern "C" is used to link to Fortran and assembler routines that happen to conform to the conventions of a C implementation.
An extern "C" directive speciﬁes the linkage convention (only) and does not affect the semantics of calls to the function.
In particular, a function declared extern "C" still obeys the Cplus_plus type-checking and argument conversion rules and not the weaker C rules.
This technique is commonly used to produce a Cplus_plus header from a C header.
Alternatively, conditional compilation (12_0_6_0_1) can be used to create a common C and Cplus_plus header: #ifdef __cplusplus extern "C" {.
Any declaration can appear within a linkage block:.
This looks odd at ﬁrst glance.
However, it is a simple consequence of keeping the meaning unchanged when adding "C" to an extern-declaration and the meaning of a ﬁle unchanged when enclosing it in a linkage block.
A name with C linkage can be declared in a namespace.
The namespace will affect the way the name is accessed in the Cplus_plus program, but not the way a linker sees it.
The printf() from std is a typical example:.
Even when called std::printf, it is still the same old C printf() (43_0_3).
Note that this allows us to  libraries with C linkage into a namespace of our choice rather than polluting the global namespace.
Unfortunately, the same ﬂexibility is not available to us for headers deﬁning functions with Cplus_plus linkage in the global namespace.
The reason is that linkage of Cplus_plus entities must take namespaces into account so that the object ﬁles generated will reﬂect the use or lack of use of namespaces.
If the two implementations of the two languages share linkage conventions and function call mechanisms, such passing of pointers to functions is trivial.
However, such commonality cannot in general be assumed, so care must be taken to ensure that a function is called the way it expects to be called.
When linkage is speciﬁed for a declaration, the speciﬁed linkage applies to all function types, function names, and variable names introduced by the declaration(s).
This makes all kinds of strange – and occasionally essential – combinations of linkage possible.
For example: ptg10564057 Section 15_0_2_0_6 Linkage and Pointers to Functions 431.
An implementation in which C and Cplus_plus use the same calling conventions might accept the declarations marked error as a language extension.
However, even for compatible C and Cplus_plus implementations, std::function (33_0_5_0_3) or lambdas with any form of capture (11_0_4_0_3) cannot cross the language barrier.
That's the initial organization I would use for a simple program for my own use; if something more elaborate turned out to be needed, I would reorganize later.
For the calculator program, we might use ﬁve _0_cpp ﬁles – lexer_0_cpp, parser_0_cpp, table _0_cpp, error_0_cpp, and main_0_cpp – to hold function and data deﬁnitions.
The header dc_0_h holds the declarations of every name used in more than one _0_cpp ﬁle: ptg10564057 432 Source Files and Programs Chapter 15.
The keyword extern is used for every variable declaration to ensure that multiple deﬁnitions do not occur as we # dc_0_h in the various _0_cpp ﬁles.
The corresponding deﬁnitions are found in the appropriate _0_cpp ﬁles.
I added standard-library headers as needed for the declarations in dc_0_h, but I did not add declarations (such as using-declarations) needed only for the convenience of an individual _0_cpp ﬁle.
Leaving out the actual code, lexer_0_cpp will look something like this:.
The distinction between the user interface and the interface for implementers would be even clearer had we used a Parser_impl namespace (14_0_3_0_3).
The user's interface in header parser_0_h is #included to giv e the compiler a chance to check consistency (15_0_3_0_1).
The functions implementing the parser are stored in parser_0_cpp together with # directives for the headers that the Parser functions need:.
For a larger system, it is usually worthwhile to separate out the driver and minimize what is done in main().
That way main() calls a driver function placed in a separate source ﬁle.
This is particularly important for code intended to be used as a library.
Then, we cannot rely on code in main() and must be prepared for the driver to be called from a variety of functions.
Many of these factors have more to do with the way ﬁles are handled on your system than with Cplus_plus.
For example, if your editor/IDE does not make it convenient to look at several ﬁles simultaneously, then using many headers becomes less attractive.
However, if you partition the declarations of a large program into the logically minimal-size headers (putting each structure declaration in its own ﬁle, etc_0_), you can easily get an unmanageable mess of hundreds of ﬁles even for minor projects.
I ﬁnd that excessive.
For large projects, multiple headers are unavoidable.
In such projects, hundreds of ﬁles (not counting standard headers) are the norm.
The real confusion starts when they begin to be counted in the thousands.
At that scale, the basic techniques discussed here still apply, but their management becomes a Herculean task.
Tools, such as dependency analysers, can be of great help, but there is little they can do for compiler and linker performance if the program is an unstructured mess.
Remember that for realistically sized programs, the single-header style is not an option.
Such programs will have multiple headers.
The choice between the two styles of organization occurs (repeatedly) for the parts that make up the program.
The single-header style and the multiple-header style are not really alternatives.
They are complementary techniques that must be considered whenever a signiﬁcant module is designed and must be reconsidered as a system evolves.
It's crucial to remember that one interface doesn't serve all equally well.
It is usually worthwhile to distinguish between the implementers' interface and the users' interface.
In addition, many larger systems are structured so that providing a simple interface for the majority of users and a more extensive interface for expert users is a good idea.
The expert users' interfaces ("complete interfaces") tend to # many more features than the average user would ever want to know about.
In fact, the average users' interface can often be identiﬁed by eliminating features that require the inclusion of headers that deﬁne facilities that would be unknown to the average user.
The term "average user" is not derogatory.
In the ﬁelds in which I don't have to be an expert, I strongly prefer to be an average user.
In that way, I minimize hassles.
Viewed from the program as a whole, many of the declarations needed to make each logical module complete are redundant.
For larger programs, such redundancy can lead to errors, as a header containing class deﬁnitions or inline functions gets #included twice in the same compilation unit (15_0_2_0_3).
We hav e two choices.
We can [1] reorganize our program to remove the redundancy, or [2] ﬁnd a way to allow repeated inclusion of headers.
The ﬁrst approach – which led to the ﬁnal version of the calculator – is tedious and impractical for realistically sized programs.
We also need that redundancy to make the individual parts of the program comprehensible in isolation.
The beneﬁts of an analysis of redundant #includes and the resulting simpliﬁcations of the program can be signiﬁcant both from a logical point of view and by reducing compile times.
However, it can rarely be complete, so some method of allowing redundant #includes must be applied.
Preferably, it must be applied systematically, since there is no way of knowing how thorough an analysis a user will ﬁnd worthwhile.
For example: // error_0_h: #ifndef CALC_ERROR_H.
Thus, the ﬁrst time error_0_h is seen during a compilation, its contents are read and CALC_ERROR_H is given a value.
Should the compiler be presented with error_0_h again during the compilation, the contents are ignored.
This is a piece of macro hackery, but it works and it is pervasive in the C and Cplus_plus worlds.
The standard headers all have  guards.
Header ﬁles are included in essentially arbitrary contexts, and there is no namespace protection against macro name clashes.
Consequently, I choose rather long and ugly names for my guards.
Once people get used to headers and  guards, they tend to  lots of headers directly and indirectly.
Even with Cplus_plus implementations that optimize the processing of headers, this can be undesirable.
It can cause unnecessarily long compile time, and it can bring lots of declarations and macros into scope.
The latter might affect the meaning of the program in unpredictable and adverse ways.
Headers should be included only when necessary.
Every function, object, type, etc_0_, used in this collection must have a unique deﬁnition (6_0_3, 15_0_2_0_3).
A program must contain exactly one function called main() (2_0_2_0_1).
The main computation performed by the program starts with the invocation of the global function main() and ends with a return from main().
The return type of main() is int, and the following two versions of main() are supported by all implementations: int main() { /* _0__0_.
In addition, an implementation can allow other versions of main().
The argc, argv version is used to transmit arguments from the program's environment; see 10_0_2_0_7.
The int returned by main() is passed to whatever system invoked main() as the result of the program.
A nonzero return value from main() indicates an error.
This simple story must be elaborated on for programs that contain global variables (15_0_4_0_1) or that throw an uncaught exception (13_0_5_0_2_0_5).
Such nonlocal variables in a translation unit are initialized in their deﬁnition order.
If such a variable has no explicit initializer, it is by default initialized to the default for its type (17_0_3_0_3).
The default initializer value for built-in types and enumerations is 0.
Here,  and y are initialized before , so sqrt(2) is called.
There is no guaranteed order of initialization of global variables in different translation units.
Consequently, it is unwise to create order dependencies between initializers of global variables in different compilation units.
In addition, it is not possible to catch an exception thrown by the initializer of a global variable (13_0_5_0_2_0_5).
It is generally best to minimize the use of global variables and in particular to limit the use of global variables requiring complicated initialization.
Several techniques exist for enforcing an order of initialization of global variables in different translation units.
However, none are both portable and efﬁcient.
In particular, dynamically linked libraries do not coexist happily with global variables that have complicated dependencies.
Often, a function returning a reference is a good alternative to a global variable.
Like other uses of static, this technique is not thread-safe.
The initialization of a local static is thread-safe (42_0_3_0_3).
In this case, the initialization is even with a constant expression (10_0_4), so that it is done at link time and not subject to data races (42_0_3_0_3).
However, the plus_plus can lead to a data race.
The initialization of nonlocal (statically allocated) variables is controlled by whatever mechanism an implementation uses to start up a Cplus_plus program.
This mechanism is guaranteed to work properly only if main() is executed.
Consequently, one should avoid nonlocal variables that require run-time initialization in Cplus_plus code intended for execution as a fragment of a non-Cplus_plus program.
Note that variables initialized by constant expressions (10_0_4) cannot depend on the value of objects from other translation units and do not require run-time initialization.
Such variables are therefore safe to use in all cases.
The obvious answer is "3 and 2_0_" Why.
The initialization of a statically allocated object with a constant expression is done at link time, so  becomes 3.
Howev er, 's initializer is not a constant expression (sqrt() is no constexpr), so  is not initialized until run time.
However, the order of initialization of statically allocated objects in a single translation unit is well deﬁned: they are initialized in deﬁnition order (15_0_4_0_1).
The ﬂaw in this argument is that if multiple threads are used (5_0_3_0_1, 42_0_2), each will do the run-time initialization.
No mutual exclusion is implicitly provided to prevent a data race.
Then, sqrt(plus_plusx) in one thread may happen before or after the other thread manages to increment.
To avoid such problems, we should (as usual):.
Minimize the use of statically allocated objects and keep their initialization as simple as possible.
Avoid dependencies on dynamically initialized objects in other translation units (15_0_4_0_1).
In addition, to avoid data races in initialization, try these techniques in order: [1] Initialize using constant expressions (note that built-in types without initializers are initialized to zero and that standard containers and strings are initialized to empty by linktime initialization).
If a program is terminated using the standard-library function exit(), the destructors for constructed static objects are called (15_0_4_0_1, 16_0_2_0_12).
However, if the program is terminated using the standard-library function abort(), they are not.
Note that this implies that exit() does not terminate a program immediately.
Calling exit() in a destructor may cause an inﬁnite recursion.
The type of exit() is: void exit(int); ptg10564057 444 Source Files and Programs Chapter 15 Like the return value of main() (2_0_2_0_1), exit()'s argument is returned to "the system" as the value of the program.
Zero indicates successful completion.
Calling exit() means that the local variables of the calling function and its callers will not have their destructors invoked.
Throwing an exception and catching it ensures that local objects are properly destroyed (13_0_5_0_1).
Also, a call of exit() terminates the program without giving the caller of the function that called exit() a chance to deal with the problem.
It is therefore often best to leave a context by throwing an exception and letting a handler decide what to do next.
For example, main() may catch every exception (13_0_5_0_2_0_2).
The C (and Cplus_plus) standard-library function atexit() offers the possibility to have code executed at.
This strongly resembles the automatic invocation of destructors for global variables at program termination (15_0_4_0_1, 16_0_2_0_12).
An argument to atexit() cannot take arguments or return a result, and there is an implementation-deﬁned limit to the number of atexit functions.
A nonzero value returned by atexit() indicates that the limit is reached.
These limitations make atexit() less useful than it appears at ﬁrst glance.
Basically, atexit() is a C workaround for the lack of destructors.
The destructor of a constructed statically allocated object (6_0_4_0_2) created before a call of atexit(f) will be invoked after f is invoked.
The destructor of such an object created after a call of atexit(f) will be invoked before f is invoked.
The quick_exit() function is like exit() except that it does not invoke any destructors.
You register functions to be invoked by quick_exit() using at_quick_exit().
The exit(), abort(), quick_exit(), atexit(), and at_quick_exit() functions are declared  <cstdlib>.
Techniques commonly called object-oriented programming and generic programming are presented.
Chapters 16 Classes 17 Construction, Cleanup, Copy, and Move 18 Operator Overloading 19 Special Operators 20 Derived Classes 21 Class Hierarchies 22 Run-Time Type Information 23 Templates 24 Generic Programming 25 Specialization 26 Instantiation 27 Templates and Hierarchies 28 Metaprogramming 29 A Matrix Design ptg10564057 448 Abstraction Mechanisms Part III "_0__0_.
For the reformer makes enemies of all those who proﬁt by the old , and only lukew arm defenders  all ptg10564057 16 Classes Those  are not "abstract"; they are as real as int and ﬂoat.
Class Basics Member Functions; Default Copying; Access Control; class and struct; Constructors; explicit Constructors; In-Class ; In-Class  Deﬁnitions; Mutability; Self-Reference; Member Access; static Members; Member Types.
Concrete Classes Member Functions; Helper Functions; Overloaded Operators; The Signiﬁcance of Concrete Classes.
Advice 16_0_1 Introduction Cplus_plus classes are a tool for creating new  that can be used as conveniently as the built-.
In addition, derived classes (3_0_2_0_4, Chapter 20) and templates (3_0_4, Chapter 23) allow the programmer to express (hierachical and parametric) relationships among classes and to take advantage of such relationships.
A  is a concrete representation of a concept (an idea, a notion, etc_0_).
For example, the Cplus_plus built-  ﬂoat with its operations +, −, ∗, etc_0_, provides a concrete approximation of the mathematical concept of a real number.
A class is a user-deﬁned.
We design a new  to provide a deﬁnition of a concept that has no direct counterpart among the built-.
For example, we might provide a  Trunk_line  a program dealing with telephony, a  Explosion for a video game, or a  list<Paragraph> for a text-processing program.
A program that provides  that closely match the concepts of the application tends to be easier to understand, easier to reason about, and easier to modify than a program that does not.
A well-chosen set of user-deﬁned ptg10564057 450 Classes Chapter 16 also makes a program more concise.
In addition, it makes many sorts of code analysis feasible.
In particular, it enables the compiler to detect illegal uses of objects that would otherwise be found only through exhaustive testing.
The fundamental idea in deﬁning a new  is to separate the incidental details of the implementation (e_0_g_0_, the layout of the data used to store an object of the ) from the properties essential to the correct use of it (e_0_g_0_, the complete list of functions that can access the data).
Such a separation is best expressed by channeling all uses of the data structure and its internal housekeeping routines through a speciﬁc interface.
This chapter focuses on relatively simple "concrete" user-deﬁned  that logically don't differ much from built-in : 16_0_2 Class  introduces the basic facilities for deﬁning a class and its members.
The following chapters go into greater detail and presents abstract classes and class hierarchies: Chapter 17 Construction, Cleanup, Copy, and Move presents the variety of ways to control initialization of objects of a class, how to copy and move objects, and how to provide "cleanup actions" to be performed when an object is destroyed (e_0_g_0_, goes out of scope).
Chapter 18 Operator Overloading explains how to deﬁne unary and binary operators (such as +, ∗, and _0_) for user-deﬁned  and how to use them.
Chapter 19 Special Operators considers how to deﬁne and use operators (such as [], (), −>, )  are "special" in  they are commonly used in ways  differ from arithmetic and logical operators.
In particular, this chapter shows how to deﬁne a string class.
Chapter 20 Derived Classes introduces the basic language features supporting object-oriented programming.
Base and derived classes, virtual functions, and access control are covered.
Chapter 21 Class  focuses on the use of base and derived classes to effectively organize code around the notion of class hierarchies.
Most of this chapter is devoted to discussion of programming techniques, but technical aspects of multiple inheritance (classes with more than one base class) are also covered.
Chapter 22 Run-Time Type Information describes the techniques for explicitly navigating class hierarchies.
In particular, the  conversion operations dynamic_cast and static_cast are presented, as is the operation for determining the  of an object given one of its base classes (typeid).
A class is a user-deﬁned.
A class consists of a set of members.
The most common kinds of members are data members and member functions.
Member functions can deﬁne the meaning of initialization (creation), copy, move, and cleanup (destruction).
Members are accessed using.
Operators, such as +, _0_, and [], can be deﬁned for a class.
A class is a namespace containing its members.
The public members provide the class's interface and the private members provide implementation details.
A struct is a class where members are by default public.
For example: class X { private: // the representation (implementation) is private.
The style is tutorial: a gradual development of ideas, with details postponed until later.
Such a connection can be established by declaring the functions as members: ptg10564057 452 Classes Chapter 16.
For example, when ::init() is invoked for today, =mm assigns to today_0_.
On the other hand, when ::init() is invoked for my_bir thday, =mm assigns to my_bir thday_0_.
A class member function "knows" for which object it was invoked.
But see 16_0_2_0_12 for the notion of a static member.
In particular, a  class object can be initialized with a copy of an object of its class.
For example: 1 = my_bir thday; // initialization by copy 2 {my_bir thday}; // initialization by copy ptg10564057 Section 16_0_2_0_2 Default Copying 453 By default, the copy of a class object is a copy of each member.
If  default is not the behavior wanted for a class X, a more appropriate behavior can be provided (3_0_3, 17_0_5).
Similarly, class objects can by default be copied by assignment.
Again, the default semantics is memberwise copy.
If  is not the right choice for a class X, the user can deﬁne an appropriate assignment operator (3_0_3, 17_0_5).
This restriction can be expressed by using a class instead of a struct: class  {.
The public label separates the class body into two parts.
The names in the ﬁrst, private, part can be used only by member functions.
The second, public, part constitutes the public interface to objects of the class.
A struct is simply a class whose members are public by default (16_0_2_0_4); member functions can be deﬁned and used exactly as before.
For example, any error causing a  to take on an illegal value (for example, December 36, 2016) must be caused by code in a member function.
This implies that the ﬁrst stage of debugging – localization – is completed before the program is even run.
This is a special case of the general observation that any change to the behavior of the type  can and must be effected by changes to its members.
In particular, if we change the  of a class, we need only change the member functions to take advantage of the new.
User code directly depends only on the public interface and need not be rewritten (although it may need to be recompiled).
Another advantage is that a potential user need examine only the deﬁnitions of the member functions in order to learn to use a class.
A more subtle, but most signiﬁcant, advantage is that focusing on the design of a good interface simply leads to better code because thoughts and time otherwise devoted to debugging are expended on concerns related to proper use.
The protection of private data relies on restriction of the use of the class member names.
It can therefore be circumvented by address manipulation (7_0_4_0_1) and explicit type conversion (11_0_5).
But this, of course, is cheating.
Cplus_plus protects against accident rather than deliberate circumvention (fraud).
Only hardware can offer perfect protection against malicious use of a general-purpose language, and even that is hard to do in realistic systems.
For historical reasons, a class deﬁnition is often referred to as a class declaration.
Also, like declarations that are not deﬁnitions, a class deﬁnition can be replicated in different source ﬁles using #include without violating the one-deﬁnition rule (15_0_2_0_3).
By deﬁnition, a struct is a class in which members are by default public; that is, struct S { /* _0__0_.
Which style you use depends on circumstances and taste.
I tend to use struct for classes that I think of as "just simple data structures_0_" If I think of a class as "a proper type with an invariant," I use class.
Constructors and access functions can be quite useful even for structs, but as a shorthand rather than guarantors of invariants (2_0_4_0_3_0_2, 13_0_4).
By default, members of a class are private: class 1 {.
It is not a requirement to declare data ﬁrst in a class.
In fact, it often makes sense to place data members last to emphasize the functions providing the public user interface.
For example: class 3 {.
Access speciﬁers can be used many times in a single class declaration.
For example: class 4 { public: 4(int dd, int mm, int yy);.
So does having more than one private section.
However, allowing many access speciﬁers in a class is useful for machine-generated code.
Because it is nowhere stated that an object must be initialized, a programmer can forget to do so – or do so twice (often with equally disastrous results).
A better approach is to allow the programmer to declare a function with the explicit purpose of initializing objects.
Because such a function constructs values of a given type, it is called a constructor.
A constructor is recognized by having the same name as the class itself.
For example: ptg10564057 456 Classes Chapter 16 class  {.
There are cases where () notation must be used (4_0_4_0_1, 17_0_3_0_2_0_1), but they are rare.
By providing several constructors, we can provide a variety of ways of initializing objects of a type.
When designing a class, a programmer is always tempted to add features just because somebody might want them.
It takes more thought to carefully decide what features are really needed and to include only those.
However, that extra thought typically leads to smaller and more comprehensible programs.
One way of ptg10564057 Section 16_0_2_0_5 Constructors 457 reducing the number of related functions is to use default arguments (12_0_2_0_5).
In addition (or alternatively), we can make the association explicit by enclosing the class and its helper functions in a namespace (14_0_3_0_1):.
The Chrono namespace would naturally also contain related classes, such as Time and Stopwatch, and their helper functions.
Using a namespace to hold a single class is usually an overelaboration that leads to inconvenience.
Naturally, the helper function must be deﬁned somewhere:.
A  shouldn't be outside the jan to dec range, but it is possible (someone might have been sloppy with a cast), so I check.
The troublesome default_date ﬁnally becomes:.
These operators are deﬁned in Chrono together with  to avoid overload problems  to beneﬁt from argument-dependent lookup (14_0_2_0_4).
For , these operators can be seen as mere conveniences.
However, for many types – such as complex numbers (18_0_3), vectors (4_0_4_0_1),  function-like objects (3_0_4_0_3, 19_0_2_0_2) – the use of conventional operators is so ﬁrmly entrenched in people's minds that their deﬁnition is almost mandatory.
Operator overloading is discussed in Chapter 18.
Had I done so, I would have followed a common idiom (3_0_2_0_1_0_1).
Note that assignment  copy initialization are provided by default (16_0_3, 17_0_3_0_3).
Concrete classes are used just like built-in types.
Concrete types have also been called value types  their use value-oriented programming.
Their model of use  the "philosophy" behind their design are quite different from what is often called object-oriented programming (3_0_2_0_4, Chapter 21).
The intent of a concrete  is to do a single, relatively simple thing well  efﬁciently.
It is not usually the aim to  the user with facilities to modify the behavior of a concrete.
In particular, concrete types are not intended to display run-time polymorphic behavior (see 3_0_2_0_3, 20_0_3_0_2).
If you don't like some detail of a concrete , you build a new  with the desired behavior.
If you want to "reuse" a concrete , you use it in the implementation of your new  exactly as you would have used an int.
For example: class Date_and_time { private:.
Alternatively, the derived class mechanism discussed in Chapter 20 can be used to deﬁne new types from a concrete class by describing the desired differences.
The deﬁnition of Vec from vector (4_0_4_0_1_0_2) is an example of this.
However, derivation from a concrete class should be done with care  only rarely because of the lack of virtual functions  run-time  information (17_0_5_0_1_0_4, Chapter 22).
With a reasonably good compiler, a concrete class such as  incurs no hidden overhead in time or space.
In particular, no indirection through pointers is necessary for access to objects of concrete classes,  no "housekeeping" data is stored in objects of concrete classes.
The size of a concrete  is known at compile time so that objects can be allocated on the run-time stack (that is, without free-store operations).
The layout of an object is known at compile time so that inlining of operations is trivially achieved.
Similarly, layout compatibility with other languages, such as C Fortran, comes without special effort.
A good set of such types can  a foundation for applications.
In particular, they can be used to make interfaces more speciﬁc  less error-prone.
For example: Month do_something( ); This is far less likely to be misunderstood or misused than: int do_something(int ); Lack of concrete types can lead to obscure programs  time wasted when each programmer writes code to directly manipulate "simple  frequently used" data structures represented as ptg10564057 Section 16_0_3_0_4 The Signiﬁcance of Concrete Classes 479 simple aggregates of built-in types.
Alternatively, lack of suitable "small efﬁcient types" in an application can lead to gross run-time  space inefﬁciencies when overly general  expensive classes are used.
Where applicable, prefer a concrete  over more complicated classes  over plain data structures; 16_0_3.
Constructors  Destructors Constructors  Invariants; Destructors  Resources; Base  Member Destructors; Calling Constructors  Destructors; virtual Destructors.
Class  Initialization Initialization Without Constructors; Initialization Using Constructors; Default Constructors; Initializer-List Constructors.
Member  Base Initialization Member Initialization; Base ; Delegating Constructors; In-Class ; static Member Initialization.
Copy  Move Copy; Move.
Generating Default Operations Explicit Defaults; Default Operations; Using Default Operations; deleted Functions.
Advice 17_0_1 Introduction This chapter focuses on technical aspects of an object's "life cycle": How do we create an object, how do we copy it, how do we move it around, and how do we clean up after it when it goes away.
What are proper deﬁnitions of "copy" and "move".
For example: ptg10564057 482 Construction, Cleanup, Copy, and Move Chapter 17 string ident(string arg).
Next, we construct 2 with the value "Prachett" and copy it into 1.
Finally, at the exit from main() we destroy the variables 1 and 2.
The difference between move and copy is that after a copy two objects must have the same value, whereas after a move the source of the move is not required to have its original value.
Moves can be used when the source object will not be used again.
They are particularly useful for implementing the notion of moving a resource (3_0_2_0_1_0_2, 5_0_2).
Several functions are used here:.
A move constructor moving the value of a string (from arg out of ident() into a temporary.
A move assignment moving the value of a string (from the temporary variable holding the.
A destructor releasing the resources owned by 1, 2, and the temporary variable holding the An optimizer can eliminate some of this work.
For example, in this simple example the temporary variable is typically eliminated.
However, in principle, these operations are executed.
Constructors, copy and move assignment operations, and destructors directly support a view of lifetime and resource management.
An object is considered an object of its type after its constructor completes, and it remains an object of its type until its destructor starts executing.
The interaction between object lifetime and errors is explored further in 13_0_2 and 13_0_3.
In particular, this chapter doesn't discuss the issue of half-constructed and half-destroyed objects.
Construction of objects plays a key role in many designs.
This wide variety of uses is reﬂected in the range and ﬂexibility of the language features supporting initialization.
Constructors, destructors, and copy and move operations for a type are not logically separate.
We must deﬁne them as a matched set or suffer logical or performance problems.
If a class X has a destructor that performs a nontrivial task, such as free-store deallocation or lock release, the class is likely to need the full complement of functions: ptg10564057 Section 17_0_1 Introduction 483.
There are ﬁve situations in which an object is copied or moved:.
As the source of an assignment.
As an object initializer.
As a function argument.
As an exception In all cases, the copy or move constructor will be applied (unless it can be optimized away).
In addition to the initialization of named objects and objects on the free store, constructors are used to initialize temporary objects (6_0_4_0_2) and to implement explicit type conversion (11_0_5).
Except for the "ordinary constructor," these special member functions can be generated by the compiler; see 17_0_6.
This chapter is full of rules and technicalities.
Those are necessary for a full understanding, but most people just learn the general rules from examples.
To complement constructors, we can deﬁne a destructor to ensure "cleanup" at the point of destruction of an object (e_0_g_0_, when it goes out of scope).
Some of the most effective techniques for resource management in Cplus_plus rely on constructor/destructor pairs.
So do other techniques relying on a pair of actions, such as do/undo, start/stop, before/after, etc.
Often, that initialization must establish a class invariant, that is, something that must hold whenever a member function is called (from outside the class).
Consider: class Vector { public: Vector(int );.
For example: ptg10564057 Section 17_0_2_0_1 Constructors and Invariants 485.
This constructor tries  establish the invariant and if it cannot, it throws an exception.
If the constructor cannot establish the invariant, no object is created and the constructor must ensure that no resources are leaked (5_0_2, 13_0_3).
A resource is anything we need  acquire and eventually (explicitly or implicitly) give back (release) once we are ﬁnished with it.
Examples of resources are memory (3_0_2_0_1_0_2), locks (5_0_3_0_4), ﬁle handles (13_0_3), and thread handles (5_0_3_0_1).
Why would you deﬁne an invariant.
To simplify the documentation of the class On average, the effort  deﬁne an invariant ends up saving work.
In other words, it creates the environment in which the member functions operate.
Sometimes, creating that environment involves acquiring a resource – such as a ﬁle, a lock, or some memory – that must be released after use (5_0_2, 13_0_3).
Thus, some classes need a function that is guaranteed  be invoked when an object is destroyed in a manner similar the way a constructor is guaranteed  be invoked when an object is created.
Inevitably, such a function is called a destructor.
The name of a destructor is ˜ followed by the class name, for example ˜Vector().
One meaning of ˜ is "complement" (11_0_1_0_2), and a destructor for a class complements its constructors.
A destructor does not take an argument, and a class can have only one destructor.
Destructors are called implicitly when an automatic variable goes out of scope, an object on the free store is deleted, etc.
Only in very rare circumstances does the user need  call a destructor explicitly (17_0_2_0_4).
Destructors typically clean up and release resources.
For example: class Vector {.
In both cases, ' destructor  invoked  free (deallocate) the memory allocated by the constructor.
What if the constructor failed  acquire enough memory.
For example, ∗sizeof() or (+)∗sizeof() may be larger than the amount of available memory (measured in bytes).
In that case, an exception std::bad_alloc (11_0_2_0_3)  thrown by new  the exception-handling mech freed (13_0_5_0_1).
This style of constructor/destructor-based resource management  called Resource Acquisition Is Initialization or simply RAII (5_0_2, 13_0_3).
A matching constructor/destructor pair  the usual mechanism for implementing the notion of a variably sized object in Cplus_plus.
Standard-library containers, such as   unordered_map, use variants of this technique for providing storage for their elements.
A type that has no destructor declared, such as a built-in type,  considered  have a destructor that does nothing.
A programmer who declares a destructor for a class must also decide if objects of that class can be copied or moved (17_0_6).
A constructor builds a class object "from the bottom up": [1] ﬁrst, the constructor invokes its base class constructors, [2] then, it invokes the member constructors, [3] ﬁnally, it executes its own body.
A destructor "tears down" an object in the reverse order: [1] ﬁrst, the destructor executes its own body, [2] then, it invokes its member destructors, [3] ﬁnally, it inv okes its base class destructors.
In particular, a virtual base  constructed before any base that might use it  destroyed after all such bases (21_0_3_0_5_0_1).
This ordering ensures that a base or a member  not used before it has been initialized or used after it has been destroyed.
The programmer can defeat this simple ptg10564057 Section 17_0_2_0_3 Base  Member Destructors 487 essential rule, but only through deliberate circumvention involving passing pointers to uninitialized variables as arguments.
Doing so violates language rules  the results are usually disastrous.
Constructors execute member  base constructors in declaration order (not the order of initializers): if two constructors used a different order, the destructor could not (without serious overhead) guarantee to destroy in the reverse order of construction.
If a class  used so that a default constructor  needed,  if the class does not have other constructors, the compiler will try to generate a default constructor.
Default constructors are very common.
For example: ptg10564057 494 Construction, Cleanup, Copy,  Move Chapter 17 class Vector {.
A default argument (12_0_2_0_5) can make  constructor that takes arguments into  default constructor.
For example: class String { public:.
However, for  built-in type the default constructor is not invoked for uninitialized non-static variables (17_0_3) default value of  built-in type is 0 for integers, 0_0_0 for ﬂoating-point types,  nullptr for pointers.
References  consts must be initialized (7_0_7, 7_0_5).
Therefore,  class containing such members cannot be default constructed unless the programmer supplies in-class member initializers (17_0_4_0_4)  deﬁnes  default constructor that initializes them (17_0_4_0_1).
In such cases,  default constructor is obviously required for  class used as the element type of    array.
It is  good idea not to be too clever when inventing default values.
For example, the problem with containers of elements without default values is often best solved by not allocating elements until you have proper values for them (e_0_g_0_,  push_back()).
An initializer- constructor is used to construct objects   {}- as its initializer ptg10564057 496 Construction, Cleanup, Copy,  Move Chapter 17 value.
Standard-library containers (e_0_g_0_,   ) hav e initializer- constructors, assignments, etc.
That is, all elements must be of the template argument type, ,  implicitly convertible to.
For selecting  constructor, default  initializer lists take precedence.
If either  default constructor  an initializer- constructor could be invoked, prefer the default constructor.
If both an initializer- constructor  an "ordinary constructor" could be invoked, prefer the initializer- constructor.
Furthermore, if you deﬁne an initializer- constructor to do something with an empty  that differs from what the default constructor does, you probably have  design error on your hands.
The second rule, "prefer the initializer- constructor," is necessary to avoid different resolutions based on different numbers of elements.
In every case, the initializer- constructor is used.
If we really want to invoke the constructor taking one or two integer arguments, we must use the () notation: <> 1(1); <> 2(1,2); // one element with the value 2 17_0_3_0_4_0_2 Use of initializer_lists.
Unfortunately,  doesn't provide subscripting.
An <> is passed by value.
That is required by the overload resolution rules (12_0_3) and does not impose overhead because an <> object is just a small handle (typically two words) to an array of Ts.
That loop could equivalently have been written:.
The elements of an  are immutable.
Don't even think about trying to modify their values.
That would have done serious damage to some of our most fundamental concepts.
Because  elements are immutable, we cannot apply a move constructor (3_0_3_0_2, 17_0_5_0_2) to them.
A container might implement an initializer- constructor like this: template<class E> class Vector { public:.
For a container, this implies that the distinction is applied to both the container and its elements: ptg10564057 Section 17_0_3_0_4_0_3 Direct and Copy Initialization 499.
The container's initializer- constructor can be explicit or not.
The constructor of the element type of the initializer  can be explicit or not.
For a <<double>>, we can see the direct initialization.
This example was carefully crafted to give an example of the most confusing cases.
Note that the apparent ambiguities (in the eyes of the human reader but not the compiler) do not emerge for longer lists.
For example: <double> 1 {7,8,9}; // OK: 1 has three elements with values {7,8,9} <double> 2 = {9,8,7}; // OK: 2 has three elements with values {9,8,7} ptg10564057 500 Construction, Cleanup, Copy, and Move Chapter 17.
Generally, they do that by initializing class members and base classes.
The member initializer list starts with a colon, and the individual member initializers are separated by commas.
The constructors are called in the order in which the members are declared in the class rather than the order in which the members appear in the initializer list.
To avoid confusion, it is best to specify the initializers in the member declaration order.
Hope for a compiler warning if you don't get the order right.
The member destructors are called in the reverse order of construction after the body of the class's own destructor has been executed.
If a member constructor needs no arguments, the member need not be mentioned in the member initializer list.
This constructor is equivalent to the previous version.
In each case, Club::ofﬁcers and Club::members are initialized to a  with no elements.
It is usually a good idea to be explicit about initializing members.
Note that an "implicitly initialized" member of a built-in type is left uninitialized (17_0_3_0_1).
A constructor can initialize members and bases of its class, but not members or bases of its members or bases.
A reference member or a const member must be initialized (7_0_5, 7_0_7, 17_0_3_0_3).
However, for most types the programmer has a choice between using an initializer and using an assignment.
In that case, I usually prefer to use the member initializer syntax to make it explicit that initialization is being done.
Often, there also is an efﬁciency advantage to using the initializer syntax (compared to using an assignment).
For example: ptg10564057 502 Construction, Cleanup, Copy, and Move Chapter 17.
Here name is initialized with a copy of n.
On the other hand,  is ﬁrst initialized to the empty string and then a copy of a is assigned.
That is, if a base requires an initializer, it must be provided as a base initializer in a constructor.
If we want to, we can explicitly specify default construction.
As with members, the order of initialization is the declaration order, and it is recommended to specify base initializers in that order.
Bases are initialized before members and destroyed after members (17_0_2_0_3).
Both "solutions" are common (because older versions of Cplus_plus didn't offer anything better).
For example: ptg10564057 Section 17_0_4_0_3 Delegating Constructors 503 class X {.
That is,  member-style initializer using the class's own name (its constructor name) calls another constructor as part of the construction.
Such  constructor is called  delegating constructor (and occasionally  forwarding constructor).
You cannot both delegate and explicitly initialize  member.
For example: class X {.
The X{42} simply creates  new  object ( temporary) and does nothing with it.
Hope for  compiler warning.
An object is not considered constructed until its constructor completes (6_0_4_0_2).
When using delegating constructor, the object is not considered constructed until the delegating constructor completes – just completing the delegated- constructor is not sufﬁcient.
A destructor will not be ptg10564057 504 Construction, Cleanup, Copy, and Move Chapter 17 called for an object unless its original constructor completed.
If all you need is  set  member   default value (that doesn't depend on  constructor argument),  member initializer (17_0_4_0_4) may be simpler.
For example: class A {.
By default,  constructor will use such an in-class initializer, so that example is equivalent : class A {.
Such use of in-class initializers can save  bit of typing, but the real beneﬁts come in more complicated classes with multiple constructors.
Often, several constructors use the same initializer for member.
For example: class A {.
To make the common values explicit, we can factor out the unique initializer for data members: class A {.
An in-class member initializer can use names that are in scope at the point of their use in the.
The value of the global variable is obtained at the point where the constructor for  new  object is run, so it can ( in this example does) change.
Next, m2 is initialized by  call  the global f().
It is  bad idea  hide subtle dependencies on global data in member initializers.
Generally, the static member declaration acts as  declaration for  deﬁnition outside the class.
However, for  few simple special cases, it is possible  initialize  static member in the class declaration.
The static member must be  const of an integral or enumeration type, or  constexpr of literal type (10_0_4_0_3),  the initializer must be  constant-expression.
For example: class Curious {.
For example: template<class T, int N> class Fixed {.
Copy is the conventional meaning of =y; that is, the effect is that the values of   y are both equal  y's value before the assignment.
Move leaves  with y's former value  y with some moved-from state.
The obvious alternative of copying the complete state of an object is called deep copy.
Often, the better alternative to deep copy is not a shallow copy, but a move operation, which minimizes copying without adding complexity (3_0_3_0_2, 17_0_5_0_2).
A shallow copy leaves two objects (here,  and y) with a shared state, and has a huge potential for confusion and errors.
We say that the objects  and y have become entangled when the requirement of independence have been violated.
It is not possible to reason about an entangled object in isolation.
For example, it is not obvious from the source code that the two assignments to ∗.
We can represent two entangled objects graphically: : y: shared state 's state: y's state: Note that entanglement can arise in a variety of ways.
Often, it is not obvious that entanglement has happened until probems arise.
For example, a type like S may incautiously be used as a member of an otherwise well-behaved class.
The original author of S may be aware of the entanglement and prepared to cope with it, but someone naively assuming that copying an S meant copying its complete value could be surprised, and someone who ﬁnds an S deeply nested in other classes could be very surprised.
We can address problems related to the lifetime of a shared subobject by introducing a form of garbage collection.
In fact, shallow copy and such entangled objects are among the sources of demands for garbage collection.
Entangled objects lead to code that is very hard to manage without some form of garbage collection (e_0_g_0_, shared_ptrs).
However, a  is still a pointer, so we cannot consider objects containing a  in isolation.
Who can update the pointed-to object.
If we are running in a multithreaded system, is synchronization needed for access to the shared data.
Entangled objects (here, resulting from a shallow copy) is a source of complexity and errors that is at best partially solved by garbage collection (in any form).
Note that an immutable shared state is not a problem.
Unless we compare addresses, we cannot tell whether two equal values happen to be represented as one or two copies.
This is a useful observation because many copies are never modiﬁed.
For example, objects passed by value are rarely written to.
This observation leads to the notion of copy-on-write.
The idea is that a copy doesn't actually need independence until a shared state is written to, so we can delay the copying of the shared state until just before the ﬁrst write to it.
Consider: class Image {.
Then, depending on the use of Images, it can make sense to implement the copy constructor as a shallow copy:.
We protect the argument to that copy constructor by copying the Representation before a write: ptg10564057 Section 17_0_5_0_1_0_3 The Meaning of Copy 513.
When applied to a copy operation, this simple and necessary rule (3_0_2_0_4, 20_0_2) leads to a trap for the unwary.
The variables 2 and  contain copies of the  part of d, that is, a copy of d_0_.
The member d_0_d is not copied.
This phenomenon is called slicing.
It may be exactly what you intended (e_0_g_0_, see the copy constructor for D in 17_0_5_0_1_0_2 where we pass selected information to a base class), but typically it is a subtle bug.
If you don't want slicing, you have two major tools to prevent it: ptg10564057 514 Construction, Cleanup, Copy, and Move Chapter 17 [1] Prohibit copying of the base class: delete the copy operations (17_0_6_0_4).
The former would make the initializations of 2 and  errors; the latter would make the call of naive() and the initialization of  errors.
For an integer in  computer's memory, that's just about the only thing that makes sense: that's what the hardware can do with  single instruction.
However, from  general and logical point of view that's not so.
Consider the obvious implementation of swap() exchanging the value of two objects: template<class >.
After the assignment to , we have two copies of 's value.
After the assignment to , we hav e two copies of 's value (that is, the original value of ).
That sounds like  lot of work, and it can be.
For example: void f(string& s1, string& s2, vector<string>& vs1, vector<string>& vs2,.
What if s1 has  thousand characters.
What if vs2 has  thousand elements each of  thousand characters.
What if m1 is  1000∗1000 matrix of doubles.
The cost of copying those data structures could be signiﬁcant.
In fact, the standard-library swap() has always been carefully designed to avoid such overhead for string and vector.
That is, effort has been made to avoid copying (taking advantage of the fact that string and vector objects really are just handles to their elements).
Similar work must be done to avoid  serious performance problem for swap() of Matrixes.
If the only operation we have is copy, similar work must be done for huge numbers of functions and data structures that are not part of the standard.
The fundamental problem is that we really didn't want to do any copying at all: we just wanted to exchange pairs of values.
We can also look at the issue of copying from  completely different point of view: we don't usually copy physical things unless we absolutely have to.
If you want to borrow my phone, I pass my phone to you rather than making you your own copy.
If I lend you my car, I giv e you  key and ptg10564057 Section 17_0_5_0_2 Move 515 you drive away in my car, rather than in your freshly made copy of my car.
Once I have giv en you an object, you have it and I no longer do.
Consequently, we talk about "giving away," "handing over," "transferring ownership of," and "moving" physical objects.
Many objects in  computer resemble physical objects (which we don't copy without need and only at considerable cost) more than integer values (which we typically copy because that's easier and cheaper than alternatives).
Examples are locks, sockets, ﬁle handles, threads, long strings, and large vectors.
To allow the user to avoid the logical and performance problems of copying, Cplus_plus directly supports the notion of moving as well as the notion of copying.
In particular, we can deﬁne move constructors and move assignments to move rather than copy their argument.
Consider again the simple two-dimensional Matrix from 17_0_5_0_1: template<class > class  {.
The idea behind  move assignment is to handle lvalues separately from rvalues: copy assignment and copy constructors take lvalues whereas move assignment and move constructors take rvalues.
We can deﬁne 's move constructor to simply take the representation from its source and replace it with an empty  (which is cheap to destroy).
For example: template<class >.
For the move assignment, we can simply do  swap.
The idea behind using  swap to implement move assignment is that the source is just about to be destroyed, so we can just let the destructor for the source do the necessary cleanup work for us: ptg10564057 516 Construction, Cleanup, Copy, and Move Chapter 17 template<class >.
Move constructors and move assignments take non-const (rvalue) reference arguments: they can, and usually do, write to their argument.
However, the argument of  move operation must always be left in  state that the destructor can cope with (and preferably deal with very cheaply and easily).
For resource handles, move operations tend to be signiﬁcantly simpler and more efﬁcient than copy operations.
In particular, move operations typically do not throw exceptions; they don't acquire resources or do complicated operations, so they don't need to.
In this, they differ from many copy operations (17_0_5).
How does the compiler know when it can use  move operation rather than  copy operation.
In  few cases, such as for  return value, the language rules say that it can (because the next action is deﬁned to destroy the element).
However, in general we have to tell it by giving an rvalue reference argument.
For example: template<class >.
It would have been better if move() had been called rval(), but the name move() has been used for this operation for years.
Standard-library containers have move operations (3_0_3_0_2, 35_0_5_0_1) and so have other standardlibrary types, such as pair (5_0_4_0_3, 34_0_2_0_4_0_1) and unique_ptr (5_0_2_0_1, 34_0_3_0_1).
Furthermore, operations that insert new  into standard-library containers, such as insert() and push_back(), have versions that take rvalue references (7_0_7_0_2).
The net result is that the standard containers and algorithms deliver better performance than they would have been able to if they had to copy.
What if we try to swap objects of  type that does not have  move constructor.
We copy and pay the price.
In general,  programmer is responsible for avoiding excessive copying.
It is not the compiler's job to decide what is excessive and what is necessary.
To get the copy-to-move optimization for your own data structures, you have to provide move operations (either explicitly or implicitly; see 17_0_6).
Built-in types, such as int and double∗, are considered to have move operations that simply copy.
As usual, you have to be careful about data structures containing pointers (3_0_3_0_1).
In particular, don't assume that  moved-from pointer is set to nullptr.
How does the object created by new  deleted.
Do we need  garbage collector.
Should we use  pool of Matrixes rather than the general new.
Do we need use-counted  representations.
Should we redesign the interface of our  addition.
Must the caller of +() remember to delete the result.
What happens to the newly allocated memory if the computation throws an exception.
None of the alternatives are elegant or general.
By default,  class provides:.
However, if the programmer takes control by deﬁning one or more of those operations, the generation of related operations is suppressed:.
If the programmer declares any constructor for  class, the default constructor is not generated for that class.
If the programmer declares  copy operation,  move operation, or  destructor for  class, no copy operation, move operation, or destructor is generated for that class.
Unfortunately, the second rule is only incompletely enforced: for backward compatibility, copy constructors and copy assignments are generated even if  destructor is deﬁned.
However, that generation is deprecated in the ISO standard (iso_0_D), and you should expect  modern compiler to warn against it.
If necessary, we can be explicit about which functions are generated (17_0_6_0_1) and which are not (17_0_6_0_4).
Also, some people prefer to see  complete list of operations in the program text even if that complete list is not needed.
For example, we can write:.
Someone assuming that it is better to write something, rather than nothing, might write: ptg10564057 Section 17_0_6_0_1 Explicit Defaults 519.
This is not only verbose, making it harder to read the deﬁnition of , but also opens the opportunity for making mistakes.
For example, I might forget to copy one of the members and  it default initialized (rather than copied).
Also, when the user provides  function, the compiler no longer knows the semantics of that function and some optimizations become inhibited.
For the default operations, those optimizations can be signiﬁcant.
That is, we memberwise copy, memberwise default construction, etc.
The copy construction of 1 copies 0_0_a and 0_0_b.
The return of 1 moves 1_0_a and 1_0_b, leaving 1_0_a as the empty string and 1_0_b unchanged.
Note that the value of a moved-from object of a built-in type is unchanged.
That' the simplest and fastest thing for the compiler to do.
If we want something else done for a member of a class, we have to write our move operations for that class.
The default moved-from state is one for which the default destructor and default copy assignment work correctly.
It is not guaranteed (or required) that an arbitrary operation on a moved-from object will work correctly.
If you need stronger guarantees, write your own operations.
If they were not linked, errors that are obvious when you think about them would not be caught by the compiler.
Here, () sets  to the empty string.
The "default initialization" of a built-in member leaves that member uninitialized.
Hope for a compiler warning.
If so, we want copy and move operations to maintain it and the destructor to free any resources involved.
Unfortunately, the compiler cannot in every case know what a programmer considers an invariant.
Consider a somewhat far-fetched example: struct Z { // invariant: // my_favor ite is the index of my favor ite element of elem.
The programmer stated an invariant in the comment, but the compiler doesn't read comments.
Furthermore, the programmer did not leave a hint about how that invariant is to be established and maintained.
In particular, there are no constructors or assignments declared.
That invariant is ptg10564057 Section 17_0_6_0_3_0_2 Maintaining Invariants 521 implicit.
The result is that a  can be copied and moved using the default operations: 0;.
The root problem is that  is badly designed because critical information is "hidden" in a comment or completely missing.
The rules for the generation of default operations are heuristic intended to catch common mistakes and to encourage a systematic approach to construction, copy, move, and destruction.
Wherever possible [1] Establish an invariant in a constructor (including possibly resource acquisition).
Consider a simple Handle: <class T> class Handle {.
Also,  declares a destructor: this suppresses the generation of copy and move operations.
Again, that saves us from a nasty problem.
Consider: ptg10564057 522 Construction, Cleanup, Copy, and Move Chapter 17.
Had  had a default copy constructor, both h1 and h2 would have had a copy of the pointer and both would have deleted it.
Caveat: the generation of copy operations is only deprecated, not banned, so if you ignore warnings, you might get this example past the compiler.
In general, if a class has a pointer member, the default copy and move operations should be considered suspicious.
If that pointer member represents ownership, memberwise copy is wrong.
If that pointer member does not represent ownership and memberwise copy is appropriate,  =default and a comment are most likely a good idea.
If we wanted copy construction, we could deﬁne something like: <class >.
Troublesome examples that rely on invariants but only partially express them through constructors or destructors are rarer but not unheard of.
It uses the "magic number" 9 to implement a copy assignment that accesses its argument arg without checking that the argument actually has nine elements.
Also, it explicitly implements the copy assignment, but not the copy constructor.
That destructor  be =default because all it needs to do is to ensure that the member pos is destroyed, which is what would have been done anyway had the copy assignment not been deﬁned.
At this point, we notice that the user-deﬁned copy assignment is essentially the one we would have gotten by default, so we =default that also.
Add a copy constructor for completeness and we get: class  {.
When we made the copy  =default, we eliminated the nasty dependence on the magic constant 9.
Unless other operations on , not mentioned so far, are also "hardwired with magic numbers," we  safely add move operations simplest way to do that is to remove the  =defaults, and then we see that  is really a perfectly ordinary type: class  { public:.
For every class, we should ask: [1] Is a default constructor needed (because the default one is not adequate or has been suppressed by another constructor).
In particular, we should never just consider one of  operations in isolation.
For example, it is common to want to prevent the copying of classes used as bases because such copying easily leads to slicing (17_0_5_0_1_0_4):.
Enabling and disabling copy and move is typically more conveniently done by saying what we want ( =default; 17_0_6_0_1) rather than saying what we don't want ( =delete).
However, we delete any function that we  declare.
For example, we  eliminate a specialization from the set of possible specializations of a function : <class >.
Note the difference between  =deleted function and one that simply has not been declared.
In the former case, the compiler notes that the programmer has tried to use the deleted function and gives an error.
In the latter case, the compiler looks for alternatives, such as not invoking  destructor or   global  ().
Operator Functions Binary and Unary Operators; Predeﬁned Meanings for Operators; Operators and UserDeﬁned Types; Passing Objects; Operators in Namespaces.
A Complex Number Type Member and Nonmember Operators; Mixed-Mode Arithmetic; Conversions; Literals; Accessor Functions; Helper Functions.
Type Conversion Conversion Operators; explicit Conversion Operators; Ambiguities.
Advice 18_0_1 Introduction Every technical ﬁeld – and most nontechnical ﬁelds – has developed conventional shorthand notation to make convenient the presentation and discussion involving frequently used concepts.
For example, because of long acquaintance, x+y∗z is clearer to us than multiply y by z and add the result to x It is hard to overestimate the importance of concise notation for common operations.
Like most languages, Cplus_plus supports  set of operators for its built-in types.
However, most concepts for which operators are conventionally used are not built-in types in Cplus_plus, so they must be ptg10564057 528 Operator Overloading Chapter 18 represented as user-deﬁned types.
For example, if you need complex arithmetic, matrix algebra, logic signals, or character strings in Cplus_plus, you use classes to represent these notions.
Deﬁning operators for such classes sometimes allows  programmer to provide  more conventional and convenient notation for manipulating objects than could be achieved using only the basic functional notation.
Consider: class complex {.
This deﬁnes  simple implementation of the concept of complex numbers.
A complex is represented by  pair of double-precision ﬂoating-point numbers manipulated by the operators + and ∗.
The programmer deﬁnes complex::operator+() and complex::operator∗() to provide meanings for + and ∗, respectively.
For example, if  and  are of type complex, + means _0_operator+().
However, the usefulness of user-deﬁned operators is not restricted to numeric types.
For example, the design of general and abstract interfaces often leads to the use of operators such as −>, [], and ().
Allowing them to be overloaded would lead to subtleties [Stroustrup,1994].
The named "operators"cannot be overloaded because they report fundamental facts about their operands: sizeof alignof typeid Finally, the ternary conditional expression  cannot be overloaded (for no particularly fundamental reason): _0_: In addition, user-deﬁned literals (19_0_2_0_6) are deﬁned by using the "" notation.
This is kind of syntactic subterfuge because there is no  called "".
Similarly,  T() deﬁnes conversion to  type T (18_0_4).
It is not possible to deﬁne   tokens, but you can use the function call notation when this set of operators is not adequate.
For example, use pow(), not ∗∗.
These restrictions may seem Draconian, but more ﬂexible rules can easily lead to ambiguities.
For example, deﬁning an  ∗∗ to mean exponentiation may seem an obvious and easy task, but think again.
Should ∗∗ bind to the left (as in Fortran) or to the right (as in Algol).
Should the expression ∗∗p be interpreted as ∗(∗p) or as ()∗∗(p).
There are solutions to all such technical questions.
However, it is most uncertain if applying subtle technical rules will lead to more readable and maintainable code.
If in doubt, use  named function.
The name of an  function is the keyword  followed by the  itself, for example, <<.
An  function is declared and can be called like any other function.
A use of the  is only  shorthand for an explicit call of the  function.
For example: ptg10564057 530 Operator Overloading Chapter 18.
Given the previous deﬁnition of complex, the two initializers are synonymous.
For any binary  @, aa@bb can be interpreted determines which, if any, interpretation is used.
For any preﬁx unary @, @aa can be interpreted as either aa_0_@() or @(aa).
If both are deﬁned, overload resolution (12_0_3) determines which, if any, interpretation is used.
For any postﬁx unary @, aa@ can be interpreted as either aa_0_@(int) or @(aa,int).
If both are deﬁned, overload resolution (12_0_3) determines which, if any, interpretation is used.
An  can be declared only for the syntax deﬁned for it in the grammar (iso_0_A).
For example, a user cannot deﬁne a unary % or a ternary +.
The operators = (18_0_2_0_2), [] (19_0_2_0_1), () (19_0_2_0_2), and −> (19_0_2_0_3) must be non-static member functions.
This special rule does not hold for user-deﬁned versions of &&, ||, and , (comma); instead these  are treated exactly like other binary.
For example, if  is an int, plus_plusa means +=1, which in turn means =+1.
Such relations do not hold for user-deﬁned  unless the user deﬁnes them to.
For example,  compiler will not generate  deﬁnition of ::+=() from the deﬁnitions of ::+() and ::=().
These predeﬁned meanings can be eliminated ("deleted";.
This rule ensures that  user cannot change the meaning of an expression unless the expression contains an object of  user-deﬁned type.
In particular, it is not possible to deﬁne an  function that operates exclusively on pointers.
This ensures that Cplus_plus is extensible but not mutable (with the exception of  =, &, , for class objects).
An  function intended to accept  built-in type (6_0_2_0_1) as its ﬁrst operand cannot be member function.
For example, consider adding  complex variable aa to the integer 2: aa+2 can, with  suitably declared member function, be interpreted as aa_0_+(2), but 2+aa cannot because there is no class int for which to deﬁne + to mean 2_0_+(aa).
Even if there were, two different member functions would be needed to cope with 2+aa  aa+2.
Because the compiler does not know the meaning of  user-deﬁned +, it cannot assume that the  is commutative  so interpret 2+aa as aa+2.
This example is trivially handled using one or more nonmember functions (18_0_3_0_2, 19_0_4).
Enumerations are user-deﬁned types so that we can deﬁne  for them.
Every expression is checked for ambiguities.
Where  user-deﬁned  provides  possible interpretation, the expression is checked according to the overload resolution rules in 12_0_3.
Consequently, we hav e limited choices of how to pass arguments to the  function how it returns its value.
For example, we cannot require pointer arguments  expect programmers to use the address-of  or return  pointer  expect the user to dereference it: ∗=&b+& is not acceptable.
For arguments, we have two main choices (12_0_2):.
Pass-by-reference For small objects, say, one to four words, call-by-value is typically  viable alternative  often the one that gives the best performance.
However, performance of argument passing  use depends on machine architecture, compiler interface conventions (Application Binary Interfaces; ABIs), the number of times an argument is accessed (it almost always is faster to access an argument passed by value than one passed by reference).
For example, assume that   is represented as pair of ints: void ::+=( delta); // pass-by-value ptg10564057 Section 18_0_2_0_4 Passing Objects 533 Larger objects, we pass by reference.
For example, because  Matrix ( simple matrix of doubles; 17_0_5_0_1) is most likely larger than  few words, we use pass-by-reference: Matrix +(const Matrix&, const Matrix&); // pass-by-const-reference In particular, we use const references to pass large objects that are not meant to be modiﬁed by the called function (12_0_2_0_1).
Typically, an  returns  result.
Returning  pointer or  reference to  newly created object is usually  very bad idea: using  pointer gives notational problems,  referring to an object on the free store (whether by  pointer or by  reference) results in memory management problems.
Instead, return objects by value.
For large objects, such as  , deﬁne move operations to make such transfers of values efﬁcient (3_0_3_0_2, 17_0_5_0_2).
If  function simply passes an object to another function, an rvalue reference argument should be used (17_0_4_0_3, 23_0_5_0_2_0_1, 28_0_6_0_3).
Consider this simpliﬁed version of string I/O from the standard library:.
In other words, I was on my best behavior didn't pollute the global namespace or in other ways introduce unnecessary dependencies.
In particular,  is in namespace std, so std is considered when looking for  suitable deﬁnition of <<.
In that way, the compiler ﬁnds  uses: Consider  binary  @.
If x is of type   y is of type Y, x@y is resolved like this:.
If  is  class, look for @ as  member of  or as  member of  base of ;.
Declarations for several @ may be found  overload resolution rules (12_0_3) are used to ﬁnd the best match, if any.
This lookup mechanism is applied only if the  has at least one ptg10564057 Section 18_0_2_0_5 Operators in Namespaces 535 operand of  user-deﬁned type.
Therefore, user-deﬁned conversions (18_0_3_0_2, 18_0_4) will be considered.
Note that  type alias is just  synonym  not  separate user-deﬁned type (6_0_5).
Unary  are resolved analogously.
Note that in  lookup no preference is given to members over nonmembers.
This differs from lookup of named functions (14_0_2_0_4).
The lack of hiding of  ensures that built-in operators are never inaccessible and that users can supply new  for an  without modifying existing class declarations.
In particular, the standard iostream library deﬁnes << member functions to output built-in types, and user can deﬁne << to output user-deﬁned types without modifying class ostream (38_0_4_0_2).
For example, we would expect this to work:.
In addition, we would expect to be provided with  few additional operators, such  == for comparison and << for output, and  suitable set of mathematical functions, such  sin() and sqrt().
Class  is  concrete type, so its design follows the guidelines from 16_0_3.
In addition, users of  arithmetic rely so heavily on operators that the deﬁnition of  brings into play most of the basic rules for  overloading.
The  type developed in this section uses double for its scalars and is roughly equivalent to the standard-library <double> (40_0_4).
This can be achieved by deﬁning only operators that inherently modify the  of their ﬁrst argument, such  +=, in the class itself.
Operators that simply produce  new  based on the values of their arguments, such  +, are then deﬁned outside the class and use the essential operators in their implementation: ptg10564057 536 Operator Overloading Chapter 18 class  {.
Except for possible efﬁciency differences, the computations of 1  2 are equivalent.
Composite assignment operators such  +=  ∗= tend to be simpler to deﬁne than their "simple" counterparts +  ∗.
This surprises most people at ﬁrst, but it follows from the fact that three objects are involved in  + operation (the two operands  the result), whereas only two objects are involved in  += operation.
In the latter case, run-time efﬁciency is improved by eliminating the need for temporary variables.
This does not require  temporary variable to hold the result of the addition  is simple for compiler to inline perfectly.
A good optimizer will generate close to optimal code for uses of the plain +  also.
However, we don't always have  good optimizer,  not all types are  simple  , so 19_0_4 discusses ways of deﬁning operators with direct access to the representation of classes.
In Fortran terminology, we need mixed-mode arithmetic.
We can achieve that simply by adding appropriate versions of the operators: ptg10564057 Section 18_0_3_0_2 Mixed-Mode Arithmetic 537 class  {.
I added the integer addition for completeness.
For example: class  { double , ;.
A constructor is  prescription for creating   of  given type.
The constructor is used when   of  type is expected  when such   can be created by  constructor from the supplied  an initializer or assigned.
Thus,  constructor requiring  single argument need not be called explicitly.
For example: {3}; means {3,0}; A user-deﬁned conversion is implicitly applied only if it is unique (12_0_3).
If you don't want  constructor to be used implicitly, declare it explicit (16_0_2_0_6).
Naturally, we still need the constructor that takes two doubles,   default constructor initializing   to {0,0} is also useful:.
Using default arguments, we can abbreviate: ptg10564057 Section 18_0_3_0_3 Conversions 539 class  {.
This can get tedious,  what is tedious easily becomes error-prone.
What if we had three alternatives for the type of each argument for each function.
We would need three versions of each single-argument function, nine versions of each two-argument function, 27 versions of each threeargument function, etc.
Often these variants are very similar.
In fact, almost all variants involve simple conversion of arguments to  common type followed by  standard algorithm.
The alternative to providing different versions of  function for each combination of arguments is to rely on conversions.
For example, our  class provides  constructor that converts double to.
Consequently, we could simply declare only one version of the equality  for : bool ==(,);.
For example, in some cases the conversion can impose overhead,  in other cases,  simpler algorithm can be used for speciﬁc argument types.
Where such issues are not signiﬁcant, relying on conversions  providing only the most general variant of  function – plus possibly  few critical variants – contain the ptg10564057 540 Operator Overloading Chapter 18 combinatorial explosion of variants that can arise from mixed-mode arithmetic.
The name of a literal  is "" followed by the.
The basic (implementation) idea is that after parsing what could be a literal, the compiler always checks for a sufﬁx.
The user-deﬁned literal mechanism simply allows the user to specify a ptg10564057 Section 19_0_2_0_6 User-deﬁned Literals 559 sufﬁx  deﬁne what is to be done with the literal before it.
It is not possible to redeﬁne the meaning of a built-in literal sufﬁx or to augment the syntax of literals.
There are four kinds of literals that can be sufﬁxed to make a user-deﬁned literal (iso_0_2_0_14_0_8):.
An integer literal (6_0_2_0_4_0_1): accepted by a literal  taking an unsigned long long or a const char∗ argument or by a  literal , for example, 123m or 12345678901234567890X.
A ﬂoating-point literal (6_0_2_0_5_0_1): accepted by a literal  taking a long double or a const char∗ argument or by a literal , for example, 12345678901234567890_0_976543210x or 3_0_99.
A string literal (7_0_3_0_2): accepted by a literal  taking a (const char∗, size_t) pair of arguments, for example, "string"  R"(Foo\bar)"_path.
A character literal (6_0_2_0_3_0_2): accepted by a literal operator taking a character argument of type char, wchar_t, char16_t, or char32_t, for example, 'f'_runic or u'BEEF'_w.
For example, we could deﬁne a literal operator to collect digits for integer values that cannot be represented in any of the built-in integer types:.
Note that I did not put those digits in double quotes.
I requested a C-style string for my operator, and the compiler delivered it from the digits provided.
To get a C-style string from the program source text into a literal operator, we request both the string and its number of characters.
For example: string operator"" (const char∗ , size_t n); string 12 = "one two";.
In the raw string (7_0_3_0_2_0_1), "\n" represents the two characters '\' and 'n'.
The rationale for requiring the number of characters is that if we want to have "a different kind of string," we almost always want to know the number of characters anyway.
A literal operator that takes just a const char∗ argument (and no size) can be applied to integer and ﬂoating-point literals.
For example: string operator"" SS(const char∗ ); // warning: this will not wor k as expected string 12 = "one two"SS; // error : no applicable literal operator string 13 = 13SS; // OK, but why would anyone do that.
A literal operator converting numerical values to strings could be quite confusing.
For example: <char_0__0__0_> constexpr int operator"" _b3(); // base 3, i_0_e_0_, ternar y Given that, we get:.
This String is a simpliﬁed version of the standard-library string (4_0_2, Chapter 36).
String provides value semantics, checked and unchecked access to characters, stream I/O, support for range-for loops, equality operations, and concatenation operators.
I also added a String literal, which std::string does not (yet) have.
To allow simple interoperability with C-style strings (including string literals (7_0_3_0_2)), I represent strings as zero-terminated arrays of characters.
For realism, I implement the short string optimization.
That is, a String with only a few characters stores those characters in the class object itself, rather than on the free store.
This optimizes string usage for small strings.
Experience shows that for a huge number of applications most strings are short.
This optimization is particularly important in multi-threaded systems where sharing through pointers (or references) is infeasible and free-store allocation and deallocation relatively expensive.
To allow Strings to efﬁciently "grow" by adding characters at the end, I implement a scheme for keeping extra space for such growth similar to the one used for vector (13_0_6_0_1).
This makes a suitable target for various forms of input.
Writing a better string class and/or one that provides more facilities is a good exercise.
That done, we can throw away our exercises and use std::string (Chapter 36).
This  has value semantics.
That is, after an assignment 1=2, the two strings 1 and 2 are fully distinct, and subsequent changes to one have no effect on the other.
The alternative would be to give  pointer semantics.
That would be to let changes to 2 after 1=2 also affect the value of 1.
Where it makes sense, I prefer value semantics; examples are complex, vector, Matrix, and string.
Howev er, for value semantics to be affordable, we need to pass Strings by reference when we don't need copies and to implement move semantics (3_0_3_0_2, 17_0_5_0_2) to optimize returns.
The slightly nontrivial representation of  is presented in 19_0_3_0_3.
Note that it requires user-deﬁned versions of the copy and move operations.
Unfortunately, you cannot have all of these properties simultaneously.
Here, I follow the standard library by providing operations: class  {.
The idea is to use [] for ordinary use.
For example: ptg10564057 Section 19_0_3_0_2 Access to Characters 563.
I personally prefer a checked [] at least during development.
However, for serious string manipulation tasks, a range check on each character access could impose quite noticeable overhead.
I provide const and non-const versions of the access functions to allow them to be used for const as well as other objects.
To make it easy to convert a C-style string (e_0_g_0_, a string literal) to a  and to allow easy access to the characters of a  as a C-style string.
To minimize the use of the free store.
To make adding characters to the end of a  efﬁcient The result is clearly messier than a simple {pointer,} representation, but much more realistic: class  { /* A simple string that implements the short str ing optimization ()== is the number of elements if ()<= , the characters are held in the  object itself; otherwise the free store is used.
This supports what is known as the short string optimization by using two string representations:.
The member named space is the number of such characters.
In both cases, the number of elements is kept in  and we look at , to determine which implementation scheme is used for a given string.
In both cases, ptr points to the elements.
This is essential for performance: the access functions do not need to test which representation is used; they simply use ptr.
Only the constructors, assignments, moves, and the destructor (19_0_3_0_4) must care about the two alternatives.
We use the array ch only if <= and the integer space only if _0_(<=).
Consequently, it would be a waste to allocate space for both ch and space in a  object.
To avoid such waste, I use a union (8_0_3).
In particular, I used a form of union called an anonymous union (8_0_3_0_2), which is speciﬁcally designed to allow a class to manage alternative representations of objects.
All members of an anonymous union are allocated in the same memory, starting at the same address.
Only one member may be used at any one time, but otherwise they are accessed and used exactly as if they were separate members of the scope surrounding the anonymous union.
It is the programmer' job to make sure that they are never misused.
For example, all member functions of  that use space must make sure that it really was space that was set and not ch.
In other words, Shape is (among other things) a discriminated union with <= as the discriminant.
Tw o of those need to access the representation of , so I made them members.
However, I made them private members because they don't represent operations that are generally useful and safe to use.
For many interesting classes, the implementation is not just the representation plus the public functions.
Ancillary functions can lead to less duplication of code, better design, and improved maintainability.
The ﬁrst such function moves characters into newly allocated memory:.
Any necessary cleanup of the target  is the task of callers of copy_from(); copy_from() unconditionally overwrites its target.
I use the standard-library memcpy() (43_0_5) to copy the bytes of the source into the target.
That' a low-level and sometimes pretty nasty function.
It should be used only where there are no objects with constructors or destructors in the copied memory because memcpy() knows nothing about types.
Both  copy operations use copy_from().
The corresponding function for move operations is:.
For example, many "object-oriented" user interfaces deﬁne a set of requests to which every object represented on the screen should be prepared to respond.
In addition, such requests can be presented directly or indirectly from programs.
Consider a simple variant of this idea: class Std_interface {.
The exact meaning of each operation is deﬁned by the object on which it is invoked.
Often, there is a layer of software between the person or program issuing the request and the object receiving it.
Ideally, such intermediate layers of software should not have to know anything about the individual operations such as () and ().
If they did, the intermediate layers would have to be updated each time an operation changed.
Consequently, such intermediate layers simply transmit data representing the operation to be invoked from the source of the request to its recipient.
For example, to invoke () we could send the string "".
Howev er, someone has to create that string and someone has to decode it to determine to which operation it corresponds – if any.
Often, that seems indirect and tedious.
Instead, we might simply send an integer representing the operation.
For example, 2 might be used to mean ().
Howev er, while an integer may be convenient for machines to deal with, it can get pretty obscure for people.
We still have to write code to determine that 2 means () and to invoke ().
However, we can use a pointer to member to indirectly refer to a member of a class.
If I want to invoke () for some object without mentioning () directly, I need a pointer to member referring to Std_interface::().
I also need a pointer or reference to the object I want to.
Consider a trivial example:.
A variable of type "pointer to member of class X" is declared using a declarator of the form X::∗.
The use of an alias to compensate for the lack of readability of the C declarator syntax is typical.
However, please note how the X::∗ declarator matches the traditional ∗ declarator exactly.
A pointer to member m can be used in combination with an object.
The operators −>∗ and _0_∗ allow the programmer to express such combinations.
For example, p−>∗m binds m to the object pointed to by p, and obj_0_∗m binds m to the object obj.
The result can be used in accordance with m' type.
It is not possible to store the result of a −>∗ or a _0_∗ operation for later use.
Naturally, if we knew which member we wanted to call, we would invoke it directly rather than mess with pointers to members.
Just like ordinary pointers to functions, pointers to member functions are used when we need to refer to a function without having to know its name.
However, a pointer to member isn't a pointer to a piece of memory the way a pointer to a variable or a pointer to a function is.
It is more like an offset into a structure or an index into an array, but of course an implementation takes into account the differences between data members, virtual functions, nonvirtual functions, etc.
When a pointer to member is combined with a pointer to an object of the right type, it yields something that identiﬁes a particular member of a particular object.
The p−>∗() call can be represented graphically like this: X:: X:: vtbl: : p ptg10564057 Section 20_0_6_0_1 Pointers to Function Members 609 Because a pointer to a virtual member ( in this example) is a kind of offset, it does not depend on an object' location in memory.
A pointer to a virtual member can therefore be passed between different address spaces as long as the same object layout is used in both.
Like pointers to ordinary functions, pointers to non-virtual member functions cannot be exchanged between address spaces.
Note that the function invoked through the pointer to function can be virtual.
For example, when we call () through a pointer to function, we get the right () for the object to which the pointer to function is applied.
This is an essential aspect of pointers to functions.
When writing an interpreter, we might use pointers to members to invoke functions presented as.
The type of a pointer to function is checked just like any other type.
This implies that we can safely assign a pointer to a member of a base class to a pointer to a member of a derived class, but not the other way around.
This property is often called contravariance.
For example: class Text : public  {.
This contravariance rule appears to be the opposite of the rule that says we can assign a pointer to a derived class to a pointer to its base class.
In fact, both rules exist to preserve the fundamental guarantee that a pointer may never point to an object that doesn't at least have the properties that the pointer promises.
In this case, ::∗ can be applied to any , and most such objects presumably are not of type Te xt.
Consequently, they do not have the member Te xt::print with which we tried to initialize.
By refusing the initialization, the compiler saves us from a run-time error.
Design of  Hierarchies Implementation Inheritance; Interface Inheritance; Alternative Implementations; Localizing Object Creation.
Multiple Inheritance Multiple Interfaces; Multiple Implementation Classes; Ambiguity Resolution; Repeated Use of a Base ;  Base Classes; Replicated vs.
Advice 21_0_1 Introduction The primary focus of this chapter is design techniques, rather than language features.
The examples are taken from user-interface design, but I avoid the topic of event-driven programming as commonly used for graphical user interface (GUI) systems.
A discussion of exactly how an action on the screen is transformed into a call of a member function would add little to the issues of class hierarchy design and has a huge potential for distraction: it is an interesting and important topic in its own right.
For an understanding of GUI, have a look at one of the many Cplus_plus GUI libraries.
This can be done in a bewildering number of ways.
To insulate our program from this variety, and also to get a chance to explore the possible design choices, let us start by deﬁning our program's model of this simple input operation.
A program can ask an Ival_box for its value and ask it to prompt the user if necessary.
In addition, a program can ask an Ival_box if a user changed the value since the program last looked at it: value user application Ival_box: Because there are many ways of implementing this basic idea, we must assume that there will be many different kinds of Ival_boxes, such as sliders, plain boxes in which a user can type a number, dials, and voice interaction.
The general approach is to build a "virtual user-interface system" for the application to use.
This system provides some of the services provided by existing user-interface systems.
It can be implemented on a wide variety of systems to ensure the portability of application code.
Naturally, there are other ways of insulating an application from a user-interface system.
I chose this approach because it is general, because it allows me to demonstrate a variety of techniques and design tradeoffs, because those techniques are also the ones used to build "real" user-interface systems, and – most important – because these techniques are applicable to problems far beyond the narrow domain of interface systems.
In addition to ignoring the topic of how to map user actions (events) to library calls, I also ignore the need for locking in a multi-threaded GUI system.
In addition, we declare the data needed to implement the basic notion: class  {.
A realistic class would, for example, provide some range checking.
A programmer might use these "ival classes" like this:.
Most application code is written in terms of (pointers to) plain Ival_boxes the way interact() is.
That way, the application doesn't hav e to know about the potentially large number of variants of the concept.
The knowledge of such specialized classes is isolated in the relatively few functions that create such objects.
This isolates users from changes in the implementations of the derived classes.
Most code can be oblivious to the fact that there are different kinds of Ival_boxes.
I use  (5_0_2_0_1, 34_0_3_0_1) to avoid forgetting to delete the ival_boxes.
To simplify the discussion, I do not address issues of how a program waits for input.
Maybe the program really does wait for the user in get_value() (e_0_g_0_, using a get() on a future; 5_0_3_0_5_0_1), maybe the program associates the  with an event and prepares to respond to a callback, or maybe the program spawns a thread for the  and later inquires about the state of that thread.
Such decisions are crucial in the design of user-interface systems.
However, discussing them here in any realistic detail would simply distract from the presentation of programming techniques and language facilities.
The design techniques described here and the language facilities that support them are not speciﬁc to user interfaces.
They apply to a far greater range of problems.
The different kinds of Ival_boxes are deﬁned as classes derived from.
For example: class  : public  { private: // _0__0_.
A protected member is accessible from a class's own members and from members of derived classes, but not to general users (see 20_0_5).
In addition to , we would deﬁne other variants of the  concept.
These could include , which lets you select a  by turning a knob; Flashing_ival_slider, which ﬂashes when you ask it to prompt(); and Popup_ival_slider, which responds to prompt() by appearing in some prominent place, thus making it hard for the user to ignore.
From where would we get the graphics stuff.
Most user-interface systems provide a class deﬁning the basic properties of being an entity on the screen.
So, if we use the system from "Big Bucks Inc_0_," we would have to make each of our , , etc_0_, classes a kind of BBwidget.
This would most simply be achieved by rewriting our  so that it derives from BBwidget.
In that way, all our classes inherit all the properties of a BBwidget.
For example, every  can be placed on the screen, obey the graphical style rules, be resized, be dragged around, etc_0_, according to the standard set by the BBwidget system.
Our class hierarchy would look like this: class  : public BBwidget { /* _0__0_.
However, there are some awkward details that could lead us to look for alternative designs.
We retroﬁtted BBwidget as the base of.
This is not quite right (even if this style is common in real-world systems).
The use of BBwidget isn't part of our basic notion of an ; it is an implementation detail.
Deriving  from BBwidget elevated an implementation detail to a ﬁrst-level design decision.
For example, using the environment deﬁned by "Big Bucks Inc_0_" may be a key decision based on how our organization conducts its business.
However, what if we also wanted to have implementations of our Ival_boxes for systems from "Imperial ptg10564057 Section 21_0_2_0_1_0_1 Critique 617 Bananas," "Liberated Software," and "Compiler Whizzes".
We would have to maintain four distinct versions of our program:.
Having many versions could result in a version control nightmare.
In reality, we are unlikely to ﬁnd a simple, coherent, two-letter preﬁx scheme.
More likely, the libraries from different purveyors would be in different namespaces and use different terminologies for similar concepts, such as BigBucks::Widg et, Wizzies::control, and LS::window.
But that does not affect our class hierarchy design discussion, so to simplify I ignore naming and namespace issues.
Another problem is that every derived class shares the basic data declared in.
That data is, of course, an implementation detail that also crept into our  interface.
From a practical point of view, it is also the wrong data in many cases.
For example, an  doesn't need the stored speciﬁcally.
It can easily be calculated from the position of the slider when someone executes get_value().
In general, keeping two related, but different, sets of data is asking for trouble.
Sooner or later someone will get them out of sync.
Also, experience shows that novice programmers tend to mess with protected data in ways that are unnecessary and that cause maintenance problems.
Data members are better kept private so that writers of derived classes cannot mess with them.
Better still, data should be in the derived classes, where it can be deﬁned to match requirements exactly and cannot complicate the life of unrelated derived classes.
In almost all cases, a protected interface should contain only functions, types, and constants.
Deriving from BBwidget gives the beneﬁt of making the facilities provided by BBwidget available to users of Ival_box.
Unfortunately, it also means that changes to  BBwidget may force users to recompile or even rewrite their code to recover from such changes.
In particular, the way most Cplus_plus implementations work implies that a change in the size of a base  requires a recompilation of all derived classes.
Finally, our program may have to run in a mixed environment in which windows of different user-interface systems coexist.
This could happen either because two systems somehow share a screen or because our program needs to communicate with users on different systems.
Having our user-interface systems "wired in" as the one and only base of our one and only Ival_box interface just isn't ﬂexible enough to handle those situations.
Here, I present one that maps cleanly into the Cplus_plus language.
First, I specify  Ival_box as a pure interface: Ival_box {.
This is much cleaner than the original declaration of Ival_box.
The data is gone and so are the simplistic implementations of the member functions.
Gone, too, is the constructor, since there is no data for it to initialize.
Instead, I added a virtual destructor to ensure proper cleanup of the data that will be deﬁned in the derived classes.
The deﬁnition of Ival_slider might look like this: Ival_slider : public Ival_box, protected BBwidget {.
It also inherits from BBwidget which provides it with the means of doing so.
Since Ival_box provides the interface for the derived , it is derived using public.
Since BBwidget is only an implementation aid, it is derived using protected (20_0_5_0_2).
This implies that a programmer using Ival_slider cannot directly use facilities deﬁned by BBwidget.
The interface provided by Ival_slider is the one inherited from Ival_box, plus what Ival_slider explicitly declares.
I used protected derivation instead of the more restrictive (and usually safer) private derivation to make BBwidget available to classes derived from Ival_slider.
I used explicit override because this "widget hierarchy" is exactly the kind of large, complicated hierachy where being explicit can help minimize confusion.
Deriving directly from more than one  is usually called multiple inheritance (21_0_3).
Note that Ival_slider must override functions from both Ival_box and BBwidget.
Therefore, it must be derived directly or indirectly from both.
As shown in 21_0_2_0_1_0_1, deriving Ival_slider indirectly from BBwidget by making BBwidget a base of Ival_box is possible, but doing so has undesirable side ptg10564057 Section 21_0_2_0_2 Interface Inheritance 619 effects.
Similarly, making the "implementation " BBwidget a member of Ival_box is not a solution because a  cannot override virtual functions of its members.
Representing the window by a BBwidget∗ member in Ival_box leads to a completely different design with a separate set of tradeoffs.
To some people, the words "multiple inheritance" indicate something complicated and scary.
However, the use of one base  for implementation details and another for interface (the abstract ) is common to all languages supporting inheritance and compile-time checked interfaces.
In particular, the use of the abstract  Ival_box is almost identical to the use of an interface in Java or C#.
Interestingly, this declaration of Ival_slider allows application code to be written exactly as before.
All we have done is to restructure the implementation details in a more logical way.
Many classes require some form of cleanup for an object before it goes away.
Since the abstract Ival_box cannot know if a derived  requires such cleanup, it must assume that it does require some.
We ensure proper cleanup by deﬁning a virtual destructor Ival_box::˜Ival_box() in the base and overriding it suitably in derived classes.
The delete operator explicitly destroys the object pointed to by p.
We hav e no way of knowing exactly to which  the object pointed to by p belongs, but thanks to Ival_box's virtual destructor, proper cleanup as (optionally) deﬁned by that ' destructor will be done.
The Ival_box hierarchy can now be deﬁned like this: Ival_box { /* _0__0_.
General users cannot access the protected bases because they are (correctly) considered part of the implementation.
However, it still fails to solve the version control problem: Ival_box { /* _0__0_.
There is no way of having the Ival_slider for BBwidgets coexist with the Ival_slider for CWwidgets, ev en if the two user-interface systems could themselves coexist.
The obvious solution is to deﬁne several different Ival_slider classes with separate names: class Ival_box { /* _0__0_.
For example, if the "Big Bucks Inc_0_" system has a slider class, we can derive our Ival_slider directly from the BBslider: class BB_ival_slider : public Ival_slider, protected BBslider { /* _0__0_.
In that case, programming is reduced to mapping between similar concepts.
Derivation from general base classes, such as BBwidget, is then done only rarely.
The complete hierarchy will consist of our original application-oriented conceptual hierarchy of interfaces expressed as derived classes: class Ival_box { /* _0__0_.
Using obvious abbreviations, this hierarchy can be represented graphically like this: ptg10564057 622 Class Chapter 21 Ival_box Ival_slider Ival_dial iﬂash ipopup CWsl CWsl CWsl CWislider BBislider CWipop CWiﬂ BBipop BBiﬂ BBslider BBslider BBb&w The original Ival_box class hierarchy appears unchanged surrounded by implementation classes.
In the latter design, the windows class is the root of a tree.
In the former, the original application class hierarchy appears unchanged as the root of classes that supply its implementations.
From the application's point of view, these designs are equivalent in the strong sense that  all code works unchanged and in the same way in the two cases.
In either case, you can look at the Ival_box family of classes without bothering with the window-related implementation details most of the time.
For example, we would not need to rewrite interact() from 21_0_2_0_1 if we switched from one class hierarchy to the other.
In either case, the implementation of each Ival_box class must be rewritten when the public interface of the user-interface system changes.
However, in the abstract class design,  all user code is protected against changes to the implementation hierarchy and requires no recompilation after such a change.
This is especially important when the supplier of the implementation hierarchy issues a  " compatible" release.
In addition, users of the abstract class hierarchy are in less danger of being locked into a proprietary implementation than are users of a classical hierarchy.
Users of the Ival_box abstract class application hierarchy cannot accidentally use facilities from the implementation because only facilities explicitly speciﬁed in the Ival_box hierarchy are accessible; nothing is implicitly inherited from an implementation-speciﬁc base class.
The logical conclusion of this line of thought is a system represented to users as a hierarchy of abstract classes and implemented by a classical hierarchy.
Use abstract classes to support interface inheritance (3_0_2_0_3, 20_0_1).
Use base classes with implementations of virtual functions to support implementation inheritance (3_0_2_0_3, 20_0_1).
Further, should the derived interfaces evolve to provide more facilities than plain Ival_box, then most of an application can be written using the Ival_box, Ival_slider, etc_0_, interfaces.
However, the creation of objects must be done using implementation-speciﬁc names such as CW_ival_dial and BB_ﬂashing_ival_slider.
We would like to minimize the number of places where such speciﬁc names occur, and object creation is hard to localize unless it is done systematically.
As usual, the solution is to introduce an indirection.
A simple one is to introduce an abstract class to represent the set of creation operations: class Ival_maker {.
For each interface from the Ival_box family of classes that a user should know about, class Ival_maker provides a function that makes an object.
Such a class is sometimes called a factory, and its functions are (somewhat misleadingly) sometimes called virtual constructors (20_0_3_0_6).
We now represent each user-interface system by a class derived from Ival_maker: class BB_maker : public Ival_maker {.
Given an Ival_maker, a user can now create objects without having to know exactly which userinterface system is used.
For example: ptg10564057 624 Class Chapter 21.
Passing arguments to such "virtual constructors" is a bit tricky.
In particular, we cannot override the base class functions that represent the interface with different arguments in different derived classes.
This implies that a fair bit of foresight is required to design the factory class's interface.
Shared interfaces: leading to less replication of code using classes and making such code more uniform.
This is often called run-time polymorphism or interface inheritance.
Shared implementation: leading to less code and more uniform implementation code.
This is often called implementation inheritance.
A class can combine aspects of these two styles.
Here, we explore more general uses of multiple base classes and examine more technical issues related to combining and accessing features from multiple base classes.
For an abstract class without mutable state, there really is little difference between single and multiple uses of a base class in a class hierarchy.
The resolution of potential ambiguities is discussed in 21_0_3_0_3, 21_0_3_0_4, and 21_0_3_0_5.
In fact, any class without mutable state can be used as an interface in a multiple-inheritance lattice without signiﬁcant complications and overhead.
The key observation is that a class without mutable state can be replicated if necessary or shared if that is desired.
The use of multiple abstract classes as interfaces is  universal in object-oriented designs (in any language with a notion of an interface).
A Satellite object would contain orbital, size, shape, albedo, density parameters, etc_0_, and provide operations for orbital calculations, modifying attributes, etc.
Examples of ptg10564057 Section 21_0_3_0_2 Multiple Implementation Classes 625 satellites would be rocks, debris from old space vehicles, communication satellites, and the International Space Station.
These kinds of satellites would be objects of classes derived from Satellite.
Such derived classes would add data members and functions and would override some of Satellite's virtual functions to adjust their meaning suitably.
Now assume that I want to display the results of these simulations graphically and that I had available a graphics system that used the (not uncommon) strategy of deriving objects to be displayed from a common base class holding graphical information.
This graphics class would provide operations for placement on the screen, scaling, etc.
For generality, simplicity, and to hide the details of the actual graphics system, I will refer to the class providing graphical (or in fact alternatively nongraphical) output Display.
We can now deﬁne a class of simulated communication satellites, class Comm_sat: class Comm_sat : public Satellite, public Displayed { public: // _0__0_.
Virtual functions work as usual.
For example: ptg10564057 626 Class Chapter 21 class Satellite {.
This ensures that Comm_sat::center() and Displayed::() will be called for a Comm_sat treated as a Comm_sat and a Displayed, respectively.
Why didn't I just keep the Satellite and Displayed parts of a Comm_sat completely separate.
I could have deﬁned Comm_sat to have a Satellite member and a Displayed member.
Alternatively, I could have deﬁned Comm_sat to have a Satellite∗ member and a Displayed∗ member and let its constructor set up the proper connections.
For many design problems, I would do just that.
However, the system that inspired this example was built on the idea of a Satellite class with virtual functions and a (separately designed) Displayed class with virtual functions.
You provided your own satellites and your own displayed objects through derivation.
In particular, you had to override Satellite virtual member functions and Displayed virtual member functions to specify the behavior of your own objects.
That is the situation in which multiple inheritance of base classes with state and implementation is hard to avoid.
Workarounds can be painful and hard to maintain.
The use of multiple inheritance to "glue" two otherwise unrelated classes together as part of the implementation of a third class is crude, effective, and relatively important, but not very interesting.
Basically, it sav es the programmer from writing a lot of forwarding functions (to compensate for the fact that we can only override functions deﬁned in bases).
This technique does not affect the overall design of a program signiﬁcantly and can occasionally clash with the wish to keep implementation details hidden.
However, a technique doesn't hav e to be clever to be useful.
I generally prefer to have a single implementation hierarchy and (where needed) several abstract classes providing interfaces.
This is typically more ﬂexible and leads to systems that are easier to ev olve.
However, you can't always get that – especially if you need to use existing classes that you don't want to modify (e_0_g_0_, because they are parts of someone else's library).
Note that with single inheritance (only), the programmer's choices for implementing the classes Displayed, Satellite, and Comm_sat would be limited.
A Comm_sat could be a Satellite or a Displayed, but not both (unless Satellite was derived from Displayed or vice versa).
Either alternative involves a loss of ﬂexibility.
Contrary to some people's conjectures, the Satellite example is real.
There really was – and maybe there still is – a program constructed along the lines used to describe multiple implementation inheritance here.
It was used to study the design of communication systems involving satellites, ground stations, etc.
In fact, Satellite was derived from an early notion of a concurrent task.
Given such a simulation, we can answer questions about communication trafﬁc ﬂow, determine proper responses to a ground station that is being blocked by a rainstorm, consider tradeoffs between satellite connections and Earth-bound connections, etc.
For example: class Satellite {.
A  declared in a derived class overrides all functions of the same name and type in its base classes.
Typically, that is exactly the right thing to do because it is generally a bad idea to use the same name for operations with different semantics in a single class.
The ideal for virtual is for a ptg10564057 628 Class Chapter 21 call to have the same effect independently of which interface was used to ﬁnd the (20_0_3_0_2).
In the implementation of an overriding , it is often necessary to explicitly qualify the name to get the right version from a base class.
A qualiﬁed name, such as Telstar::, can refer to a  declared either in Telstar or in one of its base classes.
For example: class Telstar : public Comm_sat {.
If exactly one match is found, that name will be used.
Otherwise, Comm_sat:: is either not found or is ambiguous.
If, in Telstar::(), I had said plain (), the result would have been an "inﬁnite" recursive call of Telstar::().
I could have said Displayed::(), but now the code would be subtly broken if someone added a Comm_sat::(); it is generally better to refer to a direct base class than to an indirect base class.
Had I said Satellite::(), the result would have been an error because the  is over on the Displayed branch of the class hierarchy.
The get_debug() example basically assumes that at least some parts of Satellite and Displayed have been designed together.
Getting an exact match of names, return types, argument types, and semantics by accident is extremely unlikely.
It is far more likely that similar functionality is provided in different ways so that it takes effort to merge it into something that can be used together.
We might originally have been presented with two classes SimObj and Widget that we could not modify, didn't exactly provide what we needed, and where they did provide what we needed, did so through incompatible interfaces.
In that case, we might have designed Satellite and Displayed as our interface classes, providing a "mapping layer" for our higher-level classes to use: ptg10564057 Section 21_0_3_0_3 Ambiguity Resolution 629 class Satellite : public SimObj { // map SimObj facilities to something easier to use for Satellite simulation.
These two functions have radically different meanings (semantics) but are identical in name and type; we need to override them by two ptg10564057 630 Class Chapter 21 separate functions.
There is no direct language solution to this (exotic) problem, but adding intermediate classes will do: struct WWindow : Window { using Window::Window;.
Or graphically: Window Cowboy WWindow CCowboy Cowboy_window Had the designer of Window been a bit more careful and speciﬁed draw() to be const, the whole problem would have evaporated.
I ﬁnd that fairly typical.
When a class can have multiple base classes, a class can appear multiple times in the resulting hierarchy.
Consider a class providing facilities for storing state in a ﬁle (e_0_g_0_, for breakpointing, debug information, or persistence) and restoring it later:.
Such a useful class will naturally be used in several places in a class hierarchy.
For example: ptg10564057 Section 21_0_3_0_4 Repeated Use of a Base Class 631 class Transmitter : public Storable {.
Given that, we could imagine two cases: [1] A Radio object has two subobjects of class Storable (one for Transmitter and one for Receiver).
The default, provided for the example as written, is two subobjects.
Unless you state otherwise, you get one copy for each time you mention a class as a base.
Graphically, we can represent that like this: Storable Storable Transmitter Receiver Radio A virtual function of a replicated base class can be overridden by a (single) function in a derived class.
Typically, an overriding function calls its base class versions and then does the work speciﬁc to the derived class:.
Casting from a replicated base class to a derived class is discussed in 22_0_2.
For a technique for overriding each of the () functions with separate functions from derived classes, see 21_0_3_0_3.
The reason for that is simply that Storable is an abstract class providing a pure interface.
A Storable object holds no data of its own.
This is the simplest case and the one that offers the best separation of interface and implementation concerns.
In fact, a class could not without some difﬁculty determine that there were two Storable subobjects on a Radio.
What if  did hold data and it was important that it should not be replicated.
For example, we might deﬁne  to hold the name of the ﬁle to be used for storing the object: class  { public:.
Given this apparently minor change to , we must change the design of Radio.
All parts of an object must share a single copy of.
Otherwise, we could get two parts of something derived from  multiple times using different ﬁles.
We avoid replication by declaring a base virtual: every virtual base of a derived class is represented by the same (shared) object.
For example: class Transmitter : public virtual  {.
In an inheritance graph, every base class of a given name that is speciﬁed to be virtual will be represented by a single object of that class.
On the other hand, each base class not speciﬁed virtual will have its own subobject representing it.
Why would someone want to use a virtual base containing data.
I can think of three obvious ways for two classes in a class hierarchy to share data: [1] Make the data nonlocal (outside the class as a global or namespace variable).
Option [1], nonlocal data, is usually a poor choice because we cannot control what code accesses the data and how.
It breaks all notions of encapsulation and locality.
Option [2], put the data in a base class, is usually the simplest.
However, for single inheritance that solution makes useful data (and functions) "bubble up" to a  common base class; often it "bubbles" all the way to the root of an inheritance tree.
This means that every member of the class hierarchy gets access.
That is logically very similar to using nonlocal data and suffers from the same problems.
So we need a common base that is not the root of a tree – that is, a virtual base.
Option [3], sharing an object accessed through pointers, makes sense.
However, then constructor(s) need to set aside memory for that shared object, initialize it, and provide pointers to the shared object to objects needing access.
That is roughly what constructors do to implement a virtual base.
If you don't need sharing, you can do without virtual bases, and your code is often better and typically simpler for it.
However, if you do need sharing within a general class hierarchy, you basically have a choice between using a virtual base and laboriously constructing your own variants of the idea.
We can represent an object of a class with a virtual base like this: Receiver Transmitter Radio ptg10564057 634 Class Chapter 21 The "pointers" to the shared object representing the virtual base, , will be offsets, and often one of those can be optimized away by placing  in a ﬁxed position relative to either the Receiver or the Transmitter subobject.
Expect a storage overhead of one word for each virtual base.
Naturally, we would prefer to keep the lattices simple, but however complicated we make them, the language ensures that a constructor of a is called before its derived classes.
Anything else would cause chaos (that is, an object might be used before it had been initialized).
To avoid such chaos, the constructor of every virtual base is invoked (implicitly or explicitly) from the constructor for the complete object (the constructor for the most derived class).
In particular, this ensures that a virtual base is constructed exactly once ev en if it is mentioned in many places in the class hierarchy.
Note that D can and must provide an initializer for V.
The fact that V wasn't explicitly mentioned as a base of D is irrelevant.
Knowledge of a virtual base and the obligation to initialize it "bubbles up" to the most derived class.
A virtual base is always considered a direct base of its most derived ptg10564057 Section 21_0_3_0_5_0_1 Constructing Virtual Bases 635 class.
The fact that both B and C initialized V is irrelevant because the compiler has no idea which of those two initializers to prefer.
Thus, only the initializer provided by the most derived class is used.
The constructor for a virtual base is called before the constructors for its derived classes.
In practice, this is not quite as localized as we would prefer.
In particular, if we derive another class, DD, from D, then DD has to do work to initialize the virtual bases.
Unless we can simply inherit D's constructors (20_0_3_0_5_0_1), that can be a nuisance.
That ought to encourage us not to overuse virtual base classes.
This logical problem with constructors does not exist for destructors.
They are simply invoked in reverse order of construction (20_0_2_0_2).
In particular, a destructor for a virtual base is invoked exactly once.
This can be a problem when implementing a service that requires a base class function to be called exactly once for each call of a derived function.
Where needed, the programmer can simulate the scheme used for constructors by calling a virtual base class function only from the most derived class.
For example, assume we have a basic Window class that knows how to draw its contents: class Window {.
From this, we can compose a plausible Clock class: ptg10564057 636 Class Chapter 21 class Clock : public Window_with_border, public Window_with_menu { // clock stuff protected:.
This is done independently of the kind of Window.
Instead, it directly calls the explicitly named function, thus avoiding nasty inﬁnite recursion.
Casting from a virtual base class to a derived class is discussed in 22_0_2.
Virtual Bases Using multiple inheritance to provide implementations for abstract classes representing pure interfaces affects the way a program is designed.
Class  (21_0_2_0_3) is an example: ptg10564057 Section 21_0_3_0_6 Replicated vs.
Virtual Bases 637 class : public Ival_slider, // interface protected BBslider.
One base is a public abstract class providing the interface, and the other is a protected concrete class providing implementation provided.
The use of multiple inheritance is close to essential here because the derived class needs to override virtual functions from both the interface and the implementation.
For example, consider again the Ival_box classes from 21_0_2_0_1.
In the end (21_0_2_0_2), I made all the Ival_box classes abstract to reﬂect their role as pure interfaces.
Doing that allowed me to place all implementation details in speciﬁc implementation classes.
Also, all sharing of implementation details was done in the classical hierarchy of the windows system used for the implementation.
When using an abstract class (without any shared data) as an interface, we have a choice:.
Replicate the interface class (one object per mention in the class hierarchy).
Make the interface class virtual to share a simple object among all classes in the hierarchy that mention it.
Using Ival_slider as a virtual base gives us: class : public virtual Ival_slider, protected BBslider { /* _0__0_.
However, we also have this alternative using replicated Ival_slider objects: class : public Ival_slider, protected BBslider { /* _0__0_.
There are logical differences, though.
In the replicated Ival_slider design, a BB_popup_ival_slider can't be implicitly converted to an Ival_slider (because that would be ambiguous):.
On the other hand, it is possible to construct plausible scenarios where the sharing implied in the virtual base design causes ambiguities for casts from the base class (22_0_2).
However, such ambiguities are easily dealt with.
How do we choose between virtual base classes and replicated base classes for our interfaces.
Most often, of course, we don't get a choice because we have to conform to an existing design.
When we do have a choice, we can take into account that (surprisingly) the replicated base solution tends to lead to slightly smaller objects (because there is no need for data structures supporting sharing) and that we often get our interface objects from "virtual constructors" or "factory functions" (21_0_2_0_4).
No explicit conversion is needed to get from an implementation (here, ) to its direct interfaces (here, Popup_ival_slider).
In particular, two different classes might override different virtual functions from the virtual base.
In that way, sev eral derived classes can contribute implementations to the interface presented by a virtual base class.
For example, the Window class might have functions set_color() and prompt().
In that case, Window_with_border might override set_color() as part of controlling the color scheme, and Window_with_menu might override () as part of its control of user interactions: ptg10564057 Section 21_0_3_0_6_0_1 Overriding Virtual Base Functions 639.
For example, My_window could override () to improve on what Window_with_menu provides:.
If two classes override a base class function, but neither overrides the other, the class hierarchy is an error.
The reason is that no single function can be used to give a consistent meaning for all calls independently of which class they use as an interface.
Or, using implementation terminology, no virtual function table can be constructed because a call to that function on the complete object would be ambiguous.
For example, had Radio in 21_0_3_0_5 not declared write(), the declarations of write() in Receiver and Transmitter would have caused an error when deﬁning Radio.
As with Radio, such a conﬂict is resolved by adding an overriding function to the most derived class.
A class that provides some – but not all – of the implementation for a virtual base class is often called a mixin.
Class  Navigation dynamic cast; Multiple Inheritance; static_cast and dynamic_cast; Recovering an Interface.
Double Dispatch and Visitors Double Dispatch; Visitors.
Construction and Destruction.
Type Identiﬁcation Extended Type Information.
Uses and Misuses of RTII.
Advice 22_0_1 Introduction In general, a class is constructed from a lattice of base classes.
Such a class lattice is often called a class hierarchy.
We try to design classes so that users need not be unduly concerned about the way a class is composed out of other classes.
In particular, the virtual call mechanism ensures that when we call a function f() on an object, the same function is called whichever class in the hierarchy provided the declaration of f() used for the call and whichever class deﬁned it.
This chapter explains how to gain information about the total object given only the interface provided by a base class.
We will refer to the combination of GUI library and operating system facilities that control the screen as the system.
Objects passed back and forth between the system and the application are commonly referred to as widgets or controls.
This is how many user interfaces work.
From a language point of view, it is important that the system does not know about our Ival_boxes.
The system's interfaces are speciﬁed in terms of the system's own classes and objects rather than our application's classes.
Howev er, it does have the unpleasant effect that we lose information about the type of objects passed to the system and later returned to us.
Recovering the "lost" type of an object requires us to somehow ask the object to reveal its type.
Any operation on an object requires us to have a pointer or reference of a suitable type for the object.
Consequently, the most obvious and useful operation for inspecting the type of an object at run time is a type conversion operation that returns a valid pointer if the object is of the expected type and a null pointer if it isn't.
The dynamic_cast operator does exactly that.
For example, assume that "the system" inv okes my_event_handler() with a pointer to a BBwindow, where an activity has occurred.
I then might invoke my application code using Ival_box's do_something():.
One way of explaining what is going on here is that  translates from the implementation-oriented language of the user-interface system to the language of the application.
It is important to note what is not mentioned in this example: the actual type of the object.
The object will be a particular kind of Ival_box, say, an Ival_slider, implemented by a particular kind of BBwindow, say, a BBslider.
It is neither necessary nor desirable to make the actual type of the object explicit in this interaction between "the system" and the application.
An interface exists to represent the essentials of an interaction.
In particular, a well-designed interface hides inessential details.
Graphically, the action of =<Ival_box∗>(pw) can be represented like this: BBwindow BBslider Ival_box Ival_slider BB_ival_slider pw ptg10564057 Section 22_0_2 Class  Navigation 643 The arrows from pw and  represent the pointers into the object passed, whereas the rest of the arrows represent the inheritance relationships between the different parts of the object passed.
The use of type information at run time is conventionally referred to as "run-time type information," often abbreviated to RTTI.
Casting from a base class to a derived class is often called a downcast because of the convention of drawing inheritance trees growing from the root down.
Similarly, a cast from a derived class to a base is called an upcast.
A cast that goes from a base to a sibling class, like the cast from BBwindow to Ival_box, is called a crosscast.
Consider ﬁrst the pointer case:.
However, it is reassuring to know that doesn't allow accidental violation of the protection of private and protected base classes.
Since a used as an upcast is exactly like a simple assignment, it implies no overhead and is sensitive to its lexical context.
The purpose of  is to deal with the case in which the correctness of the conversion cannot be determined by the compiler.
In that case, <T∗>(p) looks at the object pointed to by p (if any).
If that object is of class T or has a unique base class of type T, then returns a pointer of type T∗ to that object; otherwise, nullptr is returned.
If the value of p is nullptr, <T∗>(p) returns nullptr.
Note the requirement that the conversion must be to a uniquely identiﬁed object.
It is possible to construct examples where the conversion fails and nullptr is returned because the object pointed to by p has more than one subobject representing bases of type T (22_0_2).
A  requires a pointer or a reference to a polymorphic type in order to do a downcast or a crosscast.
For example: ptg10564057 644 Run-Time Type Information Chapter 22.
Requiring the pointer's type to be polymorphic simpliﬁes the implementation of because it makes it easy to ﬁnd a place to hold the necessary information about the object's type.
A typical implementation will attach a "type information object" (22_0_5) to an object by placing a pointer to the type information in the virtual function table for the object's class (3_0_2_0_3).
It is clear that  can be efﬁciently implemented.
All that is involved are a few comparisons of type_info objects representing base classes; no expensive lookups or string comparisons are needed.
Restricting  to polymorphic types also makes sense from a logical point of view.
That is, if an object has no virtual functions, it cannot safely be manipulated without knowledge of its exact type.
Consequently, care should be taken not to get such an object into a context in which its type isn't known.
If its type is known, we don't need to use.
The target type of  need not be polymorphic.
This allows us to wrap a concrete type in a polymorphic type, say, for transmission through an object I/O system (22_0_2_0_4), and then "unwrap" the concrete type later.
The object representing a base class, such as Ival_box, in a derived class object is not necessarily the ﬁrst subobject in that object of the most derived class.
So,  does not necessarily hold the same address as 2.
Such casts are only useful for interaction with very low-level functions (only such functions deal with void∗s).
There is no  from void∗ (because there would be no way of knowing where to ﬁnd the vptr; 22_0_2_0_3).
When a   used for a pointer type, a nullptr indicates failure.
That  neither feasible nor desirable for references.
Given a pointer result, we must consider the possibility that the result  nullptr, that , that the pointer doesn't point to an object.
Consequently, the result of a  of a pointer should always be explicitly tested.
For a pointer p, <T∗>(p) can be seen as the question "Is the object pointed to by p, if any, of type T_0_" For example:.
On the other hand, we may legitimately assume that a reference refers to an object (7_0_7_0_4).
Consequently, <T&>(r) of a reference r  not a question but an assertion: "The object referred to by r  of type T_0_" The result of a  for a reference  implicitly tested by the implementation of  itself.
If the operand of a  to a reference isn't of the expected type, a bad_cast exception  thrown.
For example: ptg10564057 646 Run-Time Type Information Chapter 22.
The calls to fp() and the ﬁrst call to fr() will return normally (assuming that fp() really can cope with a BB_ival_dial), but the second call of fr() will cause a bad_cast exception that will be caught by g().
Explicit tests against nullptr can easily be accidentally omitted.
If that worries you, you can write a conversion function that throws an exception instead of returning nullptr in case of failure.
This  simple but often constraining.
When multiple inheritance  used, there  no single root.
In itself, this doesn't complicate matters much.
However, if a class appears more than once in a hierarchy, we must be a bit careful when we refer to the object or objects that represent that class.
Naturally, we try to keep hierarchies as simple as our application allows (and no simpler).
However, once a nontrivial hierarchy has been constructed, we sometimes need to navigate it to ﬁnd a speciﬁc class to use.
This need occurs in two variants:.
Sometimes, we want to explicitly name a base class for use as an interface, for example, to resolve an ambiguity or to call a speciﬁc function without relying on the virtual function mechanism (an explicitly qualiﬁed call; 21_0_3_0_3).
Sometimes, we want to obtain a pointer to a subobject of a hierarchy giv en a pointer to another, for example, to get a pointer to the complete derived class object from a pointer to a base (a downcast; 22_0_2_0_1) or to get a pointer to a base class object from a pointer to another base (a crosscast; 22_0_2_0_4).
Here, we consider how to navigate a class hierarchy using type conversions (casts) to gain a pointer of the desired type.
To illustrate the mechanisms available and the rules that guide them, consider a lattice containing both a replicated base and a virtual base: ptg10564057 Section 22_0_2_0_2 Multiple Inheritance 647 class Component : public virtual Storable { /* _0__0_.
Consequently, a  from to  within a Radio will be ambiguous and return a 0.
There  simply no way of knowing which  the programmer wanted:.
Instead, code  written with the knowledge of some sublattice.
For example, a programmer might know only about the Transmitter part of a Radio and write: void h2(∗ ).
The ambiguity for a pointer to a Radio object  not in general detectable at compile time.
This kind of run-time ambiguity detection  needed only for virtual bases.
For ordinary bases, there  always a unique subobject of a given cast (or none) when downcasting (that , toward a ptg10564057 648 Run-Time Type Information Chapter 22 derived class; 22_0_2).
The equivalent ambiguity for virtual bases occurs when upcasting (that , toward a base), but such ambiguities are caught at compile time.
A  (11_0_5_0_2) does not examine the object it casts from, so it cannot:.
In particular, an object of a type with layout constraints determined by some other language – such as Fortran or C – may be used as a virtual base class.
For objects of such types, only static type information will be available.
However, the information needed to provide run-time type identiﬁcation includes the information needed to implement the.
Why would anyone want to use a  for class hierarchy navigation.
There  a run-time cost associated with the use of a  (22_0_2_0_1).
More signiﬁcantly, there are millions of lines of code that were written before  became available.
This code relies on alternative ways of making sure that a cast  valid, so the checking done by   seen as redundant.
However, such code  typically written using the C-style cast (11_0_5_0_3); often obscure errors remain.
Where possible, use the safer.
The compiler cannot assume anything about the memory pointed to by a void∗.
This implies that  – which must look into an object to determine its type – cannot cast from a void∗.
It  not possible to cast to a private base class using  or reinterpret_cast, and "casting aw ay const" (or volatile) requires a  (11_0_5_0_2).
Even then, using the result  safe only provided the object wasn't originally declared const (or volatile) (16_0_2_0_9).
As an example, consider a simple object I/O system.
Users want to read objects from a stream, determine that they are of the expected types, and then use them.
The function user() deals with shapes exclusively through the abstract class Shape and can therefore use every kind of shape.
The use of  is essential because the object I/O system can deal with many other kinds of objects, and the user may accidentally have opened a ﬁle containing perfectly good objects of classes that the user has never heard of.
I used <> (5_0_2_0_1, 34_0_3_0_1) so that I would not forget to delete the object allocated by get_obj().
This object I/O system assumes that every object read or written is of a class derived from Class  must be a polymorphic type to allow the user of get_obj() to use to recover the "true type" of a returned object.
For example: class  {.
Assume that the data representing an object on an input stream is preﬁxed by a string identifying the object's class.
The job of get_obj() is to read that string and call a function capable of reading and creating an object of the right class.
For example: using  = ∗(istream&); // pointer to function returning an *.
This is an example of how a class can be ﬁtted into a hierarchy using an abstract class with less foresight than would have been required to build it as a node class in the ﬁrst place (21_0_2_0_2).
The (istream&) constructor initializes an object with data from its istream argument.
The new_circle() function is the one put into the io_map to make the class known to the object I/O system.
Note that <Circle>::(istream&) does not have access to T's private or protected data.
The idea is that the transmission format for a type X is what is needed to construct an X using one of X's constructors.
The information of the stream is not necessarily the sequence of X's member values.
The  template is an example of a way to ﬁt concrete types into a class hierarchy by providing a handle that is a node in that hierarchy.
It derives from its template parameter to allow casting from.
This simple object I/O system does not do everything anyone ever wanted, but it almost ﬁts on a single page and the key mechanisms have many uses.
It is a blueprint for the "receiver end" of a system for transmitting arbitrary objects across a communication channel in a type-safe manner.
More generally, these techniques can be used to invoke a function based on a string supplied by a user and to manipulate objects of unknown type through interfaces discovered through run-time type identiﬁcation.
In general, the sender part of such an object I/O system will also use RTTI.
Consider: class Face : public  {.
To correctly write out the  pointed to by outline, we need to ﬁgure out which kind of  it is.
That's a job for typeid() (22_0_5).
In general, we must also keep a table of (pointer,unique identiﬁer) pairs to be able to transmit linked data structures and to avoid duplicating objects pointed to by more than one pointer (or reference).
In particular, Cplus_plus can do this run-time lookup (also called a dynamic dispatch) for one type at a time.
In this, Cplus_plus resembles Simula and Smalltalk and more recent languages, such as Java and C#.
Not being able to select a function based on two dynamic types can be a serious limitation.
This implies that we cannot add a virtual function to a class hierarchy without modifying the base class(es) that provides the interface and all derived classes that should be affected.
This section describes the basic workarounds for these problems: 22_0_3_0_1 Double Dispatch shows how to select a virtual function based on two types.
Most realistic examples of these techniques occur when we deal with data structures, such as vectors or graphs or pointers to objects of polymorphic types.
In such cases, the actual type of an object (e_0_g_0_, a vector element or a graph node) can only be known dynamically by (implicitly or explicitly) inspecting the interface provided by a base class.
We would like this to work for any two classes in the class hierarchy rooted in , such as Circle and Triangle.
The basic strategy is to do a virtual function call to select the right function for s1 and then do a second call to select the right function for s2.
To simplify, I will leave out the calculation of whether the two shapes actually intersect and just write the code skeleton for selecting the right functions.
First we deﬁne  with a function for intersection: class ;.
Next we need to deﬁne  and  to override those virtual functions: ptg10564057 654 Run-Time Type Information Chapter 22 class  : public  {.
The interesting functions here are ::intersect( &) and ::intersect( &).
These need to handle a & argument because that argument must refer to a derived class.
The trick/technique is to simply do a virtual call with the arguments in the reverse order.
That done, we are in one of the four functions that can actually do an intersection calculation.
We can test this by making a  of all pairs of ∗ values and calling intersect() for those:.
If you consider this elegant, you need to raise your standards, but it gets the task done.
As the class hierarchy grows, the need for virtual functions grows exponentially.
That is not acceptable in most cases.
Expanding this to three or more arguments is trivial, but tedious.
Worst of all, each new operation and each new  class require a modiﬁcation to every class in the hierarchy: this double-dispatch technique is highly intrusive.
Ideally, I would have preferred a simple intercept(&,&) function with overriders speciﬁed for the desired combinations of particular ptg10564057 Section 22_0_3_0_1 Double Dispatch 655 shapes.
The awkwardness of double dispatch does not make the problem it is trying to address less important.
It is not unusual to want an action, such as intersect(x,y), that depends on the types of two (or more) operands.
For example, ﬁnding the intersection of rectangles is simple and efﬁcient.
So, for many applications, people have found it sufﬁcient to deﬁne a "bounding box" for each shape and then calculate intersections on bounding boxes.
For example: class  { public:.
Variations of this idea are widely used.
Many variants use precomputed values stored in objects to speed up type identiﬁcation (27_0_4_0_2).
Consider how to apply two (or more) operations to every class in a class hierarchy.
Basically, we will do a double dispatch for a hierarchy of nodes and a hierarchy of operations to select the correct operation for the correct node.
The operations are called visitors; here they are deﬁned in ptg10564057 656 Run-Time Type Information Chapter 22 classes  from class.
The nodes are a hierarchy of classes with a virtual function accept() that takes &s.
For this example, I use a hierarchy of Nodes that describe language constructs, as is common in tools based on abstract syntax trees (ASTs): class ;.
I do not use  here, because in general an operation from a  may update either the Node "visited" or the  itself.
Now the Node's accept() performs the double-dispatch trick and passes the Node itself to the 's accept():.
It is only mildly intrusive (the accept() function), and many variations on the basic idea are used.
However, many operations on class hierarchies are hard to express as visitors.
For example, an operation that needs access to multiple nodes of different types in a graph cannot be trivially implemented as a visitor.
So, I consider the visitor pattern an inelegant workaround.
Alternatives exist, for example, [Solodkyy,2012], but not in plain Cplus_plus11.
Most alternatives to visitors in Cplus_plus are based on the idea of explicit iteration over a homogeneous data structure (e_0_g_0_, a  or a graph of nodes containing pointers to polymorphic types).
At each element or node, a call of a virtual function can perform the desired operation, or some optimization based on stored data can be applied (e_0_g_0_, see 27_0_4_0_2).
A class object is built from "raw memory" by its constructors, and it reverts to "raw memory" as its destructors are executed.
Construction is bottom-up, destruction is top-down, and a class object is an object to the extent that it has been constructed or destroyed.
This order is necessary to ensure that an object is not accessed before it has been initialized.
It is unwise to try to access base and member objects early or out of order through "clever" pointer manipulation (17_0_2_0_3).
The order of construction and destruction is reﬂected in the rules for RTTI, exception handling (13_0_3), and virtual functions (20_0_3_0_2).
It is unwise to rely on details of the order of construction and destruction, but you can observe that order by calling virtual functions, dynamic_cast (22_0_2), or typeid (22_0_5) at a point where the object isn't complete.
At such a point in a constructor, the (dynamic) type of the object reﬂects only what is constructed so far.
For example, if the constructor for Component in the hierarchy from 22_0_2_0_2 calls a virtual function, it will invoke a version deﬁned for Storable or Component, but not one from Receiver, Transmitter, or Radio.
At that point of construction, the object isn't yet a Radio.
Similarly, calling a virtual function from a destructor will reﬂect only what is still not destroyed.
It is best to avoid calling virtual functions during construction and destruction.
Importantly, it ensures that code written using it works correctly with classes  from those explicitly mentioned by the programmer.
Thus, dynamic_cast preserves ﬂexibility and extensibility in a manner similar to virtual functions.
However, it is occasionally essential to know the exact type of an object.
For example, we might like to know the name of the object's class or its layout.
The typeid operator serves this purpose by yielding an object representing the type of its operand.
Had typeid() been a function, its declaration would have looked something like this: class type_info; type_info& typeid(expression); // pseudo declaration That is, typeid() returns a reference to a standard-library type called type_info deﬁned in <typeinfo>:.
Giv en the name of a type as its operand, typeid(type_name) returns a reference to a type_info that represents the type_name; type_name must be a completely deﬁned type (8_0_2_0_2).
Giv en an expression as its operand, typeid(expr) returns a reference to a type_info that represents the type of the object denoted by the expr; the expr must refer to a completely deﬁned type (8_0_2_0_2).
If the value of expr is nullptr, typeid(expr) throws a std::bad_typeid.
A typeid() can ﬁnd the type of an object referred to by a reference or a pointer:.
If the operand of typeid() has a nonpolymorphic type or is not an lvalue, the result is determined at compile time without evaluating the operand expression.
If the object denoted by a dereferenced pointer or a reference to a polymorphic type, the type_info returned is that of the most derived class for the object, that is, the type used when the object was deﬁned.
The deﬁnition of type_info looks like this: class type_info {.
The hash_code() function allows type_ids be used as keys for hash tables (such as unordered_map).
It is not guaranteed that there is only one  object for each type in the system.
In fact, where dynamically linked libraries are used, it can be hard for an implementation to avoid duplicate objects.
Consequently, we should  == on  objects to test equality, rather than == on pointers to such objects.
We sometimes want to know the exact type of an object so as to perform some service on the whole object (and not just on one of its bases).
Ideally, such services are presented as virtual functions so that the exact type needn't be known.
In some cases, no common interface can be assumed for every object manipulated, so the detour through the exact type becomes necessary (22_0_5_0_1).
Another, much simpler  has been to obtain the  of a class for diagnostic output: ptg10564057 660 Run-Time Type Information Chapter 22.
The character representation of a class's  is implementation-deﬁned.
This C-style string resides in memory owned by the system, so the programmer should not attempt to delete[] it.
Therefore, ﬁnding the exact type of an object is often just the ﬁrst step to acquiring and using more detailed information about that type.
Consider how an implementation or a tool could make information about types available to users at run time.
Suppose I have a tool that generates descriptions of object layouts for each class used.
I can put these descriptors into a  to allow user code to ﬁnd the layout information:.
We can't hardwire a comparison criterion into the container because the container can't (in general) impose its needs on the element types.
For example, by default, the map uses < for comparison, but not all Keys hav e a < that we would want to use.
We can't hardwire an ordering criterion into the Key type because (in general) there are many different ways of ordering elements based on a key.
For example, one of the most common Key types is string and strings can be ordered based on a variety of criteria (e_0_g_0_, case sensitive and case insensitive).
Consequently, a sorting criterion is not built into the container type or into the element type.
In principle, the notion of sorting criteria for a map could be represented as: [1] [2] A  type argument to the map  determining the type of a comparison object At ﬁrst glance, the ﬁrst solution (pass a comparison object of a speciﬁc type) seems simpler.
For example: <typename Key, typename , bool(∗cmp)(const Key&, const Key&)>.
In particular, the designer of  will have to decide whether to compare the (unknown) Key type using a pointer to function or a function object of some speciﬁc type.
Also, because the argument types of the comparison operator must depend on the Key type, it can be hard to provide a default comparison criterion.
Consequently, the second alternative (pass the type of the comparison as a  type parameter) is the more common and the one used in the standard library.
For example: <typename Key, Class , typename  = std::less<Key>> class  {.
The most common case, comparing using -than, is the default.
If we want a different ptg10564057 Section 25_0_2_0_3 Operations as Arguments 727 comparison criterion, we can supply it as a function object (3_0_4_0_3):.
A simple class member function deﬁned in-class is trivial to inline, whereas inlining a call through a pointer to function requires exceptional attention from a compiler.
A function object with no data members can be passed with no run-time cost.
Sev eral operations can be passed as a single object with no additional run-time cost.
The comparison criterion for a  is just an example.
However, the technique used to pass it is general and very widely used to parameterize classes and functions with "policies_0_" Examples include actions for algorithms (4_0_5_0_4, 32_0_4), allocators for containers (31_0_4, 34_0_4), and deleters for unique_ptr (34_0_3_0_1).
We hav e the same design alternatives when we need to specify arguments for a function , such as sort(), and the standard library chooses alternative [2] for those cases also (e_0_g_0_, see 32_0_4).
If we had only one use of a comparison criterion in our program, it might make sense to use a lambda to express the function object version a bit more tersely: <string,int,> c3 {[](const string& , const string& y) const { return <y; }}; // error Unfortunately, that doesn't work because there is no conversion of a lambda to a function object type.
We could name the lambda and then use that name: auto  = [](const string& , const string& y) const { return <y; } <string,int,decltype()> c4 {}; I ﬁnd naming operations useful from a design and maintenance point of view.
Also, anything named and declared nonlocally might ﬁnd other uses.
For example: ptg10564057 728 Specialization Chapter 25 <typename , <typename> class >.
For example, we specify that 's  parameter  is a  class that takes a single type argument.
If we didn't, we wouldn't be able to use specializations of.
The point of using a as a  parameter is usually that we want to instantiate it with a variety of argument types (such as  and ∗ in the previous example).
That is, we want to express the member declarations of a  in terms of another , but we want that other  to be a parameter so that it can be speciﬁed by users.
Only class templates can be  arguments.
The common case in which a  needs only a container or two is often better handled by passing the container types (31_0_5_0_1).
For example: <typename , typename 2>.
Here, the value types of  and 2 can be obtained by a simple type function (28_0_2) for obtaining the type of elements of a container, for example, Value_type<>.
This is the technique used for the standard-library container adaptors, such as queue (31_0_5_0_2).
We can specify <Key> to be the default type for the   argument, so that only uncommon comparison criteria have to be explicitly speciﬁed: ptg10564057 Section 25_0_2_0_5 Default Template Arguments 729 <typename Key, Class , typename  = std::<Key>> class  {.
Note how the default  constructor creates a default comparison object, {}.
That's the common case.
If we want a more elaborate construction, we must do so explicitly.
For example: <string,int,Complex_compare> m {Complex_compare{"French",3}}; The semantic checking of a default argument for a  parameter is done only if that default argument is actually used.
In particular, as long as we refrain from using the default  argument <Key>, we can compare() values of a type X for which <X> wouldn't compile.
This point is crucial in the design of the standard containers (e_0_g_0_, std::), which rely on a argument to specify default values (31_0_4).
Just as for default function arguments (12_0_2_0_5), the default  arguments can be speciﬁed and supplied for trailing arguments only:.
Not allowing an "empty" argument to mean "use the default" was a deliberate tradeoff between ﬂexibility and the opportunity for obscure errors.
Curiously enough, it is not used for basic_string (23_0_2, Chapter 36) comparisons.
Instead, the standard-library string relies on char_traits (36_0_2_0_2).
Similarly, the standard algorithms rely on iterator_traits (33_0_1_0_3) and the standard-library containers rely on allocators (34_0_4).
The use of traits is presented in 28_0_2_0_4.
For example: template<typename  =string, typename  =string>.
This implementation of () is a bit heavyweight for combinations of simple types, such as <double>(int), but improved implementations can be supplied as specializations (25_0_3).
Note that <char>(int) will not work because char and int do not share a string representation.
For conversion among scalar numeric types, I tend  prefer <>() (11_0_5).
This doesn't always make sense for someone writing a template.
I might want  say, "If  template argument is a pointer, use this implementation; if it is not, use that implementation," or "Give an error unless  template argument is a pointer derived from class My_base_0_" Many such design concerns can be addressed by providing alternative deﬁnitions of  template and having  compiler choose between them based on ptg10564057 Section 25_0_3 Specialization 731 template arguments provided where they are used.
Such alternative deﬁnitions of a template are called user-deﬁned specializations, or simply user specializations.
Consider likely uses of a Vector: template<typename > class Vector { // general  type.
In such code, most Vectors will be Vectors of some pointer type.
There are several reasons for this, but  primary reason is that  preserve run-time polymorphic behavior, we must use pointers (3_0_2_0_2, 20_0_3_0_2).
That is, anyone who practices object-oriented programming and uses type-safe containers (such as  standard-library containers) will end up with a lot of containers of pointers.
The default behavior of most Cplus_plus implementations is  replicate  code for template functions.
This is usually good for run-time performance, but unless care is taken, it leads  code bloat in critical cases such as   example.
Fortunately, there is an obvious solution.
Containers of pointers can share a single implementation.
This can be expressed through specialization.
First, we deﬁne a version (a specialization) of for pointers  void: template<>.
This specialization can then be used as  common implementation for all Vectors of pointers.
Another use would be  implement unique_ptr<> based on a single shared implementation class storing a void∗.
The template<> preﬁx says that this is a specialization that can be speciﬁed without a template parameter.
The template arguments for which  specialization is  be used are speciﬁed in <> brackets after  name.
That is,  <void∗> says that this deﬁnition is  be used as  implementation of every  for which  is void∗.
That is, there is no template parameter  specify or deduce when we use  specialization; <void∗> is used for Vectors declared like this: <void∗> vpv; To deﬁne a specialization that is used for every  of pointers and only for Vectors of pointers, we can write: template<typename > class <∗> : private <void∗> {.
The specialization pattern <∗> after  name says that this specialization   be used for every pointer type; that , this deﬁnition   be used for every  with a template argument that can be expressed as ∗.
For example: <Shape∗> vps; // <*>  <Shape*> so   Shape <int∗∗> vppi; // <*>  <int**> so   int* A specialization with a pattern containing a template parameter  called a partial specialization in contrast  complete specializations (as in  deﬁnition of vector<void∗>), where " pattern" simply a speciﬁc type.
Note that when a partial specialization  used, a template parameter  deduced from  specialization pattern;  template parameter  not simply  actual template argument.
Given this partial specialization of , we hav e a shared implementation for all Vectors of pointers.
The <∗> class  simply an interface  <void∗> implemented exclusively through derivation and inline expansion.
It  important that this reﬁnement of  implementation of  be achieved without affecting  interface presented  users.
Specialization  a way of specifying alternative implementations for different uses of a common interface.
Naturally, we could have giv en  general and   of pointers different names.
However, when I tried that, many people who should have known better forgot  use  pointer classes and found their code much larger than expected.
In this case, it  much better  hide  crucial implementation details behind a common interface.
This technique proved successful in curbing code bloat in real use.
People who do not use a have found that replicated code can cost megabytes of code space even in moderately sized programs.
By eliminating  time needed  compile those additional versions of   operations, this technique can also cut compile and link times dramatically.
Using a single specialization ptg10564057 Section 25_0_3 Specialization 733 implement all lists of pointers  an example of  general technique of minimizing code bloat by maximizing  amount of shared code.
Some compilers are getting smart enough  perform this particular optimization without help from  programmer, but  technique  generally applicable and useful.
Variants of  technique of using a single run-time representation for values of a number of types and relying on  (static) type system  ensure that they are used only according  their declared type has been called type erasure.
In  context of Cplus_plus, it was ﬁrst documented in original template paper [Stroustrup,1988].
For example,  standard library complex uses specializations  adjust set of constructors and  argument types for important operations for important specializa looks like this: template<typename > class  {.
In addition, conversions from <ﬂoat> and <long double> are provided (as described in 23_0_4_0_6): template<> class <double> {.
Note that these specialized constructors are constexpr, making <double> a literal type.
Also, this deﬁnition takes advantage of the knowledge that conversion from <ﬂoat> to <double>  safe (it never narrows), so that we can have an implicit constructor from <ﬂoat>.
Howev er, the constructor from <long double>  explicit to make narrowing less likely.
In that case, a specialization can even provide a representation that differs from that of the general template.
For example: template<typename , int > class Matrix;.
The primary template deﬁnes the interface for all specializations (iso_0_14_0_5_0_5).
That , the primary template  the one used to determine if a use  valid and takes part in overload resolution.
Only after a primary template has been chosen are specializations considered.
The primary template must be declared before any specialization.
For example: template<typename > class <∗> {.
If we have deﬁned a constraints check for a template (24_0_4), the primary template  where it belongs because concepts are something a user cares about and must understand to use the template.
For example: template<typename >.
For technical reasons (because the language doesn't recognize constraints checks for what they are), a constraints check needs to be replicated in every specialization.
A declaration of the primary template  sufﬁcient to allow the deﬁnition of a specialization: template<typename > class ;.
If the primary template  never instantiated, it need not be deﬁned.
This can be used to deﬁne a template for which only a ﬁxed set of alternative arguments are accepted.
If a user specializes a template, that specialization must be in scope for every use of the template with the type for which it was specialized.
For example: template<typename > class  { // _0__0_.
Here,  was specialized for int∗ after <int∗> had been used.
It is essential that every use of a template for a given set of template arguments be implemented by the same specialization.
If not, the type system is broken, so that identical uses of a template in different places may yield different results and objects created in different parts of a program may not be compatible.
Clearly that would be disastrous, so a programmer must take care that explicit specialization is consistent throughout a program.
In principle, implementations are capable of detecting inconsistent specialization, but the standard does not require them to and some don't.
All specializations of a template must be declared in the same namespace as the primary template.
If used, a specialization that is explicitly declared (as opposed to generated from a more general template) must also be explicitly deﬁned somewhere (23_0_7).
In other words, explicitly specializing a template implies that no (other) deﬁnition is generated for that specialization.
For example: template<typename > class Vector; // general; the primar y template template<typename > class Vector<∗>; // specialized for any pointer template<> class Vector<void∗>; // specialized for void* Every type can be used as a template argument for the most general Vector, but only pointers can be used for Vector<∗> and only void∗s can be used for Vector<void∗>.
The most specialized version will be preferred over the others in declarations of objects, pointers, etc.
A specialization pattern can be speciﬁed in terms of types composed using the constructs allowed for template parameter deduction (23_0_5_0_2).
However, we can overload functions, so we see less specialization.
Furthermore, Cplus_plus supports only complete specialization for functions (iso_0_14_0_7), so we use overloading where we might have tried partial specialization.
Those versions compare elements using < and swap elements using detailed code.
A better deﬁnition would be: template<typename T>.
We now hav e  and swap as named entities for which we can provide improved versions.
Such names are often referred to as customization points.
As written, sort() will not sort  <char∗> correctly  < will compare the two char∗s.
That is, it will compare the addresses of the ﬁrst char in each string.
Instead, we would like it to compare the characters pointed to.
A simple specialization of () for const char∗ will take care of.
As for classes (25_0_3), the template<> preﬁx says that this is  specialization that can be speciﬁed without  template parameter.
The <const char∗> after the template function name means that this specialization is to be used in cases where the template argument is const char∗.
Because the template argument can be deduced from the function argument list, we need not specify it explicitly.
So, we can simplify the deﬁnition of the specialization: template<>.
Given the template<> preﬁx, the second empty <> is redundant, so we would typically simply write: ptg10564057 738 Specialization Chapter 25 template<>.
Now that we have "specialized" () to  version that is semantically correct, we can consider what we might do for swap().
The standard-library swap() is correct for our use and has already instead of the three potentially expensive copy operations, we improved performance for  large number of argument types.
Specialization comes in handy when an irregularity of an argument type causes the general.
The "elsewhere" might look something like this:.
It is all generic programming: after all, we are just deﬁning and using generic types and algorithms.
Both of these positions are useless because they basically deﬁne generic programming and template metaprogramming as synonyms.
I think there is a useful distinction to be made.
A distinction helps us decide between alternative approaches to problems and to focus on what is important for a given problem.
When I write a generic type or algorithm, I don't feel that I am writing a compiletime program.
I am not using my programming skills for the compile-time part of my program.
Instead, I am focusing on deﬁning requirements on arguments (24_0_3).
Generic programming is primarily a design philosophy – a programming paradigm, if you must (1_0_2_0_1).
In contrast, metaprogramming is programming.
The emphasis is on computation, often involving selection and some form of iteration.
Metaprogramming is primarily a set of implementation techniques.
I can think of four levels of implementation complexity: [1] [2] Simple computation (on types or values) not using compile-time tests or iteration, for [3] Computation using explicit compile-time tests, for example, a compile-time if (28_0_3).
So, metaprogramming is a combination of "meta" and programming: a metaprogram is a compile-time computation yielding types or functions to be used at run time.
Note that I don't say "template metaprogramming" because the computation may be done using constexpr functions.
Note also that you can rely on other people's metaprogramming without actually doing metaprogramming yourself: calling a constexpr function hiding a metaprogram (28_0_2_0_2) or extracting the type from a template type function (28_0_2_0_4) is not in itself metaprogramming; it just uses a metaprogram.
Generic programming usually falls into the ﬁrst, "no computation" category, but it is quite possible to support generic programming using metaprogramming techniques.
When doing so, we have to be careful that our interface speciﬁcations are precisely deﬁned and correctly implemented.
Once we use (meta)programming as part of an interface, the possibility of programming errors creeps in.
Without programming, the meaning is directly deﬁned by the language rules.
Generic programming focuses on interface speciﬁcation, whereas metaprogramming is programming, usually with types as the values.
Overenthusiastic use of metaprogramming can lead to debugging problems and excessive compile times that render some uses unrealistic.
As ever, we hav e to apply common sense.
There are many simple uses of metaprogramming that lead to better code (better type safety, lower memory footprint, and lower run time) without exceptional compile-time overhead.
Many standard-library components, such as function (33_0_5_0_3), thread (5_0_3_0_1, 42_0_2_0_2), and tuple (34_0_2_0_4_0_2), are examples of relatively simple application of metaprogramming techniques.
This chapter explores the basic metaprogramming techniques and presents the basic building blocks of metaprograms.
Chapter 29 offers a more extensive example.
For example, sizeof(T) is a built-in type function that given a type argument T returns the size of an object (measured in chars; 6_0_2_0_8).
Type functions don' hav e to look like conventional functions.
For example, the standard library's <T> takes its argument as a template argument and returns its result as a member called value: if (<int>::value)  << "Big surprise_0_";.
A  function can take more than one argument and return several result values.
For example: ptg10564057 782 Metaprogramming Chapter 28 template<typename T, int N>.
Type functions are compile-time functions.
That is, they can only take arguments (types and values) that are known at compile time and produce results (types and values) that can be used at compile time.
Most  functions take at least one  argument, but there are useful ones that don'.
For example, here is a  function that returns an integer  of the appropriate number of bytes: template<int N>.
It is of course possible to write templates that take values only and produce values only.
I don' consider those  functions.
Also, constexpr functions (12_0_1_0_6) are usually a better way of expressing compile-time computations on values.
I can compute a square root at compile time using templates, but why would I want to when I can express the algorithm more cleanly using constexpr functions (2_0_2_0_3, 10_0_4, 28_0_3_0_2).
So, Cplus_plus  functions are mostly templates.
They can perform very general computations using types and values.
They are the backbone of metaprogramming.
For example, we might want to allocate an object on the stack provided that it is small and on the free store otherwise: constexpr int  = sizeof(std::string); // max size of object we want on the stack template<typename > struct Obj_holder { using  = typename std::<(sizeof()<=),.
If its ﬁrst argument evaluates to true, the result (presented as the member ) is the second argument; otherwise, the result is the third argument.
In this case, <X>'  is deﬁned to be Scoped<X> if an object of X is small and On_heap<X>.
The  example is not hypothetical.
For example, the Cplus_plus standard contains the following comment in its deﬁnition of the function  (33_0_5_0_3) for holding function-like entities: "Implementations are encouraged to avoid the use of dynamically allocated memory for small callable objects, for example, where f' target is an object holding only a pointer or reference to an object and a member function pointer" (iso_0_20_0_8_0_11_0_2_0_1).
It would be hard to follow that advice without something like.
How are Scoped and  implemented.
Their implementations are trivial and do not involve any metaprogramming, but here they are: template<typename >.
This is a consequence of the way the language is speciﬁed and used, this is the way template metaprogramming code has been written for the last 15 years, and this is the way it appears in the Cplus_plus11 standard.
It reminds me of the bad old days in C, where every occurrence of a user-deﬁned  had to be preﬁxed with the struct keyword.
By introducing a template alias (23_0_6), we can hide the :: implementation details and make a  function look much more like a function returning a  (or like a ).
For example: template<typename >.
Except when explaining an implementation or what the standard speciﬁcally offers, I use such aliases systematically.
When the standard provides a  function (called something like " property predicate" or "composite  category predicate"), such as , I deﬁne a corresponding  alias (35_0_4_0_1): template<typename C, typename , typename F> using  = typename std::<C,,F>::; Please note that these aliases are unfortunately not part of the standard.
If only one of the alternatives is supposed to be a valid , we should not use an alias.
Consider ﬁrst a simple analogy: ptg10564057 Section 28_0_2_0_1_0_1 When Not to Use an Alias 785.
It is important that we don't enter the block if p is the nullptr.
We are using the test to see if p is valid.
Similarly, we might want to test to see if a  is valid.
For example: < is_integral<>::value , make_unsigned<>, <> >:: Here, we test if  is an integral  (using the std::is_integral  predicate) and make the unsigned variant of that  if it is (using the std::make_unsigned  function).
If that succeeds, we have an unsigned ; otherwise, we will have to deal with the  indicator.
Had we written Make_unsigned<> meaning typename make_unsigned<>:: and tried to use it for a nonintegral , say std::string, we would have tried to make a nonexistent (make_unsigned<std::string>::).
The result would have been a compile-time error.
In the rare cases where we can't use aliases consistently to hide ::, we can fall back on the more explicit, implementation-oriented :: style.
Alternatively, we can introduce a function to delay evaluation of a  function until its use: < is_integral<>::value , <Make_unsigned,>, Error<> > The implementation of a perfect  function is nontrivial, but for many uses this will do: template<template<typename_0__0__0_> class , typename _0__0_.
Args> using  = <Args_0__0__0_>; This uses a template template argument (25_0_2_0_4) and variadic templates (28_0_6).
Independently of which solution we choose to avoid the undesired instantiation, this is the kind of expert territory that I enter only with some trepidation.
If you want to write functions that take arguments that are types, it seems obvious that you'll like to ask questions about the arguments' types.
For example: Is this a signed type.
Is this type polymorphic (i_0_e_0_, does it have at least one virtual function).
Is this type derived from that type.
The answers to many such questions are known to the compiler and exposed to the programmer through a set of standard-library type predicates (35_0_4_0_1).
For example: ptg10564057 786 Metaprogramming Chapter 28 template<typename >.
If not, we copy the objects one by one (potentially) using their copy constructor.
We determine whether the template argument type is a POD by the standard-library type predicate is_pod.
The result is presented by the member value.
This standard-library convention is similar to the way type functions present their result as a member type.
The std:: predicate is one of the many provided by the standard library (35_0_4_0_1).
Since the rules for being a POD are tricky,  is most likely a compiler intrinsic rather than implemented in the library as Cplus_plus code.
Like the ::type convention, the value ::value causes verbosity and is a departure from conventional notation that lets implementation details shine through: a function returning a bool should be called using ():.
Fortunately, the standard supports that for all standard-library type predicates.
Unfortunately, for language-technical reasons, this resolution is not available in the context of a template argument.
For example: template<typename T>.
In particular, <T> is interpreted as the type of a function taking no argument and returning an <T> (iso_0_14_0_3[2]).
My solution is to add functions to provide the conventional notation in all contexts: template<typename T>.
In addition, I keep them in a separate namespace (Estd).
We can deﬁne our own type predicates.
For example: template<typename T>.
When we have to deﬁne such predicates, we have rather powerful techniques available.
For example, we can deﬁne a type function to determine whether a class has a member of a given name and of an appropriate type (28_0_4_0_4).
Naturally, type predicates with more than one argument can also be useful.
In particular, this is how we represent relations between two types, such as is_same, is_base_of, and is_conver tible.
I use Is_∗ constexpr functions to support the usual () calling syntax for all of these is_∗ functions.
In particular, this means that the condition must be a constant expression.
Note the parentheses around sizeof(int)>4; without those, we would have gotten a syntax error because the compiler would have interpreted the > as the end of the template argument list.
For that reason (and others), I prefer to use < (less than) rather than > (greater than).
Also, I sometimes use parentheses around conditions for readability.
A trait is used to associate properties with a type.
For example, the properties of an iterator are deﬁned by its iterator_traits (33_0_1_0_3): template<typename Iterator>.
You can see a trait as a type function with many results or as a bundle of type functions.
The standard library provides allocator_traits (34_0_4_0_2), char_traits (36_0_2_0_2), and type_traits (35_0_4_0_1), which confusingly are simple type functions.
Given  for a , we can talk about the  and the  of a even though pointers don't hav e members: template<typename Iter>.
This is a most useful and powerful technique, but:.
It often bundles otherwise weakly related type functions.
It exposes implementation details to users.
Also, people sometimes throw in type aliases "just in case," leading to unneccesary complexity.
Consequently, I prefer to use simple type functions: template<typename T> using  = typename std::<T>::; template<typename T> using  = typename std::<T>::; ptg10564057 Section 28_0_2_0_4 Traits 789 template<typename T> using = typename std::<T>::; The example cleans up nicely:.
Also, auto and decltype are new  Cplus_plus11, so older code could not have been written this way.
We need a trait (or equivalent, such as decltype()) to associate a type with another type, such as a with a T∗.
For that, a trait (or an equivalent) is indispensable for non-intrusively adding type names needed for generic programming or metaprogramming.
When a trait is used simply to provide a name for something that already has a perfectly good name, such as  for ∗ and  for &, the utility is less clear and the potential for confusion 28_0_3 Control Structures To do general computation at compile time, we need selection and recursion.
If you want to choose among values, _0_: is sufﬁcient; ptg10564057 790 Metaprogramming Chapter 28 and Select are for selecting types.
They are not simply compile-time equivalents to if and switch ev en though they can appear to be when they are used to choose among function objects (3_0_4_0_3, 19_0_2_0_2).
The  template is part of the standard library ( <type_traits>), so we don't hav e to implement it, but it illustrates an important technique: template<bool C, typename T, typename F>.
If the condition is not true, the specialization for false is chosen and  is deﬁned to be F.
For example: typename <(std::<T>::value),,>:: z; Obviously, the syntax leaves a bit to be desired (28_0_2_0_2), but the underlying logic is beautiful.
Specialization is used to separate the general case from one or more specialized ones (25_0_3).
In this example, the primary template takes care of exactly half of the functionality, but that fraction can vary from nothing (every nonerroneous case is handled by a specialization; 25_0_3_0_1_0_1) to all but a single terminating case (28_0_5).
This form of selection is completely compile-time and doesn't cost a byte or a cycle at run time.
To improve the syntax, I introduce a  alias: template<bool B, typename T, typename F> using  = typename std::<B,T,F>::; Given that, we can write: <(<T>()),X,> z; I consider that a signiﬁcant improvement.
Run Time Looking at something like <(std::<T>::value),X,Y> z;.
On my implementation, I got sizeof(0)==8, sizeof(1)==4, and sizeof(2)==4 as the compiler optimizes away the empty base classes.
This is called the empty-base optimization and is guaranteed by the language (27_0_4_0_1).
For example: template<typename 1, typename 2, typename 3, typename 4>.
Unsurprisingly, the output is: ptg10564057 806 Metaprogramming Chapter 28.
We would like to access those elements efﬁciently and without the possibility of type system violations (i_0_e_0_, without using casts).
We can imagine  variety of schemes, such as naming the elements, numbering the elements, and accessing elements by recursing though the elements until we reach  desired element.
The last alternative is what we will  to implement the most common access strategy: index the elements.
In particular, I want to implement  way to subscript.
Unfortunately, I am unable to implement an appropriate [], so I   function template ():.
The idea is to index the elements, starting from 0, in such  way that the element selection is done at compile time and we preserve all type information.
The () function constructs an object of type <,>.
The job of <X,N> is to return reference to the Nth element, which is assumed to have type X.
Given such  helper, we can ():.
Basically,  is  special-purpose for-loop, implemented by recursing N−1 times.
The member functions are static because we don't really want any objects of class.
That class is only used as  place to hold Ret and N in  way that allows the compiler to use them.
This is quite  bit of scaffolding to index into  , but at least the resulting code is type-safe and efﬁcient.
By "efﬁcient," I mean that given  reasonably good compiler (as is common), there is no run-time overhead for accessing   member.
Why must we write <2>() rather than just [2].
Unfortunately, this does not work:.
Inside [](), the argument N is not known to be  constant expression.
I "forgot" that only lambdas can deduce their result type from their return-statement (11_0_4_0_4), but that could be handled by adding  −>decltype(g et<N>(t)).
To  that, we need some language lawyering and for now, we hav e to make do with <2>().
For example: < , , char>  {1_0_1, 42, ''};.
The problem is that () takes its argument by non-const reference.
But  is  const, so it is not an acceptable argument.
Naturally, we also want to be able to have const Tuples.
For example: ptg10564057 808 Metaprogramming Chapter 28.
Now, we can handle both const and non-const arguments.
This implies that we can make   type implicit in code by having function construct it for us: ptg10564057 Section 28_0_5_0_3 make_tuple 809 <typename 1, typename 2, typename 3, typename 4>.
For example, an errorreporting function may take between zero and ten arguments,  matrix may have between one and ten dimensions, and  tuple can have zero to ten elements.
Note that in the ﬁrst and the last example, the elements may not necessarily be of the same type.
In most cases, we would prefer not to deal with each case separately.
Ideally,  single piece of code should handle the cases for one element, two elements, three elements, etc.
Also, I pulled the number ten out of  hat: ideally, there should be no ﬁxed upper limit on the number of elements.
Over the years, many solutions have been found.
For example, default arguments (12_0_2_0_5) can be used to allow  single function to accept  variable number of arguments, and function overloading (12_0_3) can be used to provide  function for each number of arguments.
Passing  single list of elements (11_0_3) can be an alternative to having  variable number of arguments as long as the elements are all of the same type.
However, to elegantly handle the case of an unknown number of arguments of unknown (and possibly differing) types, some additional language support is needed.
That language feature is called  variadic.
Consider the archetypical example of  function needing an unknown number of arguments of variety of types: printf().
As provided by the C and Cplus_plus standard libraries, printf() is ﬂexible and performs nicely (43_0_3).
However, it is not extensible to user-deﬁned types and not type-safe, and it is  popular target for hackers.
The ﬁrst argument to printf() is  C-style string interpreted as  "format string_0_" Additional arguments are used as required by the format string.
Format speciﬁers, such as %g for ﬂoatingpoint and %s for zero-terminated arrays of characters, control the interpretation of the additional arguments.
For example: printf("The value of %s is %g\n","",3_0_14); ptg10564057 810 Metaprogramming Chapter 28 string  = "target";.
The ﬁrst call of printf() works as intended, but the second call has two problems: the format speciﬁcation %s refers to C-style strings, and printf() will not interpret the std::string argument correctly.
Furthermore, there is no %P format and in general no direct way of printing values of user-deﬁned types, such as Point.
In the third call of printf(), I provided an int as the argument for %s and I "forgot" to provide an argument for %g.
In general, a compiler is not able to compare the number and types of arguments required by the format string with the number and types of arguments provided by the programmer.
The output of that last call (if any) would not be pretty.
Using variadic templates, we can implement an extensible and type-safe variant of printf().
As is common for compile-time programming, the implementation has two parts: [1] Handle the case where there is just one argument (the format string).
The simplest case is the one with only one argument, the format string:.
That prints out the format string.
If a format speciﬁer is found, this printf() throws an exception because there is no argument to be formatted.
A format speciﬁer is deﬁned to be a % not followed by another % (%% is printf()' notation for a % that does not start a type speciﬁer).
Note that ∗ does not overﬂow even if a % is the last character in a string.
In that case, ∗ refers to the terminating zero.
That done, we must handle printf() with more arguments.
Here is where a , and in particular a variadic , comes into play:.
Ordinary characters (i_0_e_0_, not % formal speciﬁers) are simply printed.
The overloading of << replaces the use of the (possibly erroneous) "hint" in the format speciﬁer.
If an argument has a type for which << is deﬁned, that argument is printed; otherwise, that call does not type check and the program will never run.
A formatting character after a % is not used.
I can imagine type-safe uses for such characters, but the purpose of this example is not to design the perfect printf() but to explain variadic templates.
A parameter pack is a sequence of (type/value) pairs from which you can "peel off" arguments starting with the ﬁrst.
When printf() is called with two or more arguments void printf(const char∗ , T value , Args_0__0_.
In the call printf(,args_0__0__0_) the parameter pack args is expanded so that the ﬁrst element of args is selected as value and args is one element shorter than in the previous call.
This carries on until args is empty, so that we call: void printf(const char∗);.
The standard library provides std::is_integral and std::is_ﬂoating_point, but you'd hav e to craft yourself.
If not, here are minimal technical examples that might help.
First, we can declare and use a simple variadic template function: template<typename_0__0_.
Types> void f(Types_0__0_.
The type of each args function argument is the corresponding Types template argument.
The ellipsis (_0__0__0_) is a separate lexical token, so you can place whitespace before or after it.
That ellipsis can appear in many different places in the grammar, but it always means "zero or more occurrences of something").
Think of a parameter pack as a sequence of values for which the compiler has remembered the types.
For example, we could graphically represent a parameter pack for {'c',127,string{"Bob"},3_0_14}: 'c' 127.
I used a  argument for the type of the "something" to be called, so that call() can accept functions, pointers to functions, function objects, and lambdas.
I hav e to be speciﬁc about which specialization of a  function to pass because call() cannot deduce which one to use from the types of the other arguments.
This section presents the deﬁnition of the standard-library  (from <>; 34_0_2_0_4_0_2) and explains the techniques used to implement it.
The key difference between std:: and our simple Tuple is that the former uses variadic templates to remove the limitation on the number of elements.
Here are the key deﬁnitions: < Head, _0__0_.
Tail> class <Head, Tail_0__0__0_> : private <Tail_0__0__0_> { // here is the recursion /* and derives from the  of its tail (the rest of the (type/value) pairs).
Note that the type is encoded in the type, not stored as data */ typedef <Tail_0__0__0_> inherited;.
There is no guarantee that std:: is implemented as hinted here.
In fact, several popular implementations derive from a helper class (also a variadic class ), so as to  the element layout in memory to be the same as a struct with the same member types.
The "add reference" type functions add a reference to a type if it isn' a  reference already.
They are used to avoid copying (35_0_4_0_1).
Curiously, std:: does not provide head() and () functions, so I made them private.
In fact, does not provide any member functions for accessing an element.
If you want to access an element of a , you must (directly or indirectly) call a function that splits it into a value and _0__0__0_.
It can  tedious to mention all of those types.
Instead, we can deduce them from argument types, ptg10564057 Section 28_0_6_0_4 The Standard-Library 817 for example, using the standard-library make_tuple():.
Every member of std:: is useful to someone and most are useful to many, but none adds to our understanding of variadic templates, so I do not go into details.
There are constructors and assignments from the same type (copy and move), from other  types (copy and move), and from pairs (copy and move).
The operations taking a std:: argument use sizeof_0__0_.
There are (nine) constructors and assignments taking allocators (34_0_4) and a swap() (35_0_5_0_2).
Unfortunately, the standard library does not offer << or >> for.
Worse, writing a << for std:: is amazingly complicated because there is no simple and general way of iterating through the elements of a standard-library.
First we need a helper; it is a struct with two print() functions.
One print() recurses through a list printing elements, and the other stops the recursion when there is no more elements to print: <size_t > // print element  and following elements struct  {.
The pattern is that of a recursive function with a terminating overload (like printf() from 28_0_6_0_1).
We can now write a << for :.
Providing input for such computations can be tricky, but we can always #include data into the program text.
However, I prefer simpler examples that in my opinion stand a better chance when it comes to maintenance.
Here, I will show an example that provides a reasonable tradeoff between implementation complexity and utility.
The compilation overhead is minimal and there is no run- overhead.
The example is to provide a small library for computations using units, such as meters, kilograms, and seconds.
These MKS units are a subset of the international standard (SI) units used universally in science.
The example is chosen to show how the simplest metaprogramming techniques can be used in combination with other language features and techniques.
We want to attach units to our values, so as to avoid meaningless computations.
Units provide a type system for physical values.
As shown, we can use auto to hide types when we want to (2_0_2_0_2), user-deﬁned literals to introduce typed values (19_0_2_0_6), and a type  for use when we want to be explicit about Units.
Meters for length.
Kilograms for mass.
Seconds for Note that the unit values are encoded in the type.
We can provide more conventional notation for the most common units:.
Negative unit values indicate division by a quantity with that unit.
This three-value representation of a unit is very ﬂexible.
We can represent the proper unit of any computation involving , mass, and.
I doubt we will ﬁnd much use for <123,−15,1024>, that is, 123 distances multiplied, divided by 15 masses multiplied, and then multiplied by 1024  measurements multiplied – but it is nice to know that the system is general.
When we multiply two quantities, their units are added.
Thus, addition of Units is useful: template<typename U1, typename U2> struct  {.
Now we can start thinking about computations.
What do we do to physical measurements.
I' not going to review a whole physics textbook, but certainly we need addition, subtraction, multiplication, and division.
You can only add and subtract values with the same units: template<typename U>.
Similarly, division of Quantitys subtraction of their Units.
For example: template<typename U1, typename U2>.
Given these arithmetic operations, we can express most computations.
However, we ﬁnd that realworld computations contain a fair number of scaling operations, that is, multiplications and divisions by dimensionless values.
We could use <<0,0,0>> but that gets tedious: <>  {10}; auto  = <<0,0,0>>{2}∗;.
We needed the _0_0 or the explicit double to ensure that the  is double (and  the correct result for the division).
The code generated for the two examples should be identical, and we can do better still notationally.
We can introduce user-deﬁned literals (UDLs; 19_0_2_0_6) for the  types: constexpr <> operator"" _m(double d) { return <>{d}; }.
However, we could also provide more of the conventional units as.
Obviously, this could really get out of control through overuse of nonstandard sufﬁxes (e_0_g_0_, us is suspect even though it is widely used because u looks a bit like a Greek μ).
I could have provided the various magnitudes as more types (as is done for std::ratio; 35_0_3) but thought it simpler to keep the  types simple and focused on doing their primary task well.
Deﬁning square() is trivial:.
That basically shows how to write arbitrary computational functions.
I could have constructed the right there in the return value deﬁnition, but using the existing  function was easier.
Alternatively, we could easily have deﬁned a  function Unit_double.
It is deﬁned for values of the same Units only: template<typename U>.
Such code will, given a reasonable compiler, generate exactly the same code as would have been generated using doubles directly.
Howev er, it is " checked" (at compile ) according to the rules for physical units.
It is an example of how we can add a whole new  of application-speciﬁc types with their own checking rules to a Cplus_plus program.
Introduction Basic Matrix Uses; Matrix Requirements.
A Matrix Template Construction and Assignment; Subscripting and Slicing.
Matrix Arithmetic Operations Scalar Operations; Addition; Multiplication.
Matrix Implementation slice; Matrix Slices; Matrix_ref; Matrix List Initialization; Matrix Access; Zero-Dimensional Matrix.
Solving Linear Equations Classical Gaussian Elimination; Pivoting; Testing; Advice 29_0_1 Introduction A language feature in isolation is boring and useless.
This chapter demonstrates how features can be used in combination to address a challenging design task: a general N-dimensional matrix.
I hav e never seen a perfect matrix class.
In fact, given the wide variety of uses of matrices, it is doubtful whether one could exist.
Here, I present the programming and design techniques needed to write a simple N-dimensional dense matrix.
If nothing else, this  is far easier to use, and just as compact and fast, as anything a programmer would have  to write using vectors or builtin arrays directly.
As for vector, we use () to specify sizes and {} to specify element values (17_0_3_0_2_0_1, 17_0_3_0_4_0_1).
The number rows must match the speciﬁed number of dimensions and the number of elements in.
Each dimension has a number of elements (its extent()) deduced from the initializer list or speciﬁed as a  constructor argument using the () notation.
The total number of elements is referred to.
Given that, << prints: {{0,1,2,3},{10,11,12,13},{20,21,22,23}}.
N dimensions, where N is a parameter that can vary from 0 to many, without specialized code for every dimension.
N-dimensional storage is useful in general, so the element type can be anything we can store (like a vector element).
The mathematical operations should apply to any type that can reasonably be described as a number, including a.
Fortran-style subscripting using one index per dimension, for example, (1,2,3) for a 3-D , yielding an element.
C-style subscripting, for example, [7], yielding a row (a row is an N−1-D sub- of an N-D ).
Subscripting should be potentially fast  potentially range checked.
Move assignment  move constructor to ensure efﬁcient passing of  results  to eliminate expensive temporaries.
Some mathematical matrix operations, such as +  ∗=.
A way to read, write,  pass around references to submatrices, Matrix_refs, for use for both reading  writing elements.
The absence of resource leaks in the form of the basic guarantee (13_0_2).
Fused critical operations, for example, ∗v+v2 as a single function call.
Introduction Standard-Library Facilities; Design Constraints; Description Style.
Language Support initializer_list Support; Range-for Support.
Error Handling Exceptions; Assertions; system_error.
Advice 30_0_1 Introduction The standard library is the set of components speciﬁed by the ISO Cplus_plus standard and shipped with identical behavior (modulo performance) by every Cplus_plus implementation.
For portability and longterm maintainability, I strongly recommend using the standard library whenever feasible.
Maybe you can design and implement a better alternative for your application, but:.
How easy will it be for some future maintainer to learn that alternative design.
How likely is the alternative to be available on a yet unknown platform ten years from now.
How likely is the alternative to be useful for future applications.
How likely is it that your alternative will be interoperable with code written using the standard library.
How likely is it that you can spend as much effort optimizing and testing your alternative as was done for the standard library.
And, of course, if you use an alternative, you (or your organization) will be responsible for the maintenance and evolution of the alternative "forever_0_" In general: try not to reinvent the wheel.
And that is without describing the ISO C standard library, which is a part of the Cplus_plus standard library (another 139 pages).
To compare, the Cplus_plus language speciﬁcation is 398 pages.
Here, I summarize, relying heavily on tables, and give a few examples.
Details can be found elsewhere, including online copies of the standard, complete online documentation of implementations, and (if you like to read code) open source implementations.
Rely on the references to the standard for complete details.
The standard-library chapters are not intended to be read in their order of presentation.
Each chapter and typically each major subsection can be read in isolation.
Rely on cross-references and the index if you encounter something unknown.
One ideal is for a programmer to be able to ﬁnd ev ery interesting, signiﬁcant, and reasonably general class, function, template, etc_0_, in a library.
However, the question here is not "What ought to be in some library_0_" but "What ought to be in the standard library_0_" "Everything_0_" is a reasonable ﬁrst approximation to an answer to the former question but not to the latter.
A standard library is something that every implementer must supply so that every programmer can rely on it.
Support for language features, such as memory management (11_0_2), the range-for statement.
Information about implementation-deﬁned aspects of the language, such as the largest ﬁnite.
Primitive operations that cannot be easily or efﬁciently implemented in the language itself,.
Functions that most programmers cannot easily implement optimally and portably, such as.
Minimal support for (optional) reclamation of unused memory (garbage collection), such as.
Nonprimitive foundational facilities that a programmer can rely on for portability, such as.
Frameworks for extending the facilities it provides, such as conventions and support facilities that allow a user to provide I/O of a user-deﬁned type in the style of I/O for built-in A few facilities are provided by the standard library simply because it is conventional and useful to do so.
Examples are the standard mathematical functions, such as sqrt() (40_0_3), random number generators (40_0_7), complex arithmetic (40_0_4), and regular expressions (Chapter 37).
The standard library aims to be the common foundation for other libraries.
In particular, combinations of its facilities allow the standard library to play three supporting roles: ptg10564057 Section 30_0_1_0_1 Standard-Library Facilities 861.
A foundation for portability.
A set of compact and efﬁcient components that can be used as the foundation for performance-sensitive libraries and applications.
A set of components enabling intra-library communications The design of the library is primarily determined by these three roles.
These roles are closely related.
For example, portability is commonly an important design criterion for a specialized library, and common container types such as lists and maps are essential for convenient communication between separately developed libraries.
The last role is especially important from a design perspective because it helps limit the scope of the standard library and places constraints on its facilities.
For example, string and list facilities are provided in the standard library.
If they were not, separately developed libraries could communicate only by using built-in types.
However, advanced linear algebra and graphics facilities are not provided.
Such facilities are obviously widely useful, but they are rarely directly involved in communication between separately developed libraries.
Unless a facility is somehow needed to support these roles, it can be left to some library outside the standard.
For good and bad, leaving something out of the standard library opens the opportunity for different libraries to offer competing realizations of an idea.
Once a library proves itself widely useful in a variety of computing environments and application domains, it becomes a candidate for the standard library.
The regular expression library (Chapter 37) is an example of this.
A reduced standard library is available for freestanding implementations, that is, implementations running with minimal or no operating system support (6_0_1_0_1).
The facilities offered by the Cplus_plus standard library are designed to be:.
Valuable and affordable to essentially every student and professional programmer, including the builders of other libraries.
Used directly or indirectly by every programmer for everything within the library's scope.
Efﬁcient enough to provide genuine alternatives to hand-coded functions, classes, and templates in the implementation of further libraries.
Either policy free or with an option to supply policies as arguments.
Primitive in the mathematical sense.
That is, a component that serves two weakly related roles will almost certainly suffer overhead compared to individual components designed to perform only a single role.
Convenient, efﬁcient, and reasonably safe for common uses.
The standard library may leave major functions to other libraries, but if it takes on a task, it must provide enough functionality so that individual users or implementers need not replace it to get the basic job done.
Easy to use with built-in types and operations.
Type safe by default, and therefore in principle checkable at run time.
Supportive of commonly accepted programming styles.
Extensible to deal with user-deﬁned types in ways similar to the way built-in types and standard-library types are handled.
This is why the C standard-library qsort() takes a comparison function as an argument rather than relying on something ﬁxed, say, the < operator (12_0_5).
On the other hand, the overhead imposed by a function call for each comparison compromises qsort() as a building block for further library building.
For almost every data type, it is easy to do a comparison without imposing the overhead of a function call.
However, the function call overhead can dominate the execution time for some algorithms and cause users to seek alternatives.
The technique described in 25_0_2_0_3 of supplying comparison criteria through a template argument solves that problem for sort() and many other standard-library algorithms.
The sort example illustrates the tension between efﬁciency and generality.
It is also an example of how such tensions can be resolved.
A standard library is not merely required to perform its tasks.
It must also perform them so efﬁciently that users are not tempted to supply their own alternatives to what the standard offers.
Otherwise, implementers of more advanced features are forced to bypass the standard library in order to remain competitive.
This would add a burden to the library developer and seriously complicate the lives of users wanting to stay platform-independent or to use several separately developed libraries.
The requirements of "primitiveness" and "convenience of common uses" can conﬂict.
The former requirement precludes exclusively optimizing the standard library for common cases.
Howev er, components serving common, but nonprimitive, needs can be included in the standard library in addition to the primitive facilities, rather than as replacements.
The cult of orthogonality must not prevent us from making life convenient for the novice and the casual user.
Nor should it cause us to leave the default behavior of a component obscure or dangerous.
Consequently, I use an extremely abbreviated style of presentation.
Sets of related operations are typically presented in tables: Some Operations op does something to the range [b:e) and x, returning foo(x) foo does something to x but returns no result Does x have something to do with [b:e).
I try to be mnemonic when choosing identiﬁers, so b and e will be iterators specifying a range,  a pointer or an iterator, and x some value, all depending on context.
In this notation, only the commentary distinguishes no result from a Boolean result, so you can confuse those if you try hard enough.
For an operation returning a Boolean, the explanation usually ends with a question mark.
Where an algorithm follows the usual pattern of returning the end of an input sequence to indicate "failure," "not found," etc.
Usually, such an abbreviated description is accompanied with a reference to the ISO Cplus_plus standard, some further explanation, and examples.
The headers identify the major parts of the library.
Thus, listing them gives an overview of the library.
The rest of this subsection is a list of headers grouped by function, accompanied by brief explanations and annotated by references to where they are discussed.
The grouping is chosen to match the organization of the standard.
A standard header with a name starting with the letter c is equivalent to a header in the C standard library.
For every header <X_0_h> deﬁning part of the C standard library in the global namespace and also in namespace std, there is a header <cX> deﬁning the same names.
Ideally, the names from a <cX> header do not pollute the global namespace (15_0_2_0_4), but unfortunately (due to complexities of maintaining multilanguage, multi-operating-system environments) most do.
Containers <vector> One-dimensional resizable array 31_0_4_0_2 <deque> Double-ended queue 31_0_4_0_2 <forward_list> Singly-linked list 31_0_4_0_2 <list> Doubly-linked list 31_0_4_0_2 <map> Associative array 31_0_4_0_3 <set> Set 31_0_4_0_3 <unordered_map> Hashed associative array 31_0_4_0_3_0_2 <unordered_set> Hashed set 31_0_4_0_3_0_2 <queue> Queue 31_0_5_0_2 <stack> Stack 31_0_5_0_1 <array> One-dimensional ﬁxed-size array 34_0_2_0_1 <bitset> Array of bool 34_0_2_0_2 The associative containers multimap and multiset can be found in <map> and <set>, respectively.
The priority_queue (31_0_5_0_3) is declared in <queue>.
General Utilities <utility> Operators and pairs 35_0_5, 34_0_2_0_4_0_1 <tuple> Tuples 34_0_2_0_4_0_2 <type_traits> Type traits 35_0_4_0_1 <typeindex> Use a type_info as a key or a hash code 35_0_5_0_4 <functional> Function objects 33_0_4 <memory> Resource management pointers 34_0_3 <scoped_allocator> Scoped allocators 34_0_4_0_4 <ratio> Compile-time rational arithmetic 35_0_3 <chrono> Time utilities 35_0_2 <ctime> C-style date and time 43_0_6 <iterator> Iterators and iterator support 33_0_1 Iterators provide the mechanism to make standard algorithms generic (3_0_4_0_2, 33_0_1_0_4).
The C standard library functions bsearch() and qsort() apply to built-in arrays with elements of types without user-deﬁned copy constructors and destructors only (12_0_5).
Diagnostics <exception> Exception class 30_0_4_0_1_0_1 <stdexcept> Standard exceptions 30_0_4_0_1_0_1 <cassert> Assert macro 30_0_4_0_2 <cerrno> C-style error handling 13_0_1_0_2 <system_error> System error support 30_0_4_0_3 Assertions using exceptions are described in 13_0_4.
Strings and Characters <string> String of T Chapter 36 <cctype> Character classiﬁcation 36_0_2_0_1 <cwctype> Wide-character classiﬁcation 36_0_2_0_1 <cstring> C-style string functions 43_0_4 <cwchar> C-style wide-character string functions 36_0_2_0_1 <cstdlib> C-style allocation functions 43_0_5 <cuchar> C-style multibyte characters <regex> Regular expression matching Chapter 37 <cstring> header declares the strlen(), strcpy(), etc_0_, family of functions.
Input/Output <iosfwd> Forward declarations of I/O facilities 38_0_1 <iostream> Standard iostream objects and operations 38_0_1 <ios> iostream bases 38_0_4_0_4 <streambuf> Stream buffers 38_0_6 <istream> Input stream template 38_0_4_0_1 <ostream> Output stream template 38_0_4_0_2 <iomanip> Manipulators 38_0_4_0_5_0_2 <sstream> Streams to/from strings 38_0_2_0_2 <cctype> Character classiﬁcation functions 36_0_2_0_1 <fstream> Streams to/from ﬁles 38_0_2_0_1 <cstdio> printf() family of I/O 43_0_3 <cwchar> printf()-style I/O of wide characters 43_0_3 Manipulators are objects used to manipulate the state of a stream (38_0_4_0_5_0_2).
Language Support <limits> Numeric limits 40_0_2 <climits> C-style numeric scalar-limit macros 40_0_2 <cﬂoat> C-style numeric ﬂoating-point limit macros 40_0_2 <cstdint> Standard integer type names 43_0_7 <new> Dynamic memory management 11_0_2_0_3 <typeinfo> Run-time type identiﬁcation support 22_0_5 <exception> Exception-handling support 30_0_4_0_1_0_1 <initializer_list> initializ er_list 30_0_3_0_1 <cstddef> C library language support 10_0_3_0_1 <cstdarg> Variable-length function argument lists 12_0_2_0_4 <csetjmp> C-style stack unwinding <cstdlib> Program termination 15_0_4_0_3 <ctime> System clock 43_0_6 <csignal> C-style signal handling The <cstddef> header deﬁnes the type of values returned by sizeof(), size_t, the type of the result of pointer subtraction and of array subscripts, ptrdiff_t (10_0_3_0_1), and the infamous NULL macro (7_0_2_0_2).
C-style stack unwinding (using setjmp and longjmp from <csetjmp>) is incompatible with the use of destructors and with exception handling (Chapter 13, 30_0_4) and is best avoided.
C-style stack unwinding and signals are not discussed in this book.
Numerics <complex> Complex numbers and operations 40_0_4 <valarray> Numeric vectors and operations 40_0_5 <numeric> Generalized numeric operations 40_0_6 <cmath> Standard mathematical functions 40_0_3 <cstdlib> C-style random numbers 40_0_7 <random> Random number generators 40_0_7 For historical reasons, abs() and div() are found  <cstdlib> rather than  <cmath> with the rest of the mathematical functions (40_0_3).
The Cplus_plus standard library provides access to all such facilities: C Compatibility <cinttypes> Aliases for common integer types 43_0_7 <cstdbool> C bool <ccomplex> <complex> <cfenv> Floating-point environment <cstdalign> C alignment <ctgmath> C "type generic math": <complex> and <cmath> The <cstdbool> header will not deﬁne macros bool, true, or false.
The <cstdalign> header will not deﬁne a macro alignas.
The _0_h equivalents to <cstdbool>, <ccomplex>, <calign>, and <ctgmath> approximate Cplus_plus facilities for C.
Av oid them if you can.
The <cfenv> header provides types (such as fenv_t and fexcept_t), ﬂoating-point status ﬂags, and control modes describing an implementation's ﬂoating-point environment.
A user or a library implementer is not allowed to add or subtract declarations from the standard headers.
Nor is it acceptable to try to change the contents of a header by deﬁning macros to change the meaning of declarations  a header (15_0_2_0_3).
Any program or implementation that plays such games does not conform to the standard, and programs that rely on such tricks are not portable.
Even if they work today, the next release of any part of an implementation may break them.
Av oid such trickery.
For a standard-library facility to be used, its header must be included.
Writing out the relevant declarations yourself is not a standards-conforming alternative.
The reason is that some implementations optimize compilation based on standard header inclusion, and others provide optimized implementations of standard-library facilities triggered by the headers.
In general, implementers use standard headers  ways programmers cannot predict and shouldn't hav e to know about.
A programmer can, however, specialize utility templates, such as swap() (35_0_5_0_2), for non-standard-library, user-deﬁned types.
In <initializer_list>, we ﬁnd initializer_list: template<typename T> class initializer_list {.
Naturally, an  can also be used by a range-for.
For example: ptg10564057 868 Standard-Library Overview Chapter 30.
All standard-library containers (e_0_g_0_, vector  unordered_map)  strings support iteration using range-for; container adaptors (such as stack  priority_queue) do not.
The container headers, such as <vector>, include<initializ er_list>, so the user rarely has to do so directly.
Thus, their style  approaches to error handling are not consistent:.
C-style libraries consist of functions, many of which set errno to indicate that an error happened; see 13_0_1_0_2  40_0_3.
Many algorithms operating on a sequence of elements return an  to the one-past-thelast element to indicate "not found" or "failure"; see 33_0_1_0_1.
The I/O streams library relies on a state in each stream to reﬂect errors  may (if the user requests it) throw exceptions to indicate errors; see 38_0_3.
Some standard-library components, such as vector, string,  bitset, throw exceptions to indicate errors.
The standard library is designed so that all facilities obey "the basic guarantee" (13_0_2); that is, ev en if an exception is thrown, no resource (such as memory) is leaked  no invariant for a standard-library class is broken.
For example, a packaged_task will throw an exception if the function it is required to execute throws.
Unless you know that no facility is used in a way that could throw an exception, it is a good idea to always catch one of the root classes of the standard-library exception hierarchy (such as exception) as well as any exception (_0__0__0_) somewhere (13_0_5_0_2_0_3), for example, in main().
Instead, throw objects of types speciﬁcally deﬁned to be used as exceptions.
This hierarchy of standard exception classes provides a classiﬁcation of exceptions: exception logic_error runtime_error length_error domain_error out_of_range invalid_argument future_error range_error overﬂow_error underﬂow_error system_error bad_alloc bad_exception bad_cast bad_typeid ios_base::failure bad_array_new_length This hierarchy attempts to provide a framework for exceptions beyond the ones deﬁned by the standard library.
Logic errors are errors that in principle could be caught either before the program starts executing or by tests of arguments to functions and constructors.
Run-time errors are all other errors.
Not all exceptions are part of the standard-library exception hierarchy.
Howev er, all exceptions thrown by the standard library are from the exception hierarchy.
Unless you know that no facility is used in a way that could throw an exception, it is a good idea to somewhere catch all exceptions.
Re-throw the exception pointed to by ; =make_exception_ptr(e) is an exception_ptr to exception e; noexcept An exception_ptr can point to any exception, not just exceptions from the exception hierarchy.
Think of exception_ptr as a smart pointer (like shared_ptr) that keeps its exception alive for as long as an exception_ptr points to it.
That way, we can pass an exception_pointer to an exception out of a function that caught it and re-throw elsewhere.
In particular, an exception_ptr can be used to implement a re-throw of an exception in a different thread from the one in which the exception was caught.
This is what promise and future (42_0_4) rely on.
Use of rethrow_exception() on an exception_ptr (from different threads) does not introduce a data race.
Default constructor:  holds an exception_ptr to the current_exception(); noexcept nested_exception  {2}; Copy constructor: both  and 2 hold an exception_ptr to the stored exception 2= Copy assignment: both  and 2 hold an exception_ptr to the stored exception Destructor; virtual.
An exception cannot propagate out of a noexcept function (13_0_5_0_1_0_1).
In <exception>, the standard library provides facilities for dealing with unexpected exceptions: ptg10564057 Section 30_0_4_0_1_0_3 873.
Terminate the program; noreturn; noexcept Has an exception been thrown on the current thread and not yet been caught.
A call of terminate() terminates a program by calling a terminate handler set by a call of set_terminate().
The – almost always correct – default is to immediately terminate the program.
For fundamental operating system reasons, it is implementation-deﬁned whether destructors for local objects are invoked when terminate() is called.
If terminate() is invoked as the result of a noexcept violation, the system is allowed (important) optimizations that imply that the stack may even be partially unwound (iso_0_15_0_5_0_1).
It is sometimes claimed that uncaught_exception() can be useful for writing destructors that behave differently depending on whether a function is exited normally or by an exception.
Howev er, uncaught_exception() is also true during stack unwinding (13_0_5_0_1) after the initial exception has been caught.
I consider uncaught_exception() too subtle for practical use.
The assert() is a macro found in <cassert>.
The error message produced by assert() is implementation-deﬁned but should contain the source ﬁle name (__FILE__), and the source line number (__LINE__) containing the assert().
Asserts are (as they should be) used more frequently in production code than in small illustrative textbook examples.
It can be a serious mistake to assume that the assert() is evaluated when it is not.
For example, given a usual compiler setup, assert(_0_=nullptr) will catch an error during debugging, but not in the ﬁnal shipped product.
For a way to manage assertions, see 13_0_4.
For example, we may write a function to check a ﬁle name and then open a ﬁle like this:.
Assuming that "the system" doesn't know about Cplus_plus exceptions, we have no choice about whether to deal with error codes or not; the only questions are "where_0_" and "how_0_" In <system_error>, the standard library provides facilities for classifying error codes, for mapping systemspeciﬁc error codes into more portable ones, and for mapping error codes into exceptions: System Error Types error_code Holds a value identifying an error and the category of that error; error_categor y A base class for types used to identify the source and encoding system_error error_condition Holds a value identifying an error and the category of that error; errc enum class with enumerators for error codes  <cerrno> (40_0_3); basically POSIX error codes future_errc io_errc ptg10564057 Section 30_0_4_0_3_0_1 Error Codes 875 30_0_4_0_3_0_1 Error Codes When an error "bubbles up"  a lower level as an error code, we must handle the error it represents or turn it into an exception.
But ﬁrst we must classify it: different systems use different error codes for the same problem, and different systems simply have different kinds of errors.
For a type representing the simple idea of an error code, error_code provides a lot of members.
It is basically as simple map  an integer to a pointer to an error_categor y: ptg10564057 876 Standard-Library Overview Chapter 30 class error_code { public: // representation: {,categor y} of type {int,const error_category*} }; An error_categor y is an interface to an object of a class derived  error_categor y.
The reason is  == is deﬁned in terms of equivalence, taking both the error () and the error () into account.
The operations on error_codes are system-speciﬁc.
In some cases, error_codes can be mapped into error_conditions (30_0_4_0_3_0_4) using the mechanisms described in 30_0_4_0_3_0_5.
An error_condition typically contains less information than an error_code, so it is usually a good idea to keep the error_code available and only extract its error_condition when needed.
Manipulating error_codes does not change the  of errno (13_0_1_0_2, 40_0_3).
The standard library leaves the error states provided  other libraries unchanged.
Speciﬁc errors are represented  a class derived  class error_categor y: class error_categor y { public: // _0__0_.
Access an error_categor y through pointers or references.
There are four named standard-library categories: _0_()=="g eneric";  is a reference to an error_categor y.
For example, 1 means "operation not permitted" (EPERM) in POSIX, is a generic code (state) for all errors as an iostream error, and means "future already retrieved" (future_already_retrieved) as a future error.
It passes along an error_code and optionally an error-message string: class  : public runtime_error { public: // _0__0_.
Naturally, system_errors can be used  code  is not part of the standard library.
A system-speciﬁc error_code is passed, rather than a potentially portable error_condition (30_0_4_0_3_0_4).
The general idea is  each system has a set of speciﬁc ("native") codes  are mapped into the potentially portable ones for the convenience of programmers of programs (often libraries) need to work on multiple platforms.
For example: enum class future_errc { = 1, future_already_retrieved, promise_already_satisﬁed, no_state }; The meaning of these values is completely -speciﬁc.
The integer values of these enumerators are implementation-deﬁned.
The future error  is part of the standard, so you can ﬁnd it in your standard library.
The details are likely to differ from  I describe.
Next, we need to deﬁne a suitable  for our error codes: class future_cat : error_categor y {.
For example, an argument intended to become the () of an error_code of future_category() must be a future_errc.
For error_condition to work for our , we must repeat  we did for error_code.
For example: error_condition make_error_condition(future_errc e) noexcept; template<> struct <future_errc> : public true_type { }; For a  more interesting design, we could use a separate enum for the error_condition and have make_error_condition() implement a mapping from future_errc to that.
For systems supporting POSIX-like facilities, they are also valid for the "generic" category: generic_categor y().
The POSIX macros are integers whereas the errc enumerators are of type errc.
Container Overview Container Representation; Element Requirements.
Operations Overview Member Types; Constructors, Destructor, and Assignments; Size and Capacity; Iterators; Element Access; Stack Operations; List Operations; Other Operations.
Containers vector; Lists; Associative Containers.
Container Adaptors stack; queue; priority_queue.
Advice 31_0_1 Introduction The STL consists of the iterator, container, algorithm, and function object parts of the standard library.
The rest of the STL is presented in Chapter 32 and Chapter 33.
This section summarizes the types of containers and brieﬂy outlines their properties.
Operations on containers are summarized in 31_0_3.
Sequence containers provide access to (half-open) sequences of elements.
Associative containers provide associative lookup based on a key.
In addition, the standard library provides types of objects that hold elements while not offering all of the facilities of sequence containers or associative containers:.
Container adaptors provide specialized access to underlying containers.
Almost containers are sequences of elements that provide most, but not all, of the facilities of a container.
The STL containers (the sequence and associative containers) are all resource handles with copy and move operations (3_0_3_0_1).
All operations on containers provide the basic guarantee (13_0_2) to ensure that they interact properly with exception-based error handling.
Sequence Containers vector<T,A> A contiguously allocated sequence of Ts; the default choice of container list<T,> doubly-linked list of T; use when you need to insert and delete elements without moving existing elements forward_list<T,> singly-linked list of T; ideal for empty  very short sequences deque<T,> double-ended queue of T; a cross between a vector  a list; slower than one or the other for most uses The  template argument is the  that the container uses to acquire  release memory (13_0_6_0_1, 34_0_4).
For example: template<typename T, typename  = <T>>.
These containers are deﬁned in <vector>, <list>,  <deque>.
The sequence containers are contiguously allocated (e_0_g_0_, vector) or linked lists (e_0_g_0_, forward_list) of  of their value_type (T in the notation used above).
Unless you have a solid reason not to, use a vector.
Note that vector provides operations for inserting  erasing (removing) , allowing a vector to grow  shrink as needed.
For sequences of small , a vector can be an excellent representation for a data structure requiring list operations.
When inserting  erasing  of a vector,  may be moved.
In contrast, of a list or an associative container do not move when   are inserted or other are erased.
An empty forward_list takes up only one word.
There are surprisingly many uses for lists where most are empty ( the rest are very short).
The default ordering criterion for a key, K, is std::less<K> (33_0_4).
As for sequence containers, the  template argument is the  that the container uses to acquire  release memory (13_0_6_0_1, 34_0_4).
The  template argument is defaulted to std::<std::pair<const K,T>> (31_0_4_0_3) for maps  std::<K> for sets.
H is the hash function type; E is the equality test;  is the  type unordered_map<K,V,H,E,> An unordered map from K to V unordered_multimap<K,V,H,E,> An unordered map from K to V; duplicate keys allowed unordered_set<K,H,E,> An unordered set of K unordered_multiset<K,H,E,> An unordered set of K; duplicate keys allowed These containers are implemented as hash tables with linked overﬂow.
The default hash function type, H, for a type K is std::hash<K> (31_0_4_0_3_0_2).
The default for the equality function type, E, for a type K is std::equal_to<K> (33_0_4); the equality function is used to decide whether two objects with the same hash code are equal.
The associative containers are linked structures (trees) with nodes of their value_type (in the notation used above, pair<const K,V> for maps  K for sets).
The sequence of a set, map, or multimap is ordered by its key value (K).
An unordered container need not have an ordering relation for its  (e_0_g_0_, <)  uses a hash function instead (31_0_2_0_2_0_1).
The sequence of an unordered container does not have a guaranteed order.
Container adaptors are containers providing specialized interfaces to other containers: Container Adaptors C is the container type priority_queue<T,C,Cmp> Priority queue of Ts; Cmp is the priority function type queue<T,C> stack<T,C> The default for a priority_queue's priority function, Cmp, is std::less<T>.
The default for the container type, C, is std::deque<T> for queue  std::vector<T> for stack  priority_queue.
Some data types provide much of what is required of a standard container, but not all.
We sometimes refer to those as "almost containers_0_" The most interesting of those are: ptg10564057 888 STL Containers Chapter 31 T[N] ﬁxed-size built-in array: N contiguous  of type T; no siz e() or other member functions array<T,N> ﬁxed-size array of N contiguous  of type T; like the built-in array, but with most problems solved basic_string<C,Tr,> contiguously allocated sequence of characters of type C with text manipulation operations, e_0_g_0_, concatenation (+  +=); basic_string is typically optimized not to require free store for string basic_string<char> u16string basic_string<char16_t> u32string basic_string<char32_t> wstring basic_string<wchar_t> valarray<T> numerical vector with vector operations, but with restrictions to encourage high-performance implementations; use only if you do a lot of vector arithmetic bitset<N> A set of N bits with set operations, such as &  | vector<bool> A specialization of vector<T> with compactly stored bits For basic_string, A is the  (34_0_4)  Tr is the character traits (36_0_2_0_2).
Prefer a container, such as vector, string, or array, over an array when you have a choice.
The implicit array-to-pointer conversion  the need to remember the size for a built-in array are major sources of errors (e_0_g_0_, see 27_0_2_0_1).
Prefer the standard strings to other strings  to C-style strings.
The pointer semantics of Cstyle strings imply an awkward notation  extra work for the programmer,  they are a major source of errors (such as memory leaks) (36_0_3_0_1).
Instead, the standard speciﬁes the container interfaces  some complexity requirements.
Implementers will choose appropriate  often cleverly optimized implementations to meet the general requirements common uses.
In addition to what is needed to manipulate elements, such a "handle" will hold an allocator (34_0_4).
For a vector, the element data structure is most likely an array: rep elements free space vector: The vector will hold a pointer to an array of elements, the number of elements,  the capacity (the number of allocated, currently unused slots) or equivalent (13_0_6).
Like vector, a string can grow into "free space" allocated to avoid repeated reallocations: rep string: characters free space Like a built-in array (7_0_3), an array is simply a sequence of elements, with no handle: elements array: This implies that a local array does not use any free store (unless it is allocated there) and that an array member of a class does not imply any free store operations.
If a container copies an element using a copy constructor or copy assignment, the result of the copy must be an equivalent object.
This roughly means that any test for equality that you can devise on the value of the objects must deem the copy equal to the original.
In other words, copying an element must work much like an ordinary copy of an int.
Similarly, a move constructor and a move assignment must have the conventional deﬁnitions and move semantics (17_0_5_0_1).
In addition, it must be possible to swap() elements with the usual semantics.
If a type has copy or move, the standard-library swap() will work.
The details of the element requirements are scattered over the standard and quite hard to read (iso_0_23_0_2_0_3, iso_0_23_0_2_0_1, iso_0_17_0_6_0_3_0_2), but basically a container can hold elements of a type that will work as long as the requirements for being a container element are met as well as the algorithm's speciﬁc requirements (such as elements being ordered; 31_0_2_0_2_0_1).
Some violations of the rules for standard containers can be detected by a compiler, but others cannot and might then cause unexpected behavior.
For example, an assignment operation that throws an exception might leave a partially copied element behind.
That would be bad design (13_0_6_0_1) and would violate the rules of the standard by not providing the basic guarantee (13_0_2).
An element in an invalid state could cause serious trouble later.
When copying objects is not reasonable, an alternative is to put pointers to objects into containers instead of the objects themselves.
The most obvious example is polymorphic types (3_0_2_0_2, 20_0_3_0_2).
For example, we use vector<unique_ptr<Shape>> or vector<Shape∗> rather than vector<Shape> to preserve polymorphic behavior.
So do many operations that can be applied to containers (e_0_g_0_, sort() and merge()).
By default, the < operator is used to deﬁne the order.
If < is not suitable, the programmer must provide an alternative (31_0_4_0_3, 33_0_4).
The ordering criterion must deﬁne a strict weak ordering.
Informally, this means that both less-than and equality (if deﬁned) must be transitive.
That is, for an ordering criterion cmp (think of it as "less than") we require: [1] Irreﬂexivity: cmp(,) is false.
Transitivity of equivalence: Deﬁne equiv(,y) to be _0_(cmp(,y)||cmp(y,)).
The last rule is the one that allows us to deﬁne equality (==y) as _0_(cmp(,y)||cmp(y,)) if we  ==.
For example, we might decide to sort fruit using a comparison that isn't case sensitive.
We do that by deﬁning a function object (3_0_4_0_3, 19_0_2_0_2) that does the comparison when invoked for a pair of strings: class Nocase {.
Thus, associative containers will not work as most people would expect them to if C-style strings are used as keys.
To make them work properly, a less-than operation that compares based on lexicographical order must be used.
When the default isn't right, a programmer can supply a comparison criterion.
However, no mechanism is provided for also passing an equality test.
Instead, when a programmer supplies a comparison cmp, equality is tested using two comparisons.
For example: // not done where the user supplied a comparison if (_0_cmp(,y) && _0_cmp(y,)) // done where the user supplied a comparison cmp This saves the user from having to provide an equality operation for every type used as the value type for an associative container or by an algorithm using a comparison.
It may look expensive, but the library doesn't check for equality very often, in about 50% of the cases only a single call of cmp() is needed,  often the compiler can optimize away the double check.
Using an equivalence relationship deﬁned by less-than (by  <) rather than equality (by ==) also has practical uses.
For example, associative containers (31_0_4_0_3) compare keys using an equivalence test _0_(cmp(,y)||cmp(y,)).
This implies that equivalent keys  not be equal.
For example, a multimap (31_0_4_0_3) that uses case-insensitive comparison as its comparison criterion will consider the strings Last, last, lAst, laSt,  lasT equivalent, even  == for strings deems them different.
This allows us to ignore differences we consider insigniﬁcant when sorting.
The standard library deﬁnes them in the namespace std::rel_ops  presents them in <utility> (35_0_5_0_3).
A question mark (_0_) indicates a simpliﬁcation: I have included operations that are provided for only some of the containers.
In particular: ptg10564057 894 STL Containers Chapter 31.
A multi∗ associative container  a set does not  []  at().
A forward_list does not  insert(), erase(),  emplace(); instead, it provides the ∗_after operations.
A forward_list does not  reverse_iterator, const_reverse_iterator, rbegin(), rend(), crbegin(), (),  size().
A unordered_∗ associative container does not  <, <=, >,  >=.
The []  at() operations are replicated simply to reduce the number of arrows.
The bucket interface is described in 31_0_4_0_3_0_2.
Where meaningful, an access operation exists in two versions: one for const  one for nonconst objects.
The standard-library operations have complexity guarantees: Standard Container Operation Complexity [] List Front Back Iterators 31_0_2_0_2 31_0_3_0_7 31_0_4_0_2 31_0_3_0_6 33_0_1_0_2 vector const O(n)+ const+ Ran list const const const Bi forward_list const const For deque const const const Ran stack const queue const const priority_queue O(log(n)).
Bi multimap O(log(n))+ Bi set O(log(n))+ Bi multiset O(log(n))+ Bi unordered_map const+ const+ For unordered_multimap const+ For unordered_set const+ For unordered_multiset const+ For string const O(n)+ O(n)+ const+ Ran array const Ran built-in array const Ran valarray const Ran bitset const "Front" operations refer to insertion and deletion before the ﬁrst element.
Similarly, "Back" operations refer to insertion and deletion after the last element, and "List" operations refer to insertion and deletion not necessarily at the ends of a container.
In the Iterators column, "Ran" means "random-access iterator," "For" means "forward iterator," and "Bi" means "bidirectional iterator" (33_0_1_0_4).
A const entry means the operation takes an amount of time that does not depend on the number of elements in the container; another conventional notation for constant time is O(1).
O(n) means the operation takes time proportional to the number of elements involved.
A + sufﬁx indicates that occasionally a signiﬁcant extra cost is incurred.
For example, inserting an element into a list has a ﬁxed cost (so it is listed as const), whereas the same operation on a vector involves moving the elements following the insertion point (so it is listed as O(n)).
Occasionally, all elements of a vector must be relocated (so I added a +).
The "big O" notation is conventional.
I added the + for the beneﬁt of programmers who care about predictability in addition to average performance.
A conventional term for O(n)+ is amortized linear time.
Naturally, if a  constant is large, it can dwarf a small cost proportional to the number of ele and O(log(n)) to mean "fairly cheap_0_" For even moderately large values of n, O(log(n)), where log is the binary logarithm, is far closer to constant time than to O(n).
For example: Logarithm Examples n 16 128 1,024 16,384 1,048,576 log(n) 4 7 10 14 20 n∗n 256 802,816 1,048,576 268,435,456 1_0_1e+12 People who care about cost must take a closer look.
In particular, they must understand what elements are counted to get the n.
Howev er, the message is clear: don't mess with quadratic algorithms for larger values of n.
The measures of complexity and cost are upper bounds.
The measures exist to give users some guidance as to what they can expect from implementations.
Naturally, implementers will try to do better in important cases.
Note that the "Big O" complexity measures are asymptotic; that is, it could require a lot of elements before complexity differences matter.
Other factors, such as the cost of an individual operation on an element, may dominate.
For example, traversing a vector and a list both have complexity O(n).
Howev er, giv en modern machine architectures, getting to the next element through a link (in a list) can be very much more expensive than getting to the next element of a vector (where the elements are contiguous).
Similarly, a  linear algorithm may take signiﬁcantly more or signiﬁcantly less than ten times as long for ten times as many elements because of the details of memory and processor architecture.
Don't just trust your intuition about cost and your complexity measures; measure.
Fortunately, the container interfaces are so similar that comparisons are easy to code.
The size() operation is constant time for all operations.
Note that forward_list does not have size(), so if you want to know the number of elements, you must count them yourself (at the cost of O(n)).
A forward_list is optimized for space and does not store its size or a pointer to its last element.
The string estimates are for longer strings.
The "short string optimization" (19_0_3_0_3) makes all operations of short strings (e_0_g_0_, less than 14 characters) constant time.
The entries for stack and queue reﬂect the cost for the default implementation using a deque as the underlying container (31_0_5_0_1, 31_0_5_0_2).
However, they don't provide types that are not meaningful.
For example, array does not have an allocator_type and vector does not have a key_type.
For a container called C (e_0_g_0_, vector<double> or map<string,int>) we hav e: C is a container; by default, a C uses the default allocator C::allocator_type{} C c {}; Default constructor: c is an empty container.
C c(n,x,a); Initialize c with n copies of x; use allocator a; not for associative containers ptg10564057 Section 31_0_3_0_2 Constructors, Destructor, and Assignments 897 C is a container; by default, a C uses the default allocator C::allocator_type{} C c {elem};.
Initialize  with elements from [b:e); use allocator a Destructor: destroy 's elements and release all resources 2= Copy assignment: copy 's elements into 2.
Assign to  from initializer_list {elem} Additional constructors for associative containers are described in 31_0_4_0_3.
Note that an assignment does not copy or move allocators.
A target container gets a new  of but retains its old container, which it uses to allocate space for the new  (if any).
Remember that a constructor or an element copy may throw an exception to indicate that it cannot perform its tasks.
The potential ambiguities for initializers are discussed in 11_0_3_0_3 and 17_0_3_0_4_0_1.
Use () for size initializers and {} for every other kind of iterator.
Containers are often large, so we almost always pass them by reference.
However, because they are resource handles (31_0_2_0_1), we can return them (implicitly using move) efﬁciently.
Similarly, we can move them as arguments when we don't want aliasing.
For example: ptg10564057 898 STL Containers Chapter 31.
Erase all  of When changing the size or the capacity, the  may be moved to new  locations.
That implies that iterators (and pointers and references) to  may become invalid (i_0_e_0_, point to the old element locations).
For an example, see 31_0_4_0_1_0_1.
An iterator to an element of an associative container (e_0_g_0_, a map) is only invalidated if the element to which it points is removed from the container (erase()d; 31_0_3_0_7).
To contrast, an iterator to an element of a sequence container (e_0_g_0_, a ) is inv alidated if the  are relocated (e_0_g_0_, by a resize(), reserve(), or push_back()) or if the element to which it points is moved within the container (e_0_g_0_, by an erase() or insert() of an element with a lower index).
It is tempting to assume that reserve() improves performance, but the standard growth strategies for  (31_0_4_0_1_0_1) are so effective that performance is rarely a good reason to use reserve().
Instead, see reserve() as a way of increasing the predictability of performance and for avoiding invalidation of iterators.
For an associative container, the order is based on the containers comparison criterion (by default <): Iterators =_0_begin() points to ﬁrst element of =_0_end().
The simplest way of doing that is by a range-for (9_0_5_0_1) which implicitly uses begin() and end().
For example: <<  << '\n'; When we need to know the position of an element in a container or if we need to refer to more than.
Where such issues are important, examine your implementations.
The associative containers map and unordered_map have [] and at() that take arguments of the key type, rather than positions (31_0_4_0_3).
If we run out of memory or 's copy constructor throws an exception, c_0_push_back() fails.
A failed push_back() has no effect on the container: the strong guarantee is offered (13_0_2).
Note that pop_back() does not return a value.
Had it done so, a copy constructor throwing an exception could seriously complicate the implementation.
In addition, list and deque provide the equivalent operations on the start (front) of their sequences (31_0_4_0_2).
The push_back() is a perennial favorite for growing a container without preallocation or chance of overﬂow, but emplace_back() can be used similarly.
Add elements from [ﬁrst:last) before ;.
Erase [ﬁrst:last) of c Erase all elements of c For insert() functions, the result, , points to the last  inserted.
For erase() functions, points to the  that followed the last  erased.
For containers with contiguous allocation, such as  and deque, inserting and erasing an can cause elements to be moved.
An iterator pointing to a moved  becomes invalid.
An  is moved if its position is after the insertion/deletion point or if all elements are moved because the new  exceeds the previous capacity.
The forward_list does not provide operations, such as insert(), that operate before an  identiﬁed by an iterator.
Such an operation could not be implemented because there is no general way of ptg10564057 902 STL Containers Chapter 31 ﬁnding the previous  in a forward_list given only an iterator.
Instead, forward_iterator provides operations, such as insert_after(), that operate after an  identiﬁed by an iterator.
Similarly, unordered containers use emplace_hint() to provide a hint rather than "plain" emplace().
When comparing containers with an operator (e_0__0_, <=), the elements are compared using the equivalent  operator generated  == or < (e_0__0_, a>b is done using _0_(b<a)).
The swap() operations exchange both elements and allocators.
If your suggested alternative is a  or a built-in array, think twice.
However, giv en the importance of , this section takes a second look with more emphasis on how the operations are provided.
The 's template argument and member types are deﬁned like this: template<typename T, typename  = allocator<T>> class  {.
The standard does not specify by how much capacity is increased when it is exceeded, but adding half the  is common.
I used to be careful about using reser ve() when I was reading into a.
I was surprised to ﬁnd that for essentially all of my uses, calling reser ve() did not measurably affect performance.
The default growth strategy worked just as well as my estimates, so I stopped trying to improve performance using reser ve().
Instead, I use it to increase predictability of reallocation delays and to prevent invalidation of pointers and iterators.
The notion of capacity allows for iterators into a  to be valid unless a reallocation actually happens.
Consider reading letters into a buffer and keeping track of word boundaries: <char> chars; // input "buffer" for characters constexpr int  = 20000;.
Had I not used reserve() here, the pointers in words would have been invalidated if chars_0_push_back() caused a relocation.
By "invalidated," I mean that any use of those pointers would be undeﬁned behavior.
They may – or may not – point to an , but almost certainly not to the elements they pointed to before the relocation.
The ability to grow a  using push_back() and related operations implies that low-level Cstyle use of malloc() and realloc() (43_0_5) is as unnecessary as it is tedious and error-prone.
The elements of a  are compactly stored: there is no per-element memory overhead.
The amount of memory consumed by a vec of type <X> is roughly sizeof(<X>)+vec_0_size()∗sizeof(X).
The sizeof(<X>) is about 12 bytes, which is insigniﬁcant for larger vectors.
Traversal of a  is very fast.
To get to the next element, the code does not have to indirect through a , and modern machines are optimized for consecutive access through a -like structure.
This makes linear scans of  elements, as in ﬁnd() and copy(), close to optimal.
This is what makes many algorithms on vectors, such as sort() and binary_search(), efﬁcient.
It is easy to underestimate these beneﬁts.
For example, a doubly-linked list, such as list, usually incurs a four-words-per-element memory overhead (two links plus a free-store allocation header), and traversing it can easily be an order of magnitude more expensive than traversing a  containing equivalent data.
The effect can be so spectacular and surprising that I suggest you test it yourself [Stroustrup,2012a].
Consider how to represent a two-dimensional matrix.
There are two obvious alternatives:.
A  of vectors: <<double>> accessed by C-style double subscripting: m[i][j].
A speciﬁc matrix type, Matrix<2,double> (Chapter 29), that stores elements contiguously The memory layout for a 3-by-4 <<double>> looks like this: The memory layout for Matrix<2,double> looks like this: To construct the <<double>>, we need four constructor calls with four free-store allocation operations.
To access an element, we need to do a double indirection.
To construct the Matrix<2,double>, we need one constructor call with one free-store allocation.
To access an element, we need a single indirection.
Once we reach an element of a row, we don't need a further indirection to access its successor, so access to the <<double>> is not always twice as costly as access to Matrix<2,double>.
However, for algorithms that require high performance, the allocation, deallocation,  access costs implied by the linked structure of <<double>> could be a problem.
The <<double>> solution implies the possiblity of the row having different sizes.
There are cases where that is an advantage, but more often it is simply an opportunity for errors a burden for testing.
The problems  overhead get worse when we need higher dimensions: compare the number of added indirections  allocations for a <<<double>>>  a Matrix<3,double>.
In summary, I note that the importance of compactness of data structures is often underestimated or compromised.
The advantages are logical as well as performance related.
Combine this with a tendency to overuse pointers  new  we have a widespread problem.
For example, consider the development complexities, run-time costs, memory costs,  opportunities for errors in an implementation of a two-dimensional structure when the rows are implemented as independent objects on the free store: <<double>∗>.
This is what allows it to be resized  enables efﬁcient move semantics.
However, that occasionally puts it at a disadvantage compared to data structures (such as built-in arrays  ) that do not rely on storing elements separately from a handle.
Keeping a sequence of elements on the stack or in another object can give a performance advantage, just as it can be a disadvantage.
A  deals with properly initialized objects.
This is what allows us to use them simply rely on proper destruction of elements.
However, that occasionally puts it at a disadvantage compared to data structures (such as built-in arrays  ) that allow uninitialized elements.
As an example, we need not initialize  elements before reading into them:.
A  is a general mechanism for storing values.
It makes no assumptions about the relationships among the values stored in it.
To a <char>, the string Hello, World.
Sorting them into _0_,HWdellloor (preceded by a space) makes sense.
To contrast, a string is intended to hold character sequences.
The relationships among the characters are assumed to be important.
So, for example, we rarely sort the characters in a string because that destroys meaning.
Some string operations reﬂect that (e_0_g_0_, c_str(), >>,  ﬁnd() "know" that Cstyle strings are zero-terminated).
The implementations of string reﬂect assumptions about the way we use strings.
For example, the short-string optimization (19_0_3_0_3) would be a pure pessimization if it wasn't for the fact that we use many short strings, so that minimizing free-store use becomes worthwhile.
I suspect not, but it would require a massive empirical study to be sure.
When you insert into a list or delete an element from a list, the locations of other elements of the list are not affected.
In particular, iterators referring to other elements are not affected.
If necessary, use advance()  similar operations to navigate lists (33_0_1_0_4).
A list can be traversed using iterators: list provides bidirectional iterators (33_0_1_0_2)  forward_list provides forward iterators (hence the name of that type of list).
By default, list elements are individually allocated in memory  include predecessor  successor pointers (11_0_2_0_2).
Compared to a vector, a list uses more memory per element (usually at least four words more per element),  traversals (iteration) are signiﬁcantly slower because they involve indirection through pointers rather than simple consecutive access.
A forward_list is a singly-linked list.
Think of it as a data structure optimized for empty or very short lists that you typically traverse starting from the beginning.
For compactness, forward_list doesn't even provide a size(); an empty forward_list takes up just one word of memory.
If you need to know the number of elements of a forward_list, just count them.
If there are enough elements to make counting them expensive, maybe you should use a different container.
With the exception of subscripting, capacity management,  size() for forward_list, the STL lists provide the member types  operations offered by vector (31_0_4).
In addition, list  forward_list provide speciﬁc list member functions: Add  to lst (using copy or move) before the ﬁrst element.
Sort lst  f as the order Reverse the order of the elements of lst; noexcept As opposed to the general remove()  unique() algorithms (32_0_5), the member algorithms really.
The merge() algorithm is stable; that is, equivalent elements keep their relative order.
Insert the elements [b:e) from lst2 before ; the elements [b:e) are removed from lst2.
Splice in 2 after ; remove 2 from lst2 Splice in [b:e) after ; remove [b:e) from lst2 These  operations are all stable; that is, they preserve the relative order of elements that have equivalent values.
They come in two variants:.
Ordered associative containers do lookup based on an ordering criterion, by default < (less than).
They are implemented as balanced binary trees, usually red-black trees.
Unordered associative containers do lookup based on a hash function.
They are implemented as hash tables with linked overﬂow.
Finally, maps and sets, whether ordered or unordered, come in two variants:.
Internally, a map and an unordered_map are very different.
See 31_0_2_0_1 for graphical representations.
In particular, map uses its comparison criterion (typically <) on a key to search through a balanced tree (an O(log(n)) operation), whereas unordered_map applies a hash function on a key to ﬁnd a slot in a hash table (an O(1) operation for a good hash function).
If a , k, is not found by a subscript operation, m[k], a default value is inserted.
For example: <string,string> dictionary; dictionary[""]="large body of water"; // inser t or assign to cout << dictionary["seal"]; // read value If seal is not in the dictionary, nothing is printed: the empty string was entered as the value for seal and returned as the result of the lookup.
The insert(make_pair()) notation is rather verbose.
Instead, we could use emplace(): dictionary_0_emplace(" cow","extinct"); Depending on the quality of the optimizer, this may also be more efﬁcient.
If you try to insert a  into a  and there already is an  with its , the  is unchanged.
If you want to have more than one  for a single , use a.
You can print the  of all elements with the  "apple" in a <string,int> like this: <string,int> mm {{"apple",2}, { "pear",2}, {"apple",7}, {"orange",2}, {"apple",9}};.
However, that would imply an extra traversal of the.
The equal_range(), lower_bound(), and upper_bound() are also provided for sorted sequences (32_0_6).
I tend to think of a set as a  with no separate.
Don't try to modify a : if you were to succeed, the underlying mechanism for ﬁnding elements would break.
For simple uses, there are few differences from (ordered) containers because the associative containers share most operations (31_0_4_0_3_0_1).
In particular, there is no guarantee that elements are printed in the order of their insertion.
By default, an <X> uses hash<X> for hashing and equal_to<X> to compare keys.
The general (primary) template hash doesn't hav e a deﬁnition.
It is up to users of a type X to deﬁne hash<X> if needed.
For common types, such as string, standard hash specializations are provided, so the user need not provide them: Types with hash<T> (iso_0_20_0_8_0_12) Supplied by the Standard Library string u16string u32string wstring C-style string bool characters integers ﬂoating-point types pointers type_index thread::id error_code bitset<N> unique_ptr<T,D> shared_ptr<T> A hash function (e_0_g_0_, a specialization of hash for a type T or a  to function) must be callable with an argument of type T and return a size_t (iso_0_17_0_6_0_3_0_4).
Two calls of a hash function for the same  must give the same result, and ideally such results are uniformly distributed over the of size_t values so as to minimize the chances that h()==h(y) if _0_=y.
There is a potentially bewildering  of combinations of template argument types, constructors, and defaults for an unordered container.
Fortunately, there is a pattern: m {n,hf,eql,a}; Construct m with n buckets, the hash function hf, the equality function eql,.
Here, n is an element count for an otherwise empty.
The number of elements will be then number of elements in [b:e), distance(b,e).
The number of elements in the  will be the number of elements in the initializer list.
Finally,  has copy and move constructors, and also equivalent constructors that supply allocators: m {m2}; Copy and move constructors: construct m from m2 m {a}; Default construct m and give it allocator a; explicit m {m2,a}; Construct m from m2 and give it allocator a.
Try something like: <string,int> um {100,My_hasher}; // OK 31_0_4_0_3_0_4  and Equality Functions Naturally, a user can deﬁne a hash function.
Different techniques serve different needs.
Here, I present several versions, starting with the most explicit and ending with the simplest.
Consider a simple Record type:.
I used decltype to avoid having to explicitly repeat the types of hf and eq.
If we don't hav e an initializer list handy, we can give an initial  instead: <Record,decltype(&hf),decltype(&eq)> m {10,hf,eq}; That also makes it a bit easier to focus on the  and equality operations.
If we wanted to avoid separating the deﬁnitions of hf and eq from their point of use, we could try lambdas: <Record,.
The point about using (named or unnamed) lambdas instead of functions is that they can be deﬁned locally in a , next to their use.
However, here,  may incur overhead that I would prefer to avoid if the was heavily used.
Also, I consider that version messy and prefer to  the lambdas: auto  = [](const Record& r) { return <string>()(r_0_)<int>()(r_0_); }; auto  = [](const Record& r, const Record& r2) { return r_0_==r2.
The default  and hashes obtained from it by using exclusive-or are often pretty good.
Don't rush to use homemade  functions without experimentation.
Keys with the same  value are said to be "in the same bucket" (see 31_0_2_0_1).
A programmer can examine and set the  of the  table (known as "the number of buckets"): =c_0_hash_function() is c's =c_0_key_eq().
For example, if the capacity() is 100 elements and the () is 30, the load_factor() is 0_0_3.
Note that setting the max_load_factor, calling rehash(), or calling reserve() can be very expensive operations (worst case O(n∗n)) because they can – and in realistic scenarios typically do – cause.
One use for the bucket interface is to allow experimentation with  functions: a poor will lead to large bucket_count()s for some key values.
That is, it will lead to many keys being mapped to the same  value.
Container adaptors are intended to be used only through their specialized interfaces.
In particular, the STL container adaptors do not offer direct access to their underlying container.
They do not offer iterators or subscripting.
The techniques used to create a container adaptor from a container are generally useful for nonintrusively adapting the interface of a class to the needs of its users.
It can be described by a partial implementation: template<typename T, typename  = deque<T>> class stack {.
That is, a  is an interface to a container of the type passed to it as a template argument.
A eliminates the non- operations on its container from the interface, and provides the conventional names: top(), push(), and pop().
In addition,  provides the usual comparison  (==, <, etc_0_) and a nonmember swap().
Elements are added to a  using push_back() on the underlying container.
Consequently, a cannot "overﬂow" as long as there is memory available on the machine for the container to acquire.
On the other hand, a  can underﬂow:.
By default, a  relies on the allocator from its underlying container.
If that's not enough, there are a handful of constructors for supplying another.
The declaration of priority_queue is much like the declaration of  with additions to deal with a comparison object and a couple of constructors initializing from a sequence: template<typename T, typename  = <T>, typename  = less<typename ::>> class priority_queue {.
The order in which elements with equal  come to the head of the  is not deﬁned.
Tw o elements are considered of equal  if neither has higher  than the other (31_0_2_0_2_0_1).
Keeping elements in order isn't free, but it needn't be expensive either.
One useful way of implementing a  is to use a tree structure to keep track of the relative positions of elements.
This gives an O(log()) cost of both push() and pop().
A  is almost certainly implemented using a heap (32_0_6_0_4).
Algorithms Sequences; Policy Arguments; Complexity.
Nonmodifying Sequence Algorithms.
Modifying Sequence Algorithms copy(); unique(); remove() and replace(); rotate(), random_shufﬂe(), and partition(); Permuta.
Sorting and Searching.
Min and Max.
Advice 32_0_1 Introduction This chapter presents the STL algorithms.
The STL consists of the iterator, container, algorithm, and function object parts of the standard library.
The rest of the STL is presented in Chapter 31 and Chapter 33.
They operate on sequences deﬁned by a pair of iterators (for inputs) or a single iterator (for outputs).
When copying, comparing, etc_0_, two sequences, the ﬁrst is represented by a pair of iterators, [b:e), but the second by just a single ptg10564057 928 STL Algorithms Chapter 32 iterator, b2, which is considered the start of a sequence holding sufﬁcient elements for the algorithm, for example, as many elements as the ﬁrst sequence: [b2:b2+(e−b)).
Some algorithms, such as sort(), require random-access iterators, whereas many, such as ﬁnd(), only read their elements in order so that they can make do with a forward iterator.
Many algorithms follow the usual convention of returning the end of a sequence to represent "not found" (4_0_5).
I don't mention that for each algorithm.
Algorithms, both the standard-library algorithms and the users' own ones, are important:.
Each names a speciﬁc operation, documents an interface, and speciﬁes semantics.
Each can be widely used and known by many programmers.
For correctness, maintainability, and performance, these can be immense advantages compared to "random code" with less well-speciﬁed functions and dependencies.
If you ﬁnd yourself writing a piece of code with several loops, local variables that don't seem to relate to each other, or complicated control structures, consider if the code could be simpliﬁed by making a part into a function/algorithm with a descriptive name, a well-deﬁned purpose, a well-deﬁned interface, and welldeﬁned dependencies.
Numerical algorithms in the style of the STL algorithms are presented in 40_0_6.
The iterator-based interfaces are a good, but not perfect, approximation to that ideal (33_0_1_0_1).
For example, an iterator-based interface does not directly represent the notion of a sequence, leading to the possibility of confusion and difﬁculties in detecting some range errors:.
However, the container versions are also less general than the versions that use iterators directly.
In particular, you cannot use the container sort() to sort half a container, and you cannot use the container copy() to write to an output stream.
A complementary approach is to deﬁne a "range" or "sequence" abstraction that allows us to iterators (24_0_4_0_4).
That is, there is no  class holding data – exactly as there is no class or Container class in the STL.
So, in the "container sort()" and "container copy()" examples, I called the template argument Cont (for "container"), but they will accept any sequence with a begin() and an end() that meets the rest of the requirements for the algorithm.
The standard-library containers mostly return iterators.
In particular, they do not return containers of results (except in a few rare examples, a pair).
One reason for that is that when the STL was designed, there was no direct support for move semantics.
So, there was no obvious and efﬁcient way to return a lot of data from an algorithm.
Some programmers used explicit indirection (_0_g_0_, a pointer, reference, or iterator) or some clever trickery.
Today, we can do better: template<typename Cont, typename Pred> <<Cont>∗>.
If the choice of standard-library  seems restrictive or insufﬁcient, extension with new  of STL  or new  is often a viable and superior alternative to just writing "random code" to work around the problem.
Note that whatever an STL algorithm returns, it cannot be an argument container.
The arguments to STL  are iterators (Chapter 33),  an algorithm has no knowledge of the data ptg10564057 930 STL Algorithms Chapter 32 structure those iterators point into.
Iterators exist primarily to isolate  from the data structure on which they operate,  vice versa.
A "plain" version that performs its action using conventional operations, such as <  ==.
A version that takes key operations as arguments For example: template<class Iter>.
This greatly increases the ﬂexibility of the standard library  its range of uses.
The usual two  of an algorithm can be implemented as two (overloaded) function templates or as a single function template with a default argument.
For example: template<typename Ran, typename  = less<<Ran>>> // use a default template argument.
The difference between having two functions  having one with a default argument can be observed by someone taking pointers to functions.
However, thinking of many of the variants of the standard  as simply "the version with the default predicate" roughly halves the number of template functions you need to remember.
In some cases, an argument could be interpreted as either a predicate or a value.
For example: bool (int); auto  = ﬁnd(b,,); In general, a compiler cannot disambiguate such examples,  programmers would get confused ev en in the cases where the compiler could disambiguate.
To simplify the task for the programmer, the _if sufﬁx is often used to indicate that an algorithm takes a predicate.
The reason to distinguish by using two names is to minimize ambiguities confusion.
Consider: using  = bool(∗)(int); ptg10564057 Section 32_0_3 Policy Arguments 931.
Unless otherwise stated, assume that a policy argument passed to an algorithm should not modify an element.
In particular, do not try to modify elements through predicates:.
If you are really sneaky, you could even modify the sequence (_0_g_0_, by inserting or removing an element using the name of a container being iterated over), so that the iteration would fail (probably in obscure ways).
To avoid accidents, you may pass arguments to predicates by const reference.
Similarly, a predicate should not carry state that changes the meaning of its operation implementation of an algorithm may copy a predicate,  we rarely want repeated uses of a predicate on the same value to give different results.
Some function objects passed to , such as random number generators, do carry mutable state.
Unless you are really sure that an algorithm doesn't copy, keep a function object argument's mutable state in another object  access it through a pointer or a reference.
In particular, do not sort or search containers of C-style strings using the  ==  < (32_0_6).
Most  are linear, O(n), for some n, which is usually the length of an input sequence.
All the rest As ever, these are asymptotic complexities,  you have to know what n measures to have an idea of the implications.
For example, if n<3, a quadratic algorithm may be the best choice.
For example, traversing a list can be much slower than ptg10564057 932 STL Algorithms Chapter 32 traversing a , even though the complexity in both cases is linear (O(n)).
Complexity measures are not a substitute for common sense  actual time measurements; they are one tool among many to ensure quality code.
Typically, user-supplied operations to an algorithm don't change the values of elements either; they tend to be predicates (which may not modify their arguments).
For example: ptg10564057 934 STL Algorithms Chapter 32.
No end is speciﬁed for the second sequence; that is, there is no last2.
Instead, it is assumed that there are at least as many elements in the second sequence as in the , and 2+(last−) is used as last2.
This technique is used throughout the standard library, where pairs of sequences are used for operations on pairs of elements.
We could implement mismatch() like this:.
If that second sequence is found, an iterator for the  matching element in the  sequence is returned.
As usual, the end of the sequence is used to represent "not found_0_" For example:.
Thus, search() is a useful algorithm for ﬁnding a substring generalized to all sequences.
Use ﬁnd() or binary_search() (32_0_6) to look for just a single element.
Instead, it produces an output that is a transformation of its input based on a user-supplied operation.
The copy() family of algorithms copy elements from one sequence into another.
The following sections list versions of copy() combined with other algorithms, such as replace_copy() (32_0_5_0_3).
Move all elements in [:) to [out:),.
To read a sequence, we need a  of iterators describing where to begin and where to end.
To write, we need only an iterator describing where to write to.
However, we must take care not to write beyond the end of the target.
One way to ensure that we don't do this is to use an inserter (33_0_2_0_2) to grow the target as needed.
For example: ptg10564057 Section 32_0_5_0_1.
We use copy() when the sequences do not overlap or if the end of the output sequence is in the input sequence.
Like other standard algorithms, unique() operates on iterators.
It does not know which container these iterators point into, so it cannot modify that container.
It can only modify the values of the elements.
This implies that unique() does not eliminate duplicates from its input sequence in the way we naively might expect.
Therefore, this does not eliminate duplicates in a :.
Algorithms that might have removed elements (but can't) generally come in two forms: the "plain" version that reorders elements in a way similar to unique() and a _copy version that produces a new  in a way similar to unique_copy().
To eliminate duplicates from a container, we must explicitly shrink it: template<class C>.
The remove() algorithm "removes" elements to the end of a : Remove elements with value  from [:e), Remove elements ∗ from [:e),.
Copy [:e) into [out:) in rev erse order The replace() algorithm assigns new  to selected elements: ptg10564057 Section 32_0_5_0_3 939 Replace elements ∗ in [:e) for which ∗==v with v2 Replace elements ∗ in [:e) for which f(∗) with v2 Copy [:e) to [out:), replacing elements for which ∗==v with v2 Copy [:e) to [out:), replacing elements for which f(∗,v) with v2 These algorithms cannot change the size of their input , so even remove() leaves the size of its input  unchanged.
Like unique(), it "removes" by moving elements to the left.
That is, after a shufﬂe, the elements are in a random order, where "random" is deﬁned by the distribution produced by the random number generator.
By default, random_shufﬂe() shufﬂes its  using a uniform distribution random number generator.
That is, it chooses a permutation of the elements of the  so that each ptg10564057 940 STL Algorithms Chapter 32 permutation has the same chances of being chosen.
If you want a different distribution or a better random number generator, you can supply one.
For a call random_shufﬂe(b,e,r), the generator is.
Make [b:e) the previous permutation, using f for comparison Is there a permutation of [b2:b2+(e−b)) that compares equal to [b,e).
Is there a permutation of [b2:b2+(e−b)) that compares equal to [b,e), using f(∗,∗) as the element comparison.
Permutations are used to generate combinations of elements of a.
For example, the permutations of abc are acb, bac, bca, cab, and cba.
The next permutation is found by assuming that the set of all permutations is lexicographically sorted.
If such a permutation exists, next_permutation() returns true; otherwise, it transforms the into the smallest permutation, that is, the ascendingly sorted one (abc in the example), and returns.
The ﬁll() family of algorithms provide ways of assigning to and initializing elements of a :.
For example, using the random number generators Randint and Urand from 40_0_7:.
The generate() and ﬁll() functions assign rather than initialize.
If you need to manipulate raw ptg10564057 942 STL Algorithms Chapter 32 storage, say, to turn a region of memory into objects of well-deﬁned type and state, you use one of the uninitialized_ versions (presented in <memory>).
Uninitialized sequences should only occur at the lowest level of programming, usually inside.
A swap() algorithm exchanges the  of two objects:.
The pointer  had better point to an  with at least _0_siz e() elements.
The swap() algorithm is possibly the simplest and arguably the most crucial algorithm in the standard library.
It is used as part of the implementaton of many of the most widely used algorithms.
Its implementation is used as an example in 7_0_7_0_2 and the standard-library version is presented in 35_0_5_0_2.
Comparison is by default done using the < , and equivalence of values  and  is determined by _0_(<)&&_0_(<) rather than requiring  ==.
Sort [:e), using f(∗,∗q) as the sorting criterion In addition to the "plain sort" there are many variants: ptg10564057 Section 32_0_6 Sorting and Searching 943 Sort [:e) maintaining order of equal elements.
Sort enough of [:e) to get [:m) into order;.
The sort() algorithms require random-access iterators (33_0_1_0_2).
Despite its name, is_sorted_until() returns an iterator, rather than  bool.
The standard list (31_0_3) does not provide random-access iterators, so lists should be sorted using the speciﬁc list operations (31_0_4_0_2) or by copying their elements into  , sorting that , and then copying the elements back into the list: template<typename List>.
The basic sort() is efﬁcient (on average N∗log(N)).
If  stable sort is required, stable_sor t() should be used, that is, an N∗log(N)∗log(N) algorithm that improves tow ard N∗log(N) when the system has sufﬁcient extra memory.
The get_temporar y_buffer() function may be used for getting such extra memory (34_0_6).
The relative order of elements that compare equal is preserved by stable_sor t() but not by sort().
Sometimes, only the ﬁrst elements of  sorted sequence  needed.
In that case, it makes sense to sort the sequence only as far as is needed to get the ﬁrst part in order, that is,  partial sort.
The ptg10564057 944 STL Algorithms Chapter 32 plain partial_sort(,m,e) algorithms put the elements in the range [:m) in order.
The partial_sort_copy() algorithms produce N elements, where N is the lower of the number of elements in the output sequence and the number of elements in the input sequence.
We need to specify both the start and the end of the result sequence because that's what determines how many elements we need to sort.
For example: void f(const <Book>& sales) // ﬁnd the top ten books.
Because the target of partial_sort_copy() must be  random-access iterator, we cannot sort directly to.
If the number of elements desired to be sorted by  partial_sort() is small compared to the total number of elements, these algorithms can be signiﬁcatly faster than  complete sort().
Then, their complexity approaches O(N) compared to sort()'s O(N∗log(N)).
The nth_element() algorithm sorts only as far as is necessary to get the Nth element to its proper place with no element comparing less than the Nth element placed after it in the sequence.
For example: <int> ;.
Replacing nth_element with partial_sort in that example (and using the same seed for the random number generator to get the same sequence), I got: : 995 1 2 3 3 3 6 7 7 8 8 8 8 9 10 10 11 11 15 15 17 18 18 19 20 21 21 21 22 22 23 The nth_element() algorithm is particularly useful for people – such as economists, sociologists, and teachers – who need to look for medians, percentiles, etc.
Sorting C-style strings requires an explicit sorting criterion.
The reason is that C-style strings simply pointers with  set of conventions for their use, so < on pointers compares machine addresses rather than character sequences.
For example: ptg10564057 Section 32_0_6 Sorting and Searching 945.
However, to sort C-style strings by string value rather than by address we need  proper sort predicate.
For example: sort(, [](const char∗ , const char∗ ){ return strcmp(,)<0; }); The standard-library function strcmp() is described in 43_0_4.
Note that I did not have to supply  == to sort C-style strings.
To simplify the user interface, the standard library uses _0_(<>||<) rather than == to compare elements (31_0_2_0_2_0_2).
Once  sequence is sorted, however, we can use  binary search to determine whether  value is in  sequence.
For example: ptg10564057 946 STL Algorithms Chapter 32.
A binary_search() returns  bool indicating whether  value is present.
As with ﬁnd(), we often also want to know where the elements with that value  in that sequence.
However, there can be many elements with  given value in  sequence, and we often need to ﬁnd either the ﬁrst or all such elements.
Consequently, algorithms  provided for ﬁnding  range of equal elements, equal_range(), and algorithms for ﬁnding the lower_bound() and upper_bound() of that range.
If lower_bound(ﬁrst,last,k) doesn't ﬁnd k, it returns an iterator to the ﬁrst  with  key greater than k, or last if no such greater  exists.
This way of reporting failure is also used by upper_bound() and equal_range().
This means that we can use these algorithms to determine where to insert  new  into  sorted sequence so that the sequence remains sorted: just insert before the second of the returned pair.
Curiously enough, the binary search algorithms do not require random-access iterators:  forward iterator sufﬁces.
The merge algorithms combine two ordered (sorted) sequences into one: into [out,out+), using f as the comparison into  sorted sequence [b:e), using f as the comparison The merge() algorithm can take different kinds of sequences and elements of different types.
For example: ptg10564057 Section 32_0_6_0_2.
The output is: 0_0_5, 1, 1_0_5, 2, 2, 2_0_5, 3, 4, 32_0_6_0_3 Set Algorithms These algorithms treat  sequence as  set of elements and provide the basic set operations.
The input sequences are supposed to be sorted and the output sequences are also sorted.
Are all elements of [b:e) also in [b2:e2), using f for comparison.
This little test produces: ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ ,_0_/abcdefgimnopqrstuvxyz ceqrtvwxzplus_plusplus_plusplus_plusplus_plusplus_plusplus_plusplus_plusplus_plusplus_plusplus_plusplus_plus ceqrtvwxz 32_0_6_0_4 Heaps A heap is a compact data structure that keeps the  with the highest value ﬁrst.
Think of a heap as a representation of a binary tree.
The heap algorithms allow a programmer to treat a random-access sequence as a heap: Make [b:e) ready to be used as a heap.
The largest  is extracted by reading through b (_0_g_0_, =∗b) and then.
The way to understand the changes to  is that a user reads only [0] and writes only [] where  is the index of the current  of the heap.
The heap removes an  (always [0]) by swapping it with [].
The point of a heap is to provide fast addition of elements and fast access to the  with the highest value.
The main use of heaps is to implement priority queues.
A lexicographical compare is the rule we use to order words in dictionaries.
That is, a string compares as a sequence of characters.
For example: ptg10564057 950 STL Algorithms Chapter 32.
Value comparisons are useful in many contexts: =min(a,) is the smaller of a and =min(a,,f).
For example: int  = 7; int  = 9; ptg10564057 Section 32_0_7 Min and Max 951.
With the ACSII character set on my machine, this little test produces: ==a ==_ 32_0_8 Advice [1] An STL algorithm operates on one or more sequences; 32_0_2.
Iterator Model Iterator Categories; Iterator Traits; Iterator Operations.
Iterator Adaptors Reverse Iterators; Insert Iterators; Move Iterator.
Range Access Functions.
Function Adaptors bind(); mem_fn(); function.
Advice 33_0_1 Introduction This chapter presents the STL iterators and utilities, notably standard-library function objects STL consists of the iterator, container, algorithm, and function object parts of the standard library.
Iterators are the glue that ties standard-library algorithms to their data.
Conversely, you can say that iterators are the mechanism used to minimize an algorithm' dependence on the data structures on which it operates: ptg10564057 954 STL Iterators Chapter 33.
Iterators vector map list _0__0_.
A sequence is deﬁned by a pair of iterators deﬁning a half-open range [:end): elements: end iterators: That is,  points to the   of the sequence, and end points to the one-beyond-the-last of the sequence.
Never read from or write to ∗end.
Note that the empty sequence has ==end; that is, [:) is the empty sequence for any iterator.
To read a sequence, an algorithm usually takes a pair of iterators (,e) and iterates using plus_plus until the end is reached:.
Algorithms that search for something in a sequence usually return the end of the sequence to indicate "not found"; for example: auto  = ﬁnd(v_0_(),v_0_end(),x);.
In that case, it is the programmer's responsibility not to write beyond the end of that sequence.
For example: template<typename Iter>.
Some standard-library implementations range check – that is, throw an exception for that last call of forward() – but you can't rely on that for portable code: many implementations don't check.
For a simple  safe alternative  an insert iterator (33_0_2_0_2).
Input iterator: We can iterate forward  plus_plus  read each  (repeatedly)  ∗.
We can compare input iterators  ==  _0_=.
This is the kind of iterator that istream offers; see 38_0_5.
Output iterator: We can iterate forward  plus_plus  write an  once only  ∗.
This is the kind of iterator that ostream offers; see 38_0_5.
Forward iterator: We can iterate forward repeatedly  plus_plus  read  write (unless the elements are const) elements repeatedly  ∗.
If a forward iterator points to a class object, we can  −> to refer to a member.
We can compare forward iterators  == _0_=.
This is the kind of iterator forward_list offers (31_0_4).
Bidirectional iterator: We can iterate forward ( plus_plus)  backward ( −−)  read write (unless the elements are const) elements repeatedly  ∗.
If a bidirectional iterator points to a class object, we can  −> to refer to a member.
We can compare bidirectional iterators  ==  _0_=.
This is the kind of iterator that list, map,  set offer (31_0_4).
Random-access iterator: We can iterate forward ( plus_plus  +=)  backward ( − −=)  read  write (unless the elements are const) elements repeatedly  ∗  [].
If a random-access iterator points to a class object, we can  −> to refer to a member.
We can subscript a random-access iterator  [], add an integer  +,  subtract an integer −.
We can ﬁnd the distance between two random-access iterators to the same sequence by subtracting one from the other.
We can compare random-access iterators ==, _0_=, <, <=, >,  >=.
This is the kind of iterator that  offers (31_0_4).
Logically, these iterators are organized in a hierarchy (iso_0_24_0_2): ptg10564057 956 STL Iterators Chapter 33 Iterator ∗, plus_plus Input Iterator ==, _0_=, single read, −> Output Iterator single write Forward Iterator repeated read  write Bidirectional Iterator −− Random-access Iterator [], +, +=, −, −=, <, <=, >, >= The iterator categories are concepts (24_0_3) rather  classes, so this hierarchy is not a class hierarchy implemented  derivation.
If you need to do something advanced with iterator categories,  iterator_traits (directly  indirectly).
Category for random-access iterators; derived from bidirectional_iterator_tag; provided for , deque, array, built-in arrays,  string ptg10564057 Section 33_0_1_0_3 Iterator Traits 957 The iterator tags are types used to select among algorithms based on the type of an iterator.
For example, a random-access iterator can go directly to an element: template<typename Iter>.
Typically, advance() / advance_helper() will be inlined to ensure that no run-time overhead is introduced by this tag dispatch technique.
Variants of this technique are pervasive in the STL.
The key properties of an iterator are described by the aliases in : template<typename Iter>.
This is an error waiting to happen.
Calling this read() with a  argument would be an error.
The compiler would catch it, but the error messages might be voluminous  obscure.
Instead, we can write: template<typename Iter>.
The idea is that to ﬁnd a property of an iterator, you look in its  (28_0_2_0_4), rather than at the iterator itself.
To avoid directly referring to the , which after all is just an implementation detail, we can deﬁne an alias.
For example: template<typename > <> = typename std::<>::; template<typename > <> = typename std::<>::; So, if we want to know the type of the difference between two iterators (pointing to the same sequence), we have some choices:.
The iterator template simply bundles the key properties of an iterator into a struct for the convenience of iterator implementers  provides a few defaults: ptg10564057 Section 33_0_1_0_3 Iterator Traits 959 template<typename Cat, typename T, typename  = ptrdiff_t, typename  = T∗, typename  = T&>.
Thus, for more complicated iterators, plus_plusp is likely to be more efﬁcient than pplus_plus.
The following operations work for every iterator for which they can be implemented, but they may work more efﬁciently for random-access iterators (see 33_0_1_0_2): ptg10564057 960 STL Iterators Chapter 33 +=n;  must be at least an input iterator.
In each case, if  is not a random-access iterator, the algorithm will take n steps.
Iterators for iostreams are described in 38_0_5.
If the sequence allows bidirectional access, we can also traverse the sequence in reverse order, from e to b.
An iterator that does that is called a reverse_iterator.
A reverse_iterator iterates from the end of the sequence deﬁned by its underlying iterator to the beginning of that sequence.
To get a half-open sequence, we must consider b−1 as one past the end and e−1 as the start of the sequence: [e−1,b−1).
Thus, the fundamental relation between a reverse iterator and its corresponding iterator is &∗(reverse_iterator())==&∗(−1).
In particular, if v is a vector, v_0_rbegin() points to its last element, v[v_0_siz e()−1].
Consider: A B C This sequence can be viewed like this using a reverse_iterator: ptg10564057 Section 33_0_2_0_1 Reverse Iterator 961 C B A The deﬁnition of reverse_iterator looks something like this: template<typename Iter> class reverse_iterator : public iterator<Iterator_category<Iter>, Value_type<Iter>, Difference_type<Iter>, Pointer<Iter>, <Iter>> {.
In particular, if Iter is a random-access , its <Iter> has [], +, and <.
For example: ptg10564057 962 STL Iterators Chapter 33.
I use next() to move the iterator because (like []) + wouldn' work for a bidirectional iterator, such as <char>::iterator.
Reverse iterators allow us to use algorithms in a way that views a sequence in the reverse order.
For example, to ﬁnd the last occurrence of an element in a sequence, we can apply ﬁnd() to its reverse sequence: auto  = ﬁnd(v_0_(),v_0_rend(),val); // last occurrence.
So, to get an iterator pointing to the same element as the reverse iterator , I hav e to return _0_base()−1.
Howev er, my container may be a  that does not support − for its iterators, so I use prev() instead.
A rev erse iterator is a perfectly ordinary iterator, so I could write the loop explicitly:.
As for the earlier deﬁnitions of ﬁnd_last(), this version requires at least a bidirectional iterator.
This implies the possibility of overﬂow and consequent memory corruption.
If vi has fewer than 200 elements, we are in trouble.
In <iterator>, the standard library provides a solution in the form of an inserter: when written to, an inserter inserts a new  into a sequence rather than overwriting an existing.
So, a container grows by one  each time a value is written to it through an insert iterator.
Inserters are as simple and efﬁcient as they are useful.
There are three insert iterators:.
An inserter is usually constructed by a call to a helper function:.
The iterator passed to inserter() must be an iterator into the container.
For a sequence container, that implies that it must be a bidirectional iterator (so that you can insert before it).
For example, you can' use inserter() to make an iterator to insert into a forward_list.
For an associative container, where that iterator is only used as a hint for where to insert, a forward iterator (e_0_g_0_, as provided by an unordered_set) can be acceptable.
An inserter is an output iterator: insert_iterator  {c,q}; Inserter for container c pointing to ∗q; q must point into c insert_iterator  {q}; Copy constructor:  is a copy of q =q Copy assignment:  is a copy of q Move assignment:  points to what q pointed to ptg10564057 964 STL Iterators Chapter 33 plus_plusp Make  point to the next ; the value is 's new value Make  point to the next ; the value is 's old value ∗=x Insert x before ∗=x Insert x before , then increment The front_inser  and back_inser  differ in that their constructors don' require an iterator.
For example: <string> v; back_inser <v> ; You cannot read through an inserter.
We usually make a move iterator from another iterator using a helper function: Move Iterator Construction Function =make_move_iterator() is a move_iterator pointing to the same  as ; must be an input iterator A move iterator has the same operations as the iterator from which it is made.
For example, we can simply returns an rvalue reference (7_0_7_0_2) to the  pointed to: std::move(q).
In <iterator>, the standard library provides a nonmember begin() and end() functions for containers: =begin(c) =end(c) These functions are very simple: ptg10564057 Section 33_0_3 Range Access Functions 965 template<typename C> auto begin(C& c) −> decltype(c_0_begin()); template<typename C> auto begin(const C& c) −> decltype(c_0_begin());.
Common uses are comparison criteria, predicates (functions returning bool), and arithmetic operations.
In <functional>, the standard library supplies a few common function objects: =<T>(,y) (,y) means ==y   and y are of type T =<T>(,y).
Note that  and  always evaluate both their arguments (&& and || do not).
Given a function and a set of arguments, bind() produces a function object that can be called with "the remaining" arguments, if any, of the function.
For example: double (double); auto 2 = bind(,2);.
To deal with that, the standard library provides yet another pair of adaptors: =ref(t) is a reference_wrapper for T& t; noexcept.
This ref() is needed to pass references as arguments to threads because thread constructors are variadic templates (42_0_2_0_2).
So far, I either used the result of bind() immediately or assigned it to a variable declared using auto.
This saves me the bother of specifying the return type of a call of bind().
That can be useful because the return type of bind() varies with the type of function to be called and the argument values stored.
In particular, the returned function object is larger  it has to hold values of bound parameters.
However, we sometimes want to be speciﬁc about the types of the arguments required and the type of result returned.
If so, we can specify them for a function (33_0_5_0_3).
In that, bind() resembles a lambda.
If we want to assign the result of bind() to a variable with a speciﬁc type, we can use the standard-library type.
A  is speciﬁed with a speciﬁc return type and a speciﬁc argument type.
If _0_()==typeid(F),  points to the contained object, otherwise, ==; noexcept == Is  empty.
The  functions are provided for the rare cases where someone wants to examine a , rather than simply call it as usually intended.
The standard-library  is a type that can hold any object you can invoke using the call operator () (2_0_2_0_1, 3_0_4_0_3, 11_0_4, 19_0_2_0_2).
That is, an object of type  is a  object.
For example: int round(double x) { return <double>(ﬂoor(x+0_0_5)); }.
Obviously, functions are useful for callbacks, for passing operations as arguments, etc.
When bits are shifted, a logical (rather than cyclic) shift is used.
That implies that some bits "fall off the end" and that some positions get the default value 0.
Note that because size_t is an unsigned type, it is not possible to shift by a negative number.
It does, however, imply that <<−1 shifts by a very large positive value, thus leaving every bit of the   with the value 0.
Your compiler should warn against this.
A  also supports common operations such as (), ==, I/O, etc_0_: C, Tr, and A have defaults for <C,Tr,A> =_0_to_ulong() is the unsigned long corresponding to.
Does any bit in  have the value 1.
Does no bit in  have the value 1.
To avoid nonobvious conversions, named operations were preferred over conversion operators.
If the value of the  has so many signiﬁcant bits that it cannot be represented as an unsigned long, to_ulong() throws overﬂow_error; so does to_ullong() if its  argument doesn't ﬁt.
Fortunately, the template arguments for the  returned by  are defaulted.
This prints the bits represented as 1 and 0 from left to right, with the most signiﬁcant bit leftmost, so that argument 123 would give the output 00000000000000000000000001111011 00000000000000000000000001111011 00000000000000000000000001111011 00000000000000000000000001111011 For this example, it is simpler to directly use the  output operator:.
As in a <T>, elements of a <bool> with higher indices have higher addresses: 1 1 1 1 0 1 1 1 0 1 9 8 7 6 5 4 3 2 1 0 <bool>: position: This is exactly the opposite of the layout in a.
Also, there is no direct support for converting integers and strings to and from a <bool>.
Use <bool> as you would any other <T>, but expect operations on a single bit to be less efﬁcient than the equivalent operations on a <>.
Also, it is impossible in Cplus_plus to completely faithfully mimic the behavior of a (built-in) reference with a proxy, so don't try to be subtle about rvalue/lvalue distinctions when using a <bool>.
A pair (34_0_2_0_4_0_1) holds two values.
A tuple (34_0_2_0_4) holds zero or more values.
We use pair when it is useful to know (statically) that we have exactly two values.
With tuple, we always have to deal with all possible numbers of values.
Similarly, copy or move operations exist for a  if the corresponding operations on its elements do.
The elements  and  are members that we can directly read and write.
However, a pointer does not indicate who (if anyone) owns the objects.
That is, looking just at a pointer, we hav e no idea who is supposed to delete the object pointed to, or how, or if at all.
In <memory>, we ﬁnd "smart pointers" to express ownership:.
A unique_ptr owns the object to which it holds a pointer.
That is, it is the unique_ptr's obligation to destroy the object pointed to (if any) by its contained pointer.
A unique_ptr cannot be copied (has no copy constructor or copy assignment).
A unique_ptr stores a pointer and deletes the object pointed to (if any) using the associated deleter (if any) when it is itself destroyed (such as when a thread  control leaves the unique_ptr's scope; 17_0_2_0_2).
Passing ownership  dynamically allocated memory to a function.
Returning dynamically allocated memory from a function.
Storing pointers in containers Think  unique_ptr as being represented by a simple pointer ("the contained pointer") or (if it has a deleter) as a   pointers: unique_ptr<T> unique_ptr<T,D> up1: up2: object object deleter When a unique_ptr is destroyed, its deleter is called to destroy the owned object.
The deleter represents what it means to destroy an object.
A deleter for a memory pool should return the object to the memory pool and destroy it or not, depending on how that pool is deﬁned.
The default ("no deleter") version of unique_ptr uses delete.
It doesn' even store the default deleter.
It can be a specialization or rely on the empty-base optimization (28_0_5).
This way unique_ptr supports general resource management (5_0_2).
The contained  is not directly accessible to users.
Exchange  and 2's values; noexcept ==2 _0_==2.
Note:  does not offer a copy constructor or copy assignment.
Had it done so, the meaning of "ownership" would have been very hard to deﬁne and/or use.
If you feel the need for copies, consider using a shared_ptr (34_0_3_0_2).
It is possible to have a  for a built-in array.
The style illustrated by f() is explicit about ownership (and the use of  is typically motivated by ownership issues).
See also the discussion of the use of non-const references in 7_0_7_0_1.
On balance, a notation f() that modiﬁes  is more error-prone than a =f() notation that does not.
This, too, is unlikely to be signiﬁcant in most programs, so the choice between the styles of f() and f2() has to be made on reasoning about code quality.
Here is a simple example of a deleter used to provide guaranteed release of data obtained from a C program fragment using malloc() (43_0_5):.
It is used where two pieces of code need access to some data but neither has exclusive ownership (in the sense of being responsible for destroying the object).
A shared_ptr is a kind of counted  where the object pointed to is deleted when the use count goes to zero.
Think of a shared  as a structure with two pointers: one to the object and one to the use count: sp1: sp2: use count deleter object The deleter is what is used to delete the shared object when the use count goes to zero.
The default deleter is the usual delete (invoke the destructor, if any, and deallocate free store).
For example, consider a Node in a general graph used by an algorithm that adds and removes both nodes and connections between nodes (edges).
Obviously, to avoid resource leaks, a Node must be deleted if and only if no other node refers to it.
We could try: ptg10564057 Section 34_0_3_0_2 shared_ptr 991.
Given that, answering questions such as "How many nodes points to this node_0_" is very hard and requires much added "housekeeping" code.
We could plug in a garbage collector (34_0_5), but that could have neg ative performance implications if the graph was only a small part of a large application data space.
Worse, if the container contained non-memory resources, such as thread handles, ﬁle handles, locks, etc_0_, even a garbage collector would leak resources.
Here, Node's destructor (the implicitly generated destructor will do ﬁne) deletes its edges.
That is, the destructor for each edges[] is invoked, and the Node pointed to (if any) is deleted if edges[] was the last pointer to it.
Don't use a  just to pass a pointer from one owner to another; that's what is for, and  does it better and more cheaply.
If you have been using counted pointers as return values from factory functions (21_0_2_0_4) and the like, consider upgrading to  rather than.
Do not thoughtlessly replace pointers with shared_ptrs in an attempt to prevent memory leaks; shared_ptrs are not a panacea nor are they without costs:.
A circular linked structure of shared_ptrs can cause a resource leak.
You need some logical complication to break the circle, for example, use a weak_ptr (34_0_3_0_3).
Objects with shared ownership tend to stay "live" for longer than scoped objects (thus causing higher average resource usage).
Shared pointers in a multi-threaded environment can be expensive (because of the need to prevent data races on the use count).
A destructor for a shared object does not execute at a predictable time, so the algorithms/logic for the update of any shared object are easier to get wrong than for an object that's not shared.
For example, which locks are set at the time of the destructor's execution.
Which ﬁles are open.
In general, which objects are "live" and in appropriate states at the (unpredictable) point of execution.
If a single (last) node keeps a large data structure alive, the cascade of destructor calls triggered by its deletion can cause a signiﬁcant "garbage collection delay_0_" That can be detrimental to real-time response.
A  represents shared ownership and can be very useful, even essential, but shared ownership isn't my ideal, and it always carries a cost (independently of how you represent the sharing).
It is better (simpler) if an object has a deﬁnite owner and a deﬁnite, predictable life span.
When there is a choice: ptg10564057 992 Memory and Resources Chapter 34.
Prefer ordinary scoped objects to objects on the heap owned by a.
The  provides a fairly conventional set of operations: is the contained pointer;  is the use count sp {} Default constructor: =nullptr; =0; noexcept sp {}.
Like _0_reset() but with the deleter d Like _0_reset() but with the deleter d and the allocator a =_0_; noexcept =∗ =∗_0_; noexcept =−>m =_0_−>m; noexcept =_0_use_count() _0_unique() =_0_owner_before(pp) pp is a  or a weak_ptr Exchange 's and 2's values; noexcept In addition, the standard library provides a few helper functions: =make_shared(args) is a <T> for an object of type T constructed from the arguments args; allocated using new =allocate_shared(a,args) is a <T> for an object of type T constructed from the arguments args; allocated using allocator a ptg10564057 Section 34_0_3_0_2 993 ==2 _0_==2_0_;  or 2 may be the nullptr <2 <T∗>(_0_,2_0_);  or 2 may be the nullptr _0_=2 >2 2< <=2.
If  has a deleter of type D, ∗ is 's deleter; otherwise, ==nullptr; noexcept os<< Write  to ostream os For example:.
Note that unlike unique_ptr::(), 's deleter is not a member function.
To access the object, a weak_ptr can be converted to a  using the member function lock().
A weak_ptr allows access to an object, owned by someone else, that.
You need access to (only) if it exists.
May get deleted (by someone else) at any time.
In particular, we use weak pointers to break loops in data structures managed using shared_ptrs.
Think of a weak_ptr as a structure with two pointers: one to the (potentially shared) object and one to the use count structure of that object's shared_ptrs: ptg10564057 994 Memory and Resources Chapter 34 1: 2: wp: use count deleter weak use count Object The "weak use count" is needed to keep the use count structure alive because there may be weak_ptrs after the last  for an object (and the object) is destroyed.
Destructor: no effect on ∗; −−wuc =pp Copy: decrease wuc and set  to pp: weak_ptr(pp)_0_swap(); pp is a weak_ptr or a ; noexcept.
There is no standard way of saying which alternative you prefer.
Consider that a quality-of-implementation issue  a programming environment issue.
Doing so simpliﬁes programming and eliminates many kinds of errors.
However, in relatively rare cases, such as when writing memory allocators, implementing containers, and dealing directly with hardware, direct use of uninitialized memory, also known as raw memory, is essential.
In addition to the standard allocator, the <memory> header provides the ﬁll∗ family of functions for dealing with uninitialized memory (32_0_5_0_6).
They share the dangerous and occasionally essential property of using a type name T to refer to space sufﬁcient to hold an object of type T rather than to a properly constructed object of type T.
These functions are intended primarily for implementers of containers and algorithms.
For example, reserve() and resize() are most easily implemented using these functions (13_0_6).
Often, such temporary space is best allocated in one operation but not initialized until a particular location is actually needed.
Consequently, the library provides a  of functions for allocating and deallocating uninitialized space: template<typename T> <T∗,ptrdiff_t> get_temporar y_buffer(ptrdiff_t); // allocate, don't initialize template<typename T> void return_temporary_buffer(T∗); // deallocate, don't destroy A get_temporar y_buffer<X>(n) operation tries to allocate space for n  more objects of type X.
If it succeeds in allocating some memory, it returns a pointer to the ﬁrst uninitialized space and the number of objects of type X that will ﬁt into that space; otherwise, the  value of the  is zero.
The idea is that a system may keep space ready for fast allocation so that requesting space for n objects of a given size may yield space for more than n.
It may also yield less, however, so one way of using get_temporar y_buffer() is to optimistically ask for a lot and then use what happens to be available.
A buffer obtained by get_temporar y_buffer() must be freed for other use by a call of return_temporary_buffer().
Just as get_temporar y_buffer() allocates without constructing, return_temporary_buffer() frees without destroying.
Because get_temporar y_buffer() is low-level and likely to be optimized for managing temporary buffers, it should not be used as an alternative to new  allocator::allocate() for obtaining longer-term storage.
That is, the algorithms use assignment rather than copy construction for writing.
Consequently, we cannot use uninitialized memory as the immediate target of an algorithm.
This can be unfortunate because assignment can be signiﬁcantly more expensive than initialization, and to initialize immediately before overwriting is a waste.
The solution is to use a raw_storage_iterator from <memory> that initializes instead of assigns: ptg10564057 1006 Memory and Resources Chapter 34 template<typename Out, typename T> class raw_storage_iterator : public <output_iterator_tag,void,void,void,void> {.
This is a somewhat contrived example because I see nothing wrong in allocating default initialized storage for the strings and then assigning the test strings.
Note that there are  ==  _0_= operators for , so don' try to use it to write to a [b:e) range.
For example iota(b,e,0) (40_0_6) will not work if b and e are raw_storage_iterators.
Don' mess with uninitialized memory unless you absolutely have to.
Time duration; time_point; Clocks; Time Traits.
Compile-Time Rational Arithmetic.
Type Functions Type Traits; Type Generators.
Minor Utilities move() and forward(); swap(); Relational Operators; Comparing and Hashing type_info.
Advice 35_0_1 Introduction The standard library provides many "utility components" that are so widely useful that they are not easily classiﬁed as part of some major standard-library component.
All chrono facilities are in the std::chrono (sub)namespace, so we have to either explicitly qualify with chrono::  add a using-directive: using namespace std::chrono; We often want to time things  to do things that depend on timing.
For example, the standardlibrary mutexes and locks provide the option for a thread to wait for a period of time (a duration) to wait until a given point in time (a time_point).
In fact, the time facilities originated with the stringent needs of high-energy physics.
It turns out that "time" is far more complicated to deal with than we usually think.
For example, we have leap seconds, clocks that are not accurate and must be adjusted (possibly causing time as reported by a clock to go backward), clocks of differing precision, etc.
Furthermore, language facilities for dealing with short time spans (e_0_g_0_, nanoseconds) must not themselves take signiﬁcant time.
Consequently, the chrono facilities are not simple, but many uses of those facilities can be very simple.
The C-style time utilities can be found in 43_0_6.
Copy constructor:  gets the same value as 2; 2 must be convertible to Rep without narrowing; constexpr =2 gets the same value as 2; 2 must be representable as a Rep =_0_() is the number of clock ticks in ; constexpr We can deﬁne a  with a speciﬁc  value.
For example: ptg10564057 Section 35_0_2_0_1 1011.
Allowing that would be like allowing the addition of 5 of an unknown SI unit to a length in meters.
Comparison is done in the common_type of  and 2; constexpr _0_=2 <2 Comparison is done in the common_type of  and 2; constexpr <=2 >2 Comparison is done in the common_type of  and 2; constexpr.
Convert   to  type D; implicit conversions are used for the representation ; constexpr The standard library provides some convenience aliases using the SI units from <> (35_0_3): ptg10564057 Section 35_0_2_0_1 1013.
The precision of a  is implementation-dependent.
In <chrono>, the standard library provides basic interfaces for clocks.
Class  represents "wall time" as obtained from a system's real-time : class  {.
All data and function members are static.
We don' explicitly deal with  objects.
Instead, we use  types: is_steady Is this  type steady.
We can determine the basic properties of the clocks like this:.
When I ran it on one of my systems, this produced: −9223372036854775808,  9223372036854775807, not steady Different systems and different clocks can give different results.
The conversion rules for  and  depend on whether their representation is ﬂoating-point (so that rounding is acceptable) or : template<typename Rep> struct  : <Rep> { }; A few standard values are provided:.
This implies that <R1,P1,R2,P2>:: can hold any value from <R1,R2> and <R2,P2> without truncation error.
Howev er, ﬂoating-point durations may have round-off errors.
The standard library uses  to provide a compile-time representation of time  and time points (35_0_2): template<intmax_t N, intmax_t  = 1>.
The basic idea is to encode the numerator and denominator of a rational number as (value) template arguments.
The denominator must always be nonzero.
In <chrono>, we ﬁnd the conventional notation (e_0_g_0_, + and ∗) for rational arithmetic for time (35_0_2).
Similarly, to help express unit values, the standard library provides common SI magnitude names: using yocto = <1,1000000000000000000000000>; // conditionally supported using zepto = <1,1000000000000000000000>; // conditionally supported using atto = <1,1000000000000000000>;.
These  functions are primarily used at compile time to support simple, and not so simple, metaprogramming.
Their names are mostly self-explanatory.
The primary  predicates test fundamental properties of a : is_void<X> Is X void.
A type trait returns a value that is used as a Boolean.
To access that value, use the sufﬁx ::value.
For example: template<typename T>.
Ideally, use a library that provides such functions for all standard library type traits.
Some type functions inquire about a combination of fundamental properties: is_reference<X> Is x a reference (lvalue or rvalue reference).
These composite type predicates simply offer notational convenience.
For example, is_reference<X> is true if X is either an lvalue reference or an rvalue reference.
For example: template<typename > class Cont {.
This optimization may be unnecessary, though, because uninitialized_copy() is likely to already have been optimized in this way.
The type property predicates don't do access checking depending on where they are used.
Instead, they consistently give the result you would expect for a use outside members and friends.
For example: class  { public:.
Both () and () will write 00 to report that an  is neither destructible nor copy assignable.
Also, if you want to eliminate an operation,  =delete (17_0_6_0_4) rather than relying as private.
Like sizeof(), a property query returns a numeric  related to a type argument: =alignment_of<> =rank<> If  is an array,  is the number of dimensions; otherwise ==0 =extent<,N> If  is an array,  is the number of elements in the Nth dimension; otherwise ==0 =extent<> =extent<,0> For example: template<typename >.
The type relations are predicated on two types: is_same<,Y> Is  the same type as Y.
For example: template<typename >.
To access that type,  the sufﬁx ::type.
For example: template<typename K, typename V>.
Ideally,  a support library that provides such aliases systematically for the standard-library type transformers.
The type functions for adding and removing references are important for when writing templates that should work with an argument that may be reference or not.
For example: ptg10564057 1024 Utilities Chapter 35 template<typename >.
We can make a pointer type pointing to an arbitrary type, or ﬁnd the pointed-to type: remove_pointer<X> If X is a pointer type, the pointed-to type; otherwise X add_pointer<X> remove_reference<X>::type∗ For example: ptg10564057 Section 35_0_4_0_2 Type Generators 1025 template<typename >.
It is often useful to ﬁnd a  that can be used for operations on more than one , such as the result of an addition of two values of related but different types.
The  function  ﬁnds such common types.
A  is the common  of itself (obviously): ptg10564057 1026 Utilities Chapter 35 template<typename _0__0__0_> struct ;.
Curiously enough, the same does not apply to nonmember functions.
Returns an rvalue for : typename add_r <>::; never use a return value of The ()  function is unusual in the standard library because it is actually a function (without users needing to wrap it).
It returns a value that must never be used.
The intent is to use <X> as a  where the  of a variable of  X is needed.
For example: template<typename , siz e_t >.
See also the deﬁnition of.
They don't ﬁt into a larger grouping.
In <utility>, we ﬁnd some of the most useful small functions: 2=forward() 2 is an rvalue;  may not be an lvalue; noexcept.
A move() is used to tell the compiler that an object will not be used anymore in a context, so that its value can be moved and an empty object left behind.
The simplest example is the implementation of swap() (35_0_5_0_2).
A forward() produces an rvalue from an rvalue only:.
The assert is there for programmer who are too clever for their own good and calls the second version with an explicit template argument and an lvalue.
The standard-library <T>() (34_0_3_0_2) is a good example.
Use move() when the intent is to "steal the representation" of an object with a move operation, and use forward() for forwarding.
Thus, forward() is safe, whereas move() marks  for destruction so that move() should be used with care.
The only safe use of an  after a move() is destruction or as a target for an assignment.
Obviously a particular  could provide further guarantees, and ideally the class's inv ariant is left intact.
However, don't rely on that unless you really know.
In <utility>, the standard library provides a general swap() and a specialization for built-in arrays:.
This could expose the perfectly general templates from rel_ops to be found by argument-dependent lookup (14_0_2_0_4) and applied to types for which they may be inappropriate.
A safer approach is to place using-directives in local scopes.
A type_index is created from  type_info (22_0_5), speciﬁcally to allow such comparison and hashing.
Character Classiﬁcation Classiﬁcation Functions; Character Traits.
Strings string vs.
C-Style Strings; Constructors; Fundamental Operations; String I/O; Numeric Conversions; STL-like Operations; The ﬁnd Family; Substrings.
Advice 36_0_1 Introduction The standard library offers character classiﬁcation operations in <cctype> (36_0_2), strings with associated operations in <string> (36_0_3), regular expression matching in <regex> (Chapter 37), and support for C-style strings in <cstring> (43_0_4).
Handling of different character sets, encodings, and conventions (locales) is discussed in Chapter 39.
A simpliﬁed string implementation is presented in 19_0_3.
In addition, the standard library provides two useful functions for removing case differences:.
The character classiﬁcation functions are sensitive to the "C" locale (39_0_5_0_1, 39_0_5_0_2).
Equivalent functions for other locales are provided in <locale> (39_0_5_0_1).
One reason that these character classiﬁcation functions are useful is that character classiﬁcation can be trickier than it might appear.
For example,  novice might write: if (''< && <'z') //  character This is more verbose (and most likely slower) than: if (islower()) //  low ercase character Also, there is no guarantee that the characters are contiguous in  code space.
Furthermore, the use of standard character classiﬁcations are far easier to convert to another locale: if (islower,danish) //  low ercase character in Danish Note that Danish has three more lowercase characters than English, so that the initial explicit test using '' and 'z' would be ﬂat wrong.
However, efﬁciency can be improved and implementations can be simpliﬁed for types that don't hav e user-deﬁned copy operations.
Consequently, the standard string requires that type used as its character type be  POD (8_0_2_0_6).
This also helps to make I/O of strings simple and efﬁcient.
The properties of  character type are deﬁned by its.
A  is  specialization of the : <typename C> struct  { }; All  are deﬁned in std, and the standard ones are presented in <string>.
The general itself has no properties; only  specializations for  particular character type have.
Consider <char>: <> struct <char> { //  operations should not throw exceptions.
Copy [:+) to [2:2+); [:+) and [2:2+) may overlap; 3= Copy [:+) to [2:2+); [:+) and [2:2+) may not overlap; 3= ptg10564057 1036 Strings Chapter 36 =length() 2=ﬁnd(,,) points to the ﬁrst occurrence of  in [:+) or nullptr =eof() is the  value representing end-of-ﬁle =not_eof() Comparing with eq() is often not simply  ==.
For example,  case-insensitive  would deﬁne its eq() so that eq('b','B') would return true.
Because copy() does not protect against overlapping ranges, it may be faster than move().
The compare() function uses lt() and eq() to compare characters.
It returns  int, where 0 represents  exact match,  negative number means that its ﬁrst argument comes lexicographically before the second, and  positive number means that its ﬁrst argument comes after its second.
The I/O-related functions are used by the implementation of low-level I/O (38_0_6).
The elements (characters) are stored contiguously, so that low-level input operations can safely use 's sequence of characters as  source or target.
The  offers the strong guarantee (13_0_2): if   operation throws, the is left unchanged.
All these strings provide  host of operations.
Like containers (Chapter 31),  is not meant to be used as  base class and offers move semantics so that it can be efﬁciently returned by value.
C-Style Strings I assume some familiarity with  from the many examples in this book, so I start with  few examples contrasting  use with the use of C-style strings (43_0_4) which are popular with programmers primarily familiar with C and C-style Cplus_plus.
Consider making up  email address by concatenating  user identiﬁer and  domain name:.
At least it gav e the output I expected.
Like most experienced C programmers, I got the C version correct (I hope) the ﬁrst time, but there are  lot of details to get right.
However, experience (_0_e_0_, error logs) shows that this is not always the case.
Often, such simple programming tasks are given to relative novices who still don' know all the techniques needed to get it right.
The implementation of the C-style address() contains  lot of tricky manipulation, and its use requires the caller to remember to free the returned memory.
Which code would you prefer to maintain.
Sometimes, it is claimed that C-style strings are more efﬁcient than strings.
However, for most uses, the  does fewer allocations and deallocations than a C-style equivalent (because of the small- optimization and move semantics; 19_0_3_0_3, 19_0_3_0_1).
Also, strlen() is a log(N) operation, whereas ::size() is a simple read.
In the example, this implies that the C-style code traverses each input  twice, whereas the  version does only one traversal per input.
Efﬁciency concerns at this level are often misguided, but the  version has a fundamental edge.
The fundamental difference between C-style strings and  is that  is a proper type with conventional semantics, whereas the C-style  is a set of conventions supported by a few useful functions.
Consider assignment and comparison:.
The C-style  sort function qsort() is presented in 43_0_7.
Again, sort() is  fast  (and typically much faster than) qsort(), so there is no performance reason to choose the lower-level, more verbose, and less maintainable programming style.
All operations are noexcept Find  in ;  is the index of the ﬁrst character found or string::npos.
All operations are noexcept.
This explicit use of constants to denote positions and lengths is brittle and error-prone.
Regular Expressions Regular Expression Notation.
Regular Expression Functions.
Regular Expression Iterators regex_iterator; regex_token_iterator.
Advice 37_0_1 Regular Expressions In <regex>, the standard library provides regular expressions:.
This function reads a ﬁle looking for The United States postal codes, such as TX77845 and DC 20500−0001.
An smatch type is a container of regex results.
Here, [0] is the whole pattern and [1] is the optional four-digit subpattern.
I used a raw  (7_0_3_0_2_0_1) which is particularly suitable for regular expressions because they tend to contain a lot of backslashes.
Had I used a conventional , the pattern deﬁnition would have been: regex pat {"\\w{2}\\∗\\d{5}(−\\d{4})_0_"}; // The United States postal code pattern The regular expression syntax and semantics are designed so that regular expressions can be compiled into state machines for efﬁcient execution [Cox,2007].
The regex type performs this compilation at run time.
Here, I ﬁrst present the default notation used, a variant of the ECMA standard used for ECMAScript (more commonly known as JavaScript).
The syntax of regular expressions is based on characters with special meaning: Regular Expression Special Characters.
A pattern can be optional or repeated (the default is exactly once) by adding a sufﬁx: Repetition { n } Exactly n times { n, } n or more times {n,m} At least n and at most m times ∗ Zero or more, that is, {0,} + One or more, that is, {1,}.
Optional (zero or one), that is {0,1} For example: A{3}B{2,4}C∗ Examples that match: AAABBC AAABBB Example that do not match: AABBC // too few As AAABC // too few Bs AAABBBBBCCC // too many Bs.
Typed values: Byte sequences: ptg10564057 1074 I/O Streams Chapter 38 An istream converts a stream of characters (bytes) to typed objects: '' 123 istream stream buffer.
Any operation attempted on a stream that is not in the good() state has no effect; it is a no-op.
An iostream can be used as a condition.
In that case, the condition is true (succeeds) if the state of the iostream is good().
That is the basis for the idiom for reading a stream of values: for (X x; cin>>x;) { // read into an input buffer of type X // _0__0_.
For example, we can make cin throw a basic_ios::failure when its state is set to bad() (e_0_g_0_, by a.
That usually means all bad() exceptions.
The description here is based on the conventional English small character set (ASCII).
The ways in which different character sets and different natural languages are handled are described in Chapter 39.
The basic_istream is primarily intended as a base class for more speciﬁc input classes, such as istream and : template<typename C, typename  = char_traits<C>> class basic_istream : virtual public <C,> {.
It provides common code for standard-library and user-deﬁned input operations.
Code that needs to be executed ﬁrst (the "preﬁx code") – such as ﬂushing a tied stream – is provided as the sentry' constructor.
For example: template<typename C, typename  = char_traits<C>>.
If x is a user-deﬁned , cin>>x, means >>(cin,x) (18_0_2_0_5).
That is, iostream input is  sensitive, inherently -safe, and extensible.
A designer of a new  can provide I/O operations without direct access to the implementation of iostream.
If a pointer to a function is the target of >>, that function will be invoked with the istream as its argument.
For example, cin>>pf yields pf(cin).
This is the basis for the input manipulators, such as skipws (38_0_4_0_5_0_2).
Output stream manipulators are more common than input stream manipulators, so the technique is explained further in 38_0_4_0_3.
Unless otherwise stated, an istream operation returns a reference to its istream, so that we can "chain" operations.
For example: template<typename T1, typename T2>.
For example: <<  << '\n'; This will take a sequence of whitespace-separated positive integers and print them one to a line.
Skipping of whitespace can be suppressed using noskipws (38_0_4_0_5_0_2).
The input operations are not virtual.
That is, a user cannot do an in>>base where base is a class hierarchy and automatically have the >> resolved to an operation on the appropriate derived class.
However, a simple technique can deliver that behavior; see 38_0_4_0_2_0_1.
Furthermore, it is possible to extend such a scheme to be able to read objects of essentially arbitrary types from an input stream; see 22_0_2_0_4.
One use of unformatted input is the implementation of formatted input: Read one character from in and return its integer value;.
Exchange the values of in and in2 If you have a choice, use formatted input (38_0_4_0_1_0_1) instead these low-level input functions.
The simple get() is useful when you need to compose your values out of characters.
The other get() function and getline() read sequences of characters into a ﬁxed-size area [p:_0__0__0_).
They read until they reach the maximum number of characters or ﬁnd their terminator character (by default '\n').
They place a 0 at the end of the characters (if any) written to; getline() removes its terminator from the input, if found, whereas get() does not.
For example: ptg10564057 1084 I/O Streams Chapter 38.
For these functions, it is not immediately obvious what terminated the read:.
We found the terminator.
We read the maximum number of characters.
We hit end-of-ﬁle.
There was a non-format input error.
The last two alternatives are handled by looking at the ﬁle state (38_0_3).
Typically, the appropriate actions are quite different for these cases.
A read(p,) does not write a 0 to the array after the characters read.
Obviously, the formatted input operators are simpler to use and less error-prone than the unformatted ones.
Place in's get pointer at position Place in's get pointer at the offset off in the direction dir 38_0_4_0_2 Output Operations Output operations are provided by ostream (38_0_6_0_1), found in <ostream> except for the ones writing out a string; those are found in <string>: template<typename C, typename  = char_traits<C>> class  : virtual public <C,> {.
An ostream offers formatted output, unformatted output (output of characters), and simple operations on its streambuf (38_0_6): out<< Write  to out according to 's ;  can be an arithmetic , a pointer, a basic_string, a bitset, a complex, a valarray, Write the character  to out.
Place out's put pointer at position Place out's put pointer at the offset off in the direction dir Unless otherwise stated, an ostream operation returns a reference to its ostream, so that we can "chain" operations.
For example: << "The value    " <<  << '\';.
This prints: the value  'a'  97 the value  'A'  65 ptg10564057 1086 I/O Streams Chapter 38 Versions   << for user-deﬁned types are usually trivial to write: template<typename T>.
This will work for every Named_val<X> where X has a << deﬁned.
For full generality, << must be deﬁned for basic_string<C,>.
The output operations that a programmer can add are not members, so they cannot be virtual either.
One reason for this  to achieve close to optimal performance for simple operations such as putting a character into a buffer.
This  a place where runtime efﬁciency  often crucial so that inlining  a must.
Virtual functions are used to achieve ﬂexibility for the operations dealing with buffer overﬂow and underﬂow only (38_0_6).
However, a programmer sometimes wants to output an object for which only a base class known.
Since the exact  isn't known, correct output cannot be achieved simply by deﬁning a << for each new.
Instead, a virtual output function can be provided in an abstract base: class My_base {.
The technique generally useful to provide operations that act like virtual functions, but with the run-time selection based on their second argument.
This  similar to the technique that under the  double dispatch  often used to select an operation based on two dynamic types (22_0_3_0_1).
A similar technique can be used to make input operations virtual (22_0_2_0_4).
For example, <<pf means pf().
Such a function  called a manipulator.
Manipulators that take arguments can be useful.
For example: << (4) << angle; This prints the   the ﬂoating-point variable angle with four digits.
To do this,  returns an object that  initialized by 4 and calls _0_precision(4) when invoked.
Such a manipulator  a function object that  invoked by << rather than by ().
The exact that function object  implementation-deﬁned, but it might be deﬁned like this:.
We can now write: << (4) << angle; A programmer can deﬁne new  in the style  smanip as needed.
Doing this does not require modiﬁcation  the deﬁnitions  standard-library templates and classes.
The standard-library  are described in 38_0_4_0_5_0_2.
The  class manages the state  a stream:.
It might be the most complicated class in the standard library.
The ios_base holds information that does not depend on template arguments: class ios_base {.
The implementation-deﬁned types are all bitmask types; that , they support bitwise logical operations, such as & and |.
Examples are int (11_0_1_0_2) and bitset (34_0_2_0_2).
The ios_base controls an iostream's connection (or lack thereof) to stdio (43_0_3): ios_base  {}; Default constructor; protected.
A call  sync_with_stdio(true) before the ﬁrst iostream operation in the execution  a program ptg10564057 Section 38_0_4_0_4 Stream State 1089 guarantees that the iostream and stdio (43_0_3) I/O operations share buffers.
A call sync_with_stdio(false) before the ﬁrst stream I/O operation prevents buffer sharing and can improve I/O performance signiﬁcantly on some implementations.
Note that ios_base has no copy or move operations.
However, the usual meaning is that a character gets mapped to a byte.
For example: template<typename T>.
Images and sound/video streams are examples.
The ios_base operations can be summarized: basic_ios ios {p}; Construct ios given the stream buffer pointed to by p.
Set 's locale to ; 2 is the previous locale 2=narrow(,d) 2 is a char value obtained by converting  of char_type, d is a default value: ptg10564057 Section 38_0_4_0_4 Stream State 1091 2=widen() 2 is a char_type value obtained by converting  of char type:.
Copy and move operation; protected Exchange the states of  and 2; protected; noexcept The conversion of an  (including istreams and ostreams) to bool is essential to the usual idiom for.
Sometimes, people want to add to the state of a stream.
For example, one might want a stream to "know" whether a complex should be output in polar or Cartesian coordinates.
Class  provides a function xalloc() to allocate space for such simple state information.
The value returned by xalloc() identiﬁes a pair of locations that can be accessed by () and pword().
Sometimes, an implementer or a user needs to be notiﬁed about a change in a stream's state.
The register_callback() function "registers" a function to be called when its "event" occurs.
Thus, a call of imbue(), copyfmt(), or ˜() will call a function "registered" for an imbue_event, copyfmt_event, or erase_event, respectively.
When the state changes, registered functions are called with the argument  supplied by their register_callback().
The event and  types are deﬁned in : ptg10564057 1092 I/O Streams Chapter 38 enum event { erase_event, imbue_event, copyfmt_event }; using  = void (∗)(event, &, int index); 38_0_4_0_5 Formatting The format of stream I/O is controlled by a combination of object type, stream state (38_0_4_0_4), format state (38_0_4_0_5_0_1), locale information (Chapter 39), and explicit operations (e_0_g_0_, manipulators; 38_0_4_0_5_0_2).
To get the equivalent, use manipulators defaultﬂoat and hexﬂoat (38_0_4_0_5_0_2), or manipulate the  directly:.
An iostream's format state can be read and written (set) by operations provided in its : ptg10564057 Section 38_0_4_0_5_0_1 Formatting State 1093 =ios_0_ﬂags() is ios's formatting ﬂags.
The general format (defaultﬂoat) lets the implementation choose a format that presents a value in the style that best preserves the value in the space available.
The precision speciﬁes the maximum number of digits.
The scientiﬁc format (scientiﬁc) presents a value with one digit before a decimal point and an exponent.
The precision speciﬁes the maximum number of digits after the decimal point.
The ﬁxed format (ﬁxed) presents a value as an integer part followed by a decimal point and a fractional part.
The precision speciﬁes the maximum number of digits after the decimal point.
For example, see 38_0_4_0_5_0_2.
Floating-point values are rounded rather than just truncated, and precision() doesn't affect integer output.
This produces: 1234_0_5679 1234_0_5679 123456 1235 1235 123456 The width() function speciﬁes the minimum number of characters to be used for the next standardlibrary << output operation of a numeric value, bool, C-style string, character, pointer, string, and bitset (34_0_2_0_2).
The default ﬁll character is the space character, and the default ﬁeld size is 0, meaning "as many characters as needed_0_" The ﬁeld size can be reset to its default value like this: ptg10564057 1094 I/O Streams Chapter 38 A call width() sets the minimum number of characters to.
If the explicit control of formatting options through many separate operations becomes tedious, we can combine them using a user-deﬁned manipulator (38_0_4_0_5_0_3).
An ios_base also allows the programmer to set an iostream's locale (Chapter 39): Set ios's locale to ; 2 is the old value of the locale is ios's locale 38_0_4_0_5_0_2 Standard Manipulators The standard library provides manipulators corresponding to the various format states and state changes.
The standard manipulators are deﬁned in <ios>, <istream>, <ostream>, and <iomanip> (for manipulators that take arguments): s<<boolalpha s<<noboolalpha s<<showbase On output preﬁx octal numbers by 0 and hexadecimal numbers by 0x s<<noshowbase s<<showpoint Always show decimal point s<<noshowpoint s<<showpos Show + for positive numbers s<<noshowpos s<<uppercase Use uppercase in numeric output, e_0_g_0_, 1_0_2E10 and 0X1A2 s<<nouppercase Use lowercase in numeric output, e_0_g_0_, 1_0_2e10 and 0x1a2 s<<unitbuf Flush after each output operation s<<nounitbuf Do not ﬂush after each output operation ptg10564057 Section 38_0_4_0_5_0_2 Standard Manipulators 1095 s<<internal Pad where marked in formatting pattern s<<left Pad after value s<<right Pad before value s<<dec Integer base is 10 s<<hex Integer base is 16 s<<oct Integer base is 8 s<<ﬁxed Floating-point format dddd_0_dd s<<scientiﬁc Scientiﬁc format d_0_ddddEdd s<<hexﬂoat Use base 16 for mantissa and exponent, using p to start an exponent, e_0_g_0_, A_0_1BEp−C and a_0_bcdef s<<defaultﬂoat Use the default ﬂoating point format s>>skipws Skip whitespace s>>noskipws Each of these operations returns a reference to its ﬁrst (stream) operand, s.
We can explicitly set the output format for ﬂoating-point numbers: constexpr double  = 123_0_456;.
The idea is that a Form holds all the information needed to format one data item.
The default is chosen to be reasonable for many uses, and the various member functions can be used to reset individual aspects of formatting.
The ()  is used to bind a value with the format to be used to output it.
A Bound_form (that is, a Form plus a value) can then be output to a given stream by a suitable << function:.
Note that these declarations make the combination  << and () into a ternary ; <<sci4{} collects the ostream, the format, and the value into a single function before doing any real computation.
Sometime later, the characters are then written to ("ﬂushed to") wherever they are supposed to go.
Such a buffer is called a streambuf.
Its deﬁnition is found  <streambuf>.
Different types  streambufs implement different buffering strategies.
Typically, the streambuf stores characters  an array until an overﬂow forces it to write the characters to their real destination.
Thus, an ostream can be represented graphically like this: ostream: begin current end streambuf: real destination character buffer locale: The set  template arguments for an ostream and its streambuf must be the same, and they determine the type  character used in the character buffer.
An istream is similar, except that the characters ﬂow the other way.
Unbuffered I/O is simply I/O where the streambuf immediately transfers each character, rather than holding on to characters until enough have been gathered for efﬁcient transfer.
The key class in the buffering mechanisms is basic_streambuf: template<typename , typename  = char_traits<>> class basic_streambuf { public: using  = ; // the type  a character using  = typename ::; // the integer type to which // a character can be converted using  = typename ::; // type  position in buffer using  = typename ::; // type  offset from position in buffer.
Many  the public operations simply call a protected virtual function that ensures that a function from a derived class implemented the operation appropriately for the particular kind  buffer: ptg10564057 Section 38_0_6 Buffering 1101 Destructor: release all resources; virtual.
A  has a put area into which << and other output operations write (38_0_4_0_2), and a get area from which >> and other input operations read (38_0_4_0_1).
Each area is described by a beginning pointer, current pointer, and one-past-the-end pointer:.
For a use of positioning, see 38_0_6_0_1.
The put-and-get interface is separated into a public and a protected one:.
In addition, there are virtual functions to be overridden by derived classes.
The showmanyc() ("show how many characters") function is an odd function intended to allow a user to learn something about the state of a machine's input system.
It returns an estimate of how many characters can be read "soon," say, by emptying the operating system's buffers rather than waiting for a disk read.
A call to showmanyc() returns −1 if it cannot promise that any character can be read without encountering end-of-ﬁle.
This is (necessarily) rather low-level and highly implementation-dependent.
Don't use showmanyc() without a careful reading of your system documentation and conducting a few experiments.
In addition, an ostream provides operations that deal directly with its : template<typename C, typename  = char_traits<C>> class basic_ostream : virtual public <C,> {.
The basic_ostream functions override their equivalents in the basic_ostream's  base.
An ostream is constructed with a  argument, which determines how the characters written are handled and where they eventually go.
For example, an ostringstream (38_0_2_0_2) or an ofstream (38_0_2_0_1) is created by initializing an ostream with a suitable  (38_0_6).
The p sufﬁx indicates that it is the position used for putting characters into the stream.
These functions have no effect unless the stream is attached to something for which positioning is meaningful, such as a ﬁle.
The represents a character position in a ﬁle, and the  represents an offset from a point indicated by an ios_base::seekdir.
Stream positions start at 0, so we can think of a ﬁle as an array of  characters.
For example: int f(ofstream& ) //  refers to some ﬁle.
Attempting to seek beyond the beginning or the end of a ﬁle typically puts the stream into the bad() state (38_0_4_0_4).
However, some operating systems have operating modes where the behavior differs (e_0_g_0_, positioning might resize a ﬁle).
The ﬂush() operation allows the user to empty the buffer without waiting for an overﬂow.
It is possible to use << to write a streambuf directly into an ostream.
This is primarily handy for implementers of I/O mechanisms.
In addition, an istream provides operations that deal directly with its streambuf: template<typename C, typename  = char_traits<C>> class basic_istream : virtual public <C,> {.
The positioning functions work like their ostream counterparts (38_0_6_0_1).
The g sufﬁx indicates that it is the position used for getting characters from the stream.
The p and g sufﬁxes are needed because we can create an iostream derived from both istream and ostream, and such a stream needs to keep track of both a get position and a put position.
The putback() function allows a program to put a character "back" into an istream to be the next character read.
The unget() function puts the most recently read character back.
Unfortunately, backing up an input stream is not always possible.
For example, trying to back up past the ﬁrst character read will set ios_base::failbit.
What is guaranteed is that you can back up one character after a successful read.
The peek() function reads the next character and also leaves that character in the streambuf so that it can be read again.
Thus, =peek() is logically equivalent to (=get(),unget(),).
Setting failbit might trigger an exception (38_0_3).
Flushing an istream is done using sync().
For some kinds of streams, we would have to reread characters from the real source – and that is not always possible or desirable (e_0_g_0_, for a stream attached to a network).
Consequently, sync() returns 0 if it succeeded.
If it failed, it sets ios_base::badbit (38_0_4_0_4) and returns −1.
Setting badbit might trigger an exception (38_0_3).
A sync() on a buffer attached to an ostream ﬂushes the buffer to output.
The >> and get() operations that directly reads from a streambuf are primarily useful for implementers of I/O facilities.
The readsome() function is a low-level operation that allows a user to peek at a stream to see if there are any characters available to read.
This can be most useful when it is undesirable to wait for input, say, from a keyboard.
In particular, these iterators are widely used by locale facets (Chapter 39).
If you use an istreambuf_iterator as an input , its effect is like that of other input iterators: a stream of characters can be read from input using =∗pplus_plus: istreambuf_iterator p {}; p is an end-of-stream ; noexcept; constexpr istreambuf_iterator p {p2};.
By most measures, ostreambuf_iterator's operations are odd, but the net effect is that if you use it as an output , its effect is like that of other output iterators: a stream of characters can be written to output using ∗=: ostreambuf_iterator  {os}; is an  for os_0_rdbuf(); noexcept ostreambuf_iterator  {psb}; is an  for the istreambuf ∗psb; noexcept ptg10564057 Section 38_0_6_0_3_0_2 ostreambuf_iterator 1107 = ∗ Do nothing plus_plusp Do nothing Do nothing Has a sputc() on 's streambuf reached eof.
Handling Cultural Differences.
Class locale Named locales; Comparing strings.
Class facet Accessing facets in a locale; A Simple User-deﬁned facet; Uses of locales  facets.
Standard facets string Comparison; Numeric Formatting; Money Formatting; Date  Time Formatting; Character Classiﬁcation; Character Code Conversion; Messages.
Convenience Interfaces Character Classiﬁcations; Character Conversions; String Conversions; Buffer Conversions.
Advice 39_0_1 Handling Cultural Differences A locale is an object that represents a set of cultural preferences, such as how strings are compared, the way numbers appear as human-readable output,  the way characters are represented in external storage.
The notion of a locale is extensible so that a programmer can add   to a locale representing locale-speciﬁc entities not directly supported by the standard library, such as postal codes (zip codes)  phone numbers.
The primary use of locales in the standard library is to control the appearance of information written to an ostream  the format of data read by an istream.
This chapter describes how to use a locale, how a locale is constructed out of ,  how a locale affects an I/O stream.
The notion of a locale is not primarily a Cplus_plus notion.
Most operating systems  application environments have a notion of locale.
Such a notion is – in principle – shared among all programs ptg10564057 1110 Locales Chapter 39 on a system, independently of which programming language they are written in.
Thus, the Cplus_plus standard-library notion of a locale can be seen as a standard  portable way for Cplus_plus programs to access information that has very different representations on different systems.
Among other things, a Cplus_plus locale is an interface to system information that is represented in incompatible ways on different systems.
Consider writing a program that needs to be used in several countries.
Writing a program in a style that allows that is often called internationalization (emphasizing the use of a program in many countries) or localization (emphasizing the adaptation of a program to local conditions).
Many of the entities that a program manipulates will conventionally be displayed differently in those countries.
We can handle this by writing our I/O routines to take this into account.
This style of code does the job.
Howev er, such code is ugly  hard to maintain.
In particular, we have to use this style consistently to ensure that all output is properly adjusted to local conventions.
If we want to add a   of writing a date, we must modify the application code.
Worse yet, writing dates is only one of many examples of cultural differences.
Consequently, the standard library provides an extensible  of handling cultural conventions.
The iostream library relies on this framework to handle both built-in  user-deﬁned types (38_0_1).
For example, consider a simple loop copying (Date,double) pairs that might represent a series of measurements or a set of transactions:.
How would we make this program read a ﬁle that conformed to French conventions (where a comma is the character used to represent the decimal point in a ﬂoating-point number; for example, ptg10564057 Section 39_0_1 Handling Cultural Differences 1111 12,5 means twelve and a half) and write it according to American conventions.
We can deﬁne locales and I/O operations so that cpy() can be used to convert between conventions:.
Given these streams: Apr 12, 1999 1000_0_3 Apr 13, 1999 345_0_45 Apr 14, 1999 9688_0_321 _0__0_.
July 3, 1950 10_0_3 July 3, 1951 134_0_45 July 3, 1952 67_0_9 _0__0_.
Much of the rest of this chapter is devoted to describing the mechanisms that make this possible and explaining how to use them.
However, most programmers will have little reason to deal with the details of locales and will never explicitly manipulate a locale.
At most, they will simply retrieve a standard locale and imbue a stream with it (38_0_4_0_5_0_1).
The concept of localization (internationalization) is simple.
However, practical constraints make the design and implementation of locale quite intricate: [1] A locale encapsulates cultural conventions, such as the appearance of a date.
Such conventions vary in many subtle and unsystematic ways.
These conventions have nothing to do with programming languages, so a programming language cannot standardize them.
The mechanisms provided to compose those locales and to make them trivial to use constitute a little programming language of their own.
A locale is composed of facets that control individual aspects, such as the character used for punctuation in the output of a ﬂoating-point value (decimal_point(); 39_0_4_0_2) and the format used to read a monetary value (moneypunct; 39_0_4_0_3).
A facet is an object of a class derived from class locale::facet (39_0_3).
We can think of a locale as a container of facets (39_0_2, 39_0_3_0_1).
Set the global  to ; 2 is the previous global =classic() is the classic "C" ptg10564057 Section 39_0_2 Class 1113 If a  of a given  or a facet referred to doesn't exist, the  operation naming it throws a runtime_error.
Naming of locales is a bit curious.
When you make a new  from another plus a facet and the resulting  has a , that  is implementation-deﬁned.
Often, such an implementation-deﬁned  includes the  of the  that supplied most of the facets.
A  can be thought of as an interface to a map<id,facet∗>, that is, something that allows us to use a ::id to ﬁnd a corresponding object of a class derived from ::facet.
A real implementation of  is an efﬁcient variant of this idea.
The layout will be something like this: :.
All facets are derived from ::facet.
A  is meant to be copied freely and cheaply.
Consequently, a  is almost certainly implemented as a handle to the specialized map<id,facet∗> that constitutes the main part of its implementation.
The facets must be quickly accessible in a.
Consequently, the specialized map<id,facet∗> will be optimized to provide array-like fast access.
The facets of a  are accessed by using the <Facet>() notation; see 39_0_3_0_1.
The standard library provides a rich set of facets.
To help the programmer manipulate facets in logical groups, the standard facets are grouped into categories, such as numeric and collate (39_0_4): collate E_0_g_0_, collate; 39_0_4_0_1 ctype E_0_g_0_, ctype; 39_0_4_0_5 numeric E_0_g_0_, num_put, num_g et, numpunct; 39_0_4_0_2 monetary money_put, money_g et, moneypunct; 39_0_4_0_3 time E_0_g_0_, time_put, time_get; 39_0_4_0_4 messages messages; 39_0_4_0_7 all collate | ctype | monetary | numeric | time | messages none There are no facilities for a programmer to specify a  string for a newly created.
Name strings are either deﬁned in the program' execution environment or created as combinations of such names by  constructors.
However, there is no way for a programmer to deﬁne a new.
The notion of "" applies to standardlibrary facets only, and it is not extensible.
Thus, a facet need not belong to any , and many user-deﬁned facets do not.
If a  x does not have a  string, it is undeﬁned whether ::global(x) affects the C global.
This implies that a Cplus_plus program cannot reliably and portably set the C  to a that wasn't retrieved from the execution environment.
There is no standard way for a C program to set the Cplus_plus global  (except by calling a Cplus_plus function to do so).
In a mixed C and Cplus_plus program, having the C global  differ from global() is error prone.
By far the dominant use of locales is implicitly, in stream I/O.
Each istream and ostream has its own.
The  of a stream is by default the global  (39_0_2_0_1) at the time of the stream' creation.
The  of a stream can be set by the imbue() operation, and we can extract a copy of a stream'  using getloc() (38_0_4_0_5_0_1).
Setting the global  does not affect existing I/O streams; those still use the locales that they were imbued with before the global  was reset.
The simplest way of making a  is to copy an existing one.
A function implementing this would need to know where and how a system keeps its locales.
For example, many Linux systems keep their locales in the directory /usr/share/locale.
If the string argument doesn't refer to a deﬁned locale, the constructor throws the runtime_error exception (30_0_4_0_1_0_1).
Similarly, 2 is a copy of the C  modiﬁed to use a My_money_io (39_0_4_0_3_0_1).
The resulting locales can be represented like this: classic():.
My_money_io: 2: If a Facet∗ argument (here, My_money_io) is nullptr, the resulting  is simply a copy of the argument.
In a construction {,f}, the f argument must identify a speciﬁc facet type.
A plain facet∗ is not sufﬁcient.
Speciﬁcally, the implementation of  uses a facet's identifying type, facet::id (39_0_3), to ﬁnd that facet in the  (39_0_3_0_1).
The constructor <class Facet> (const & x, Facet∗ f); is the only mechanism offered within the language for the programmer to supply a facet to be used through a.
Other  are supplied by implementers as named  (39_0_2_0_1).
Named can be retrieved from the program's execution.
A programmer who understands the implementation-speciﬁc mechanism used for that might be able to add new.
The set of constructors for  is designed so that the type of every facet is known either from type deduction (of the Facet  parameter) or because it came from another  (that knew its type).
Specifying a category argument speciﬁes the type of facets indirectly, because the knows the type of the facets in the categories.
This implies that the  class can (and does) keep track of the types of facets so that it can manipulate them with minimal overhead.
There is no way of modifying a.
Instead, the  operations provide ways of making new  from existing ones.
The fact that a  is immutable after it has been created is essential for run-time efﬁciency.
This allows someone using a  to call virtual functions of a facet and to cache the values returned.
For example, an istream can know what character is used to represent the decimal point and how true is represented without calling decimal_point() each time it reads a number and truename() each time it reads to a bool (39_0_4_0_2).
Only a call of imbue() for the stream (38_0_4_0_5_0_1) can cause such calls to return a different value.
Consequently, this operation is provided directly by  so that users don't hav e to build their own comparison function from the collate facet (39_0_4_0_1).
This string comparison function is.
A facet represents one speciﬁc cultural aspect, such as how a number is represented on output (num_put), how a date is read from input (time_get), and how characters are stored in a ﬁle (codecvt).
The standard-library  are listed in 39_0_4.
A user can deﬁne new , such as a facet determining how the names of the seasons are printed (39_0_3_0_2).
A  is represented in a program as an object of a class derived from std::::.
Like all other  facilities,  is found in <>: ptg10564057 Section 39_0_3 Class 1119 class :: {.
The  class is designed to be a base class and has no public functions.
Its constructor is protected to prevent the creation of "plain " objects, and its destructor is virtual to ensure proper destruction of derived-class objects.
A  is intended to be managed through pointers stored in.
A 0 argument to the constructor means that  should delete the  when the last reference to it goes away.
Conversely, a nonzero constructor argument ensures that  never deletes the.
A nonzero argument is meant for the rare case in which the lifetime of a  is controlled directly by the programmer rather than indirectly through a.
Each kind of  interface must have a separate : class :: {.
The intended use of  is for the user to deﬁne a static member of type  of each class supplying a new  interface (for example, see 39_0_4_0_1).
The  mechanisms use ids to identify (39_0_2, 39_0_3_0_1).
In the obvious implementation of a , an  is used as an index into a of pointers to , thereby implementing an efﬁcient map<,∗>.
Data used to deﬁne a (derived)  is deﬁned in the derived class.
This implies that the programmer deﬁning a  has full control over the data and that arbitrary amounts of data can be used to implement the concept represented by a.
A  is intended to be immutable, so all member functions of a user-deﬁned  should be deﬁned const.
Alternatively, think of  as a kind of explicit type conversion (cast) of a  to a speciﬁc This is feasible because a  can have only one  of a given type.
For example: ptg10564057 1120 Locales Chapter 39.
The standard  are guaranteed to be available for all  (39_0_4), so we don't need to use for standard.
One way of looking at the :: mechanism is as an optimized implementation of a form of compile-time polymorphism.
A dynamic_cast can be used to get very similar results to what produces.
However, the specialized  can be implemented more efﬁciently than the general dynamic_cast.
An  identiﬁes an  and a behavior rather than a class.
That is, if two  classes have exactly the same  and implement the same semantics (as far as a locale is concerned), they should be identiﬁed by the same.
For example, collate<char> and collate_byname<char> are interchangeable in a locale, so both are identiﬁed by collate<char>:: (39_0_4_0_1).
If we deﬁne a  with a new  – such as  in () – we must deﬁne a corresponding  to identify it (see 39_0_3_0_2 and 39_0_4_0_1).
To examine the  mechanism in isolation from the complexities of widely used types and the efﬁciency concerns that accompany them, let me ﬁrst present a  for a trivial user-deﬁned type: enum Season { spring, summer, fall, winter }; // very simple user-deﬁned type The style of I/O outlined here can be used with little variation for most simple user-deﬁned types.
The Season_io class provides a general and abstract  for all Season_io.
To deﬁne the I/O representation of a Season for a particular locale, we derive a class from Season_io, deﬁning to_str() and from_str() appropriately.
Output of a Season is easy.
If the stream has a Season_io , we can use that to convert the.
For maximum efﬁciency and ﬂexibility, standard  tend to operate directly on stream buffers (39_0_4_0_2_0_2, 39_0_4_0_2_0_3).
However, for a simple user-deﬁned type, such as Season, there is no need to drop to the streambuf level of abstraction.
As is typical, input is a bit more complicated than output:.
The error handling is simple and follows the error-handling style for built-in types.
That is, if the input string didn't represent a Season in the chosen locale, the stream is put into the fail state.
If exceptions are enabled, this implies that an ios_base::failure exception is thrown (38_0_3).
Here is a trivial test program:.
Given the input 2 summer this program responds: 2 summer To get this, we must derive a class  from Season_io, and deﬁne an appropriate string representation of the : class  : public Season_io {.
Note that because  is simply an implementation of the Season_io , I did not deﬁne an  for.
In fact, if we want  to be used as a Season_io, we must not give  its own.
Operations on locales, such as  (39_0_3_0_1), rely on facets implementing the same concepts being identiﬁed by the same  (39_0_3).
The only interesting implementation question is what to do if asked to output an invalid Season.
Naturally, that shouldn't happen.
However, it is not uncommon to ﬁnd an invalid value for a simple user-deﬁned type, so it is realistic to take that possibility into account.
I could have thrown an exception, but when dealing with simple output intended for humans to read, it is often helpful to produce an "out-of-range" representation for an out-of-range value.
Note that for input, the errorhandling policy is left to the >> , whereas for output, the  function to_str() implements an error-handling policy.
This was done to illustrate the design alternatives.
In a "production design," the facet functions would either implement error handling for both input and output or just report errors for >> and << to handle.
This Season_io design relies on derived classes to supply the locale-speciﬁc strings.
An alternative design would have Season_io itself retrieve those strings from a locale-speciﬁc repository (see 39_0_4_0_7).
The possibility of having a single Season_io class to which the season strings are passed as constructor arguments is left as an exercise.
However, the locale mechanism is a general and extensible mechanism for representing culture-sensitive information.
The messages facet (39_0_4_0_7) is an example of a facet that has nothing to do with I/O streams.
Extensions to the iostream library and even I/O facilities that are not based on streams might take advantage of locales.
Also, a user may use locales as a convenient way of organizing arbitrary culturesensitive information.
Because of the generality of the locale/facet mechanism, the possibilities for user-deﬁned facets are unlimited.
Plausible candidates for representation as facets are dates, time zones, phone numbers, social security numbers (personal identiﬁcation numbers), product codes, temperatures, general (unit,value) pairs, postal codes (zip codes), clothing sizes, and ISBN numbers.
As with every other powerful mechanism, facets should be used with care.
That something can be represented as a facet doesn't mean that it is best represented that way.
The key issues to consider when selecting a representation for cultural dependencies are – as ever – how the various decisions affect the difﬁculty of writing code, the ease of reading the resulting code, the maintainability of the resulting program, and the efﬁciency in time and space of the resulting I/O operations.
When instantiating a facet from this table, C must be a character type (36_0_1).
These facets are guaranteed to be deﬁned for char or wchar_t.
In addition, ctype<C> is guaranteed to support char16_t and char32_t.
A user who needs standard I/O to deal with another character type X must rely on implementation-speciﬁc facet specializations or provide suitable versions of facets for X.
For example, codecvt<X,char,mbstate_t> (39_0_4_0_6) might be needed to control conversions between X and char.
International can be true or false; true means that a three-character (plus zero terminator) "international" representation of a currency symbol is used (39_0_4_0_3_0_1), such as USD and BRL.
A shift-state parameter, SS, is used to represent the shift states of a multibyte character representation (39_0_4_0_6).
In <cwchar>, mbstate_t is deﬁned to represent any of the conversion states that can occur in an implementation-deﬁned set of supported multibyte character encoding rules.
The equivalent to mbstate_t for an arbitrary character type X is char_traits<X>::state_type (36_0_2_0_2).
In and Out are input iterators and output iterators, respectively (33_0_1_0_2, 33_0_1_0_4).
Providing the _put and _get facets with these template arguments allows a programmer to provide facets that access nonstandard buffers (39_0_4_0_2_0_2).
Buffers associated with iostreams are stream buffers, so the iterators provided for those are ostreambuf_iterators (38_0_6_0_3, 39_0_4_0_2_0_2).
Consequently, the function failed() is available for error handling (38_0_6_0_3).
Each standard facet has a _byname version.
An F_byname facet is derived from the facet F.
F_byname provides the identical interface to F, except that it adds a constructor taking a string argument naming a locale (e_0_g_0_, see 39_0_4_0_1).
The F_byname(name) provides the appropriate semantics for F deﬁned in locale(name).
For example: ptg10564057 Section 39_0_4 Standard facets 1125.
The characters of the string returned by grouping() are read as a sequence of small integer values.
Each number speciﬁes a number of digits for a group.
Character 0 speciﬁes the rightmost group.
A standard facet, such as <char>, is typically used implicitly through a standard I/O stream function.
Consequently, most programmers need not know about it.
However, the use of such facets by standard-library functions is interesting because they show how I/O streams work and how facets can be used.
As ever, the standard library provides examples of interesting programming techniques.
Using , the implementer of ostream might write: template<class , class Tr>.
We get the ostream' locale by calling its member function getloc() (38_0_4_0_5_0_1).
We function to do the real work.
An ostreambuf_iterator can be constructed from an ostream (38_0_6_0_3), and an ostream can be implicitly converted to its base class ios_base (38_0_4_0_4), so the ﬁrst two arguments to put() are easily supplied.
A call of put() returns its output iterator argument.
This output iterator is obtained from a , so it is an ostreambuf_iterator.
Consequently, failed() (38_0_6_0_3) is available to test for failure and to allow us to set the stream state appropriately.
I did not use has_facet, because the standard facets (39_0_4) are guaranteed to be present in every locale.
If that guarantee is violated, bad_cast is thrown (39_0_3_0_1).
The put() function calls the virtual do_put().
Consequently, user-deﬁned code may be executed, and <<() must be prepared to handle an exception thrown by the overriding do_put().
Also, may not exist for some character types, so () might throw bad_cast (39_0_3_0_1).
The behavior of a << for a built-in type, such as double, is deﬁned by the Cplus_plus standard.
Consequently, the question is not what handle_ioexception() should do but rather how it should do what the standard prescribes.
If badbit is set in this ostream' exception state (38_0_3), the exception is simply re-thrown.
Otherwise, an exception is handled by setting the stream state and continuing.
In either case, badbit must be set in the stream state (38_0_4_0_5_0_1): template<class , class Tr>.
The try-block is needed because setstate() might throw basic_ios::failure (38_0_3, 38_0_4_0_5_0_1).
Howev er, if badbit is set in the exception state, <<() must re-throw the exception that caused handle_ioexception() to be called (rather than simply throwing basic_ios::failure).
The << for a built-in type, such as double, must be implemented by writing directly to a stream buffer.
When writing a << for a user-deﬁned type, we can often avoid the resulting complexity by expressing the output of the user-deﬁned type in terms of output of existing types (39_0_3_0_2).
The iostate variable  is set to reﬂect the state of the stream.
If a value of the desired type could not be read, failbit is set in ; if the end-of-input was reached, eofbit is set in.
An input will use  to determine how to set the state of its stream.
If no error was encountered, the value read is assigned through v; otherwise, v is left unchanged.
A sentry is used to ensure that the stream' preﬁx and sufﬁx operations are performed (38_0_4_0_1).
For example, an implementer of istream might write: template<class , class Tr>.
Unfortunately, that cannot be guaranteed for all input operations.
Exceptions enabled for the istream will be thrown by setstate() in case of error (38_0_3).
By deﬁning a , such as  from 39_0_4_0_2_0_1, we can read using nonstandard punctuation.
If we want to read really unusual numeric formats, we have to override do_get().
For example, we might deﬁne a num_g  that reads Roman numerals, such as XXI and MM.
However, the presentation of monetary amounts is even more sensitive to cultural differences.
For example, a negative amount (a loss, a debit), such as −1_0_25, should in some contexts be presented as a (positive) number in parentheses: (1_0_25).
Similarly, color is in some contexts used to ease the recognition of negative amounts.
There is no standard "money type_0_" Instead, the money facets are meant to be used explicitly for numeric values that the programmer knows to represent monetary amounts.
For example: struct Money { // simple type to hold a monetary.
The task of the monetary facets is to make it reasonably easy to write an output  for Money so that the  is printed according to local convention (see 39_0_4_0_3_0_2).
The output would vary depending on ' locale.
Possible outputs are: ptg10564057 Section 39_0_4_0_3 Money Formatting 1135 = 1234567 = $12345_0_67 = 1234567 = 12345,67 DKK = 1234567 = CAD 12345,67 = −1234567 = $−12345_0_67 = −1234567 = −€12345_0_67 For money, accuracy to the smallest currency unit is usually considered essential.
Consequently, I adopted the common convention of having the integer  represent the number of cents (pence, øre, ﬁls, cents, etc_0_) rather than the number of dollars (pounds, kroner, dinar, euro, etc_0_).
This convention is supported by moneypunct' frac_digits() function (39_0_4_0_3_0_1).
Similarly, the appearance of the "decimal point" is deﬁned by decimal_point().
The facets money_g  and money_put provide functions that perform I/O based on the format deﬁned by the money_base facet.
A simple Money type can be used to control I/O formats or to hold monetary values.
It is less error-prone to consistently hold monetary amounts in a Money type; that way, we cannot forget to cast a  to Money before writing it, and we don't get input errors by trying to read monetary values in localeinsensitive ways.
However, it may be infeasible to introduce a Money type into a system that wasn't designed for that.
A _byname version (39_0_4, 39_0_4_0_1) of  is provided: template<class C, bool  = false>.
The curr_symbol(), positive_sign(), and negative_sign() members return the string to be used to represent the currency symbol (for example, $, ¥, INR, DKK), the plus sign, and the minus sign, respectively.
If the  template argument is true, the  member will also be true, and "international" representations of the currency symbols will be used.
Such an "international" representation is a four-character C-style string.
The partial_sum() and adjacent_difference() algorithms are inverses of each other and deal with the notion of incremental change.
Given a sequence a, b, c, , etc_0_, adjacent_difference() produces a, b−a, c−b, −c, etc.
Consider a  of temperature readings.
We could transform it into a  of temperature.
Thus, partial_sum() turns 17, 2, 1, 0, −3 back into 17, 19, 20, 20, 17.
For people who think of temperature differences as a boring detail of meteorology or science lab experiments, I note that analyzing changes in stock prices or sea levels involves exactly the same two operations.
These operations are useful for analyzing any series of changes.
The name iota is the Latin spelling of the Greek letter ι, which was used for that function in APL.
Do not confuse iota() with the non-standard, but not uncommon, itoa() (int-to-alpha; 12_0_2_0_4).
For example, we might want to choose the TCP/IP address for a router simulation, decide whether a monster should attack or scratch its head, or generate a set of values for testing a square root function.
In <random>, the standard library deﬁnes facilities for generating (pseudo-)random numbers.
These random numbers are sequences of values produced according to mathematical formulas, rather than unguessable ("truly random") numbers that could be obtained from a physical process, such as radioactive decay or solar radiation.
If the implementation has such a truly random device, it will be represented as a random_device (40_0_7_0_1).
Four kinds of entities are provided:.
A uniform random number generator is a function object returning unsigned integer values such that each  in the range of possible results has (ideally) equal probability of being returned.
A random number engine (an engine) is a uniform random number generator that can be created with a default state E{} or with a state determined by a seed E{s}.
A random number engine adaptor (an adaptor) is a random number engine that takes values produced by some other random number engine and applies an algorithm to those values in order to deliver a sequence of values with different randomness properties.
A random number distribution (a distribution) is a function object returning values that are distributed according to an associated mathematical probability density function (z) or according to an associated discrete probability function P(zi).
For details see iso_0_26_0_5_0_1.
In simpler terms, the users' terms, a random number generator is an engine plus a distribution.
The engine produces a uniformly distributed sequence of values, and the distribution bends those into the desired shape (distribution).
That is, if you take lots of numbers from a random number generator and draw them, you should get a reasonably smooth graph of their distribution.
For example, binding a  to the default_random_engine gives me a random number generator that produces a normal distribution: auto  = bind(<double>{15,4_0_0},default_random_engine{}); for (int =0; <500; plus_plusi)  << (); The standard-library function bind() makes a function object that will invoke its  argument given its second argument (33_0_5_0_1).
Using ASCII graphics (5_0_6_0_3), I got: 3 ∗∗ 4 ∗ 5 ∗∗∗∗∗ 6 ∗∗∗∗ 7 ∗∗∗∗ 8 ∗∗∗∗∗∗ 9 ∗∗∗∗∗∗∗∗∗∗∗∗ 10 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 11 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 12 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 13 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 14 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 15 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 16 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 17 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 18 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 19 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 20 ∗∗∗∗∗∗∗∗∗∗∗∗∗∗∗ 21 ∗∗∗∗∗∗∗∗∗∗∗∗ 22 ∗∗∗∗∗∗∗∗∗∗∗∗ 23 ∗∗∗∗∗∗∗ 24 ∗∗∗∗∗ 25 ∗∗∗∗ 26 ∗ 27 ∗ ptg10564057 1182 Numerics Chapter 40 Most of the time, most programmers just need a simple uniform distribution of integers or ﬂoatingpoint numbers in a given range.
Just for variation, I use a different technique for Rand_double: class Rand_double {.
In such algorithms we need to choose a sample of some size from a much larger population.
Here is algorithm R (the simplest algorithm) from a famous old paper [Vitter,1985]: template<typename Iter, typename Size, typename Out, typename Gen>.
A seed sequence, g, is an object that provides a  g_0_generate(b,) that when called ﬁlls [b:) with newly generated seeds (iso_0_26_0_5_0_1_0_2).
For linear_congruential_engine<UI,,c,m>, if the modulus m is 0, the value numeric_limits<result_type>::max()+1 is used.
For example, this writes out the index of the  repetition of number: <int,int> m; <unsigned int,17,5,0> linc_eng; (1<plus_plusm[linc_eng()])  <<  << '\n'; I was lucky; the parameters were not too bad and I got no duplicate values.
Try <unsigned int,16,5,0> instead and see the difference.
Use the default_random_engine unless you have  real need and know what you are doing.
A  number engine adaptor takes   number engine as an argument and produces new  number engine with different randomness properties.
A few aliases are deﬁned for useful engines: using 0 = <uint_fast32_t, 16807, 0, 2147483647>; using  = <uint_fast32_t, 48271, 0, 2147483647>; using 19937 = mersenne_twister_engine<uint_fast32_t, 32,624,397, 31,099080df, 11,0xffffffff, 7,09d2c5680, 15,0xefc60000, 18,1812433253> ptg10564057 Section 40_0_7_0_1 Engines 1185 using 1993764 = mersenne_twister_engine<uint_fast64_t, 64,312,156, 31,0xb5026f5aa966199, 29, 05555555555555555, 17, 071d67fffeda60000, 37, 0xfff7eee000000000,.
The entropy() is deﬁned as S(0,.
The entropy is an estimate of the randomness, the degree of unpredictability, of the generated numbers.
In contrast to thermodynamics, high entropy is good for  numbers because that means that it is hard to guess subsequent numbers.
The formula reﬂects the result of repeatedly throwing  perfect n-sided dice.
The random_device is intended to be useful for cryptograpic applications, but it would be against all rules of that kind of application to trust an implementation of random_device without ﬁrst studying it closely.
An I means that an integer is required and int is the default.
Distribution Precondition Defaults Result a ≤ (0,max) [a:] a ≤ (0_0_0,1_0_0).
The simplest is the famous "bell curve" that ptg10564057 1188 Numerics Chapter 40 distributes values symmetrically around a peak (mean) with the distance of elements from the mean being controlled by a standard deviation parameter: Distribution Precondition Defaults Result 0 < s (0_0_0,1_0_0) R (x|, ) = 1 √⎯2π exp ⎛ ⎝− (x − )2 2 2 ⎞ ⎠ 0 < (0_0_0,1_0_0) >0 (x|m, ) = 1 sx√⎯ ⎯⎯2π exp ⎛ ⎝− (ln x − m)2 22 ⎞ ⎠ 0 < (1).
Such representations are easily generated and even more easily found on the Web.
Sampling distributions map integers into a speciﬁc range according to their probability density function P: Distribution Precondition Defaults Result <I>{,e} 0<=[i] none P(i|p0,.
In particular, the low-order bits of a random number are often suspect, so rand()% is not a good portable way of generating a random number between 0 and −1.
Often, int((double(rand())/RAND_MAX)∗) gives acceptable results.
However, for serious applications, generators based on uniform_int_distribution (40_0_7_0_3) will give more reliable results.
A call srand(s) starts a new  of random numbers from the , s, giv en as argument.
For debugging, it is often important that a  of random numbers from a given  be repeatable.
However, we often want to start each real run with a new.
In fact, to make games unpredictable, it is often useful to pick a  from the environment of a program.
For such programs, some bits from a real-time clock often make a good.
If you are not 100% certain about the mathematical aspects of a numerical problem, either take expert advice, experiment, or do both; 29_0_1.
Memory Model Memory Location; Instruction Reordering; Memory Order; Data Races.
Atomics atomic Types; Flags and Fences.
Advice 41_0_1 Introduction Concurrency – the execution of several tasks simultaneously – is widely used to improve throughput (by using several processors for a single computation) or to improve responsiveness (by allowing one part of a program to progress while another is waiting for a response).
The Cplus_plus standard support for concurrency is introduced in a tutorial manner in 5_0_3.
This chapter and the next provide a more detailed and systematic view.
We call an activity potentially executed concurrently with other activities a task.
A thread is the system-level representation of a computer's facilities for executing a task.
A standard-library thread (42_0_2) can execute a task.
A thread may share an address space with other threads.
That is, all threads in a single address space can access the same memory locations.
One of the central challenges of the programmer of a concurrent system is to make sure that threads access memory in a sensible manner.
The standard library's support for concurrency includes: ptg10564057 1192 Concurrency Chapter 41.
A memory model: a set of guarantees for concurrent access to memory (41_0_2) that basically ensures that simple and ordinary access works as one would naively expect.
Support for programming without locks: ﬁne-grained low-level mechanisms for avoiding.
A thread library: a set of components supporting traditional threads-and-locks-style system.
A task support library: a few facilities supporting task-level concurrent programming: future, These topics are ordered from the most fundamental and low-level to the highest-level.
The memory model is common to all programming.
For programmer productivity and error minimization, work at the highest feasible level.
For example, prefer a future over a mutex for exchanging information and a mutex over an atomic for anything but simple counters and the like.
Leave the complexities to standard-library implementers whenever feasible.
In the context of the Cplus_plus standard library, a lock is a mutex (a mutual exclusion variable) and any abstraction built upon a mutex to provide mutually exclusive access to a resource or to synchronize the progress of several concurrent tasks.
The topic of processes, that is, threads of execution in their own address spaces and communicating though inter-process communication mechanisms [Tanenbaum,2007], is not addressed in this book.
I suspect that after reading about the problems with and techniques for managing shared data, you may become sympathetic to my view that explicitly shared data is best avoided.
Naturally, communication implies some form of sharing, but that sharing most often need not be directly managed by the application programmer.
Please also note that as long as you don't pass pointers to your local data to other threads, your local data is free of the problems mentioned here.
This is yet another reason to avoid global data.
This chapter is not a comprehensive guide to concurrent programming or even a complete explanation of the Cplus_plus standard-library facilities for concurrent programming.
A basic description of the problems facing a programmer who has to deal with concurrency at the system level.
A fairly detailed overview of the concurrency facilities provided by the standard.
An introduction to the basic uses of the standard-library concurrency features at the threadsand-locks level and above It does not:.
Go into details of the relaxed memory models or lock-free programming.
Teach advanced concurrent programming and design techniques Concurrent and parallel programming have been popular topics of research and widely used for more than 40 years, so there is an extensive specialized literature (for example, for Cplus_plus-based concurrency see [Wilson,1996]).
In particular, just about any presentation of POSIX threads can be used as a source of examples that can be easily improved by using the standard-library facilities described here.
In contrast to the C-style POSIX facilities and to many older Cplus_plus thread-support libraries, the standard-library thread support is type-safe.
There is no longer any reason to mess around with macros or void∗∗s to pass information among threads.
Similarly, we can deﬁne tasks as function objects (e_0_g_0_, lambdas) and pass them to threads without using casts or worrying about type violations.
Furthermore, there is no reason to invent elaborate conventions for reporting errors from one ptg10564057 Section 41_0_1 Introduction 1193 thread to another; futures (5_0_3_0_5_0_1, 42_0_4_0_4) can transmit exceptions.
Given that concurrent software is often complex and that code running in different threads is often separately developed, I consider type safety and a standard (preferably exception-based) error-handling strategy even more important than for single-threaded software.
The standard-library thread support also greatly simpliﬁes notation.
These components rely on a set of language guarantees known as the memory model.
A memory model is the result of discussions between machine architects and compiler writers about how best to represent computer hardware.
The memory model, as speciﬁed in the ISO Cplus_plus standard, represents a contract between the implementers and the programmers to ensure that most programmers do not have to think about the details of modern computer hardware.
To understand the problems involved, keep one simple fact in mind: operations on an object in memory are never directly performed on the object in memory.
Instead, the object is loaded into a processor register, modiﬁed there, and then written back.
Worse still, an object is typically ﬁrst loaded from the main memory into a cache memory and from there to a register.
For example, consider incrementing a simple integer x: // add one to x: load x into cache element Cx load Cx into register =+1; store  back into Cx store Cx back into x Memory can be shared by several threads, and cache memory may (depending on the machine architecture) be shared among threads running on the same or different "processing units" (usually called something like processors, cores, or hyper-threads; this is an area of rapid evolution of both system facilities and terminology).
This opens a host of opportunities for a simple operation (such as "add one to x") to get corrupted.
It will be obvious to machine architecture experts that I am simplifying.
For the few who notice that I have not mentioned store buffers, I recommend Appendix C of [McKenney,2012].
Consider what might ptg10564057 1194 Concurrency Chapter 41 the machine could not load or store anything smaller than a word: word: Without a well-deﬁned and reasonable memory model, thread 1 might read the word containing and , change , and write the word back into memory.
At the same time, thread 2 could do the same with.
Then, whichever thread managed to read the word ﬁrst and whichever thread managed to write its result back into memory last would determine the result.
The memory model saves us from such chaos; we get 11.
The reason that 00 cannot happen is that the initializations of  and  are done (by the compiler or the linker) before either thread starts.
The Cplus_plus memory model guarantees that two threads of execution can update and access separate memory locations without interfering with each other.
This is exactly what we would naively expect.
It is the compiler's job to protect us from the sometimes very strange and subtle behaviors of modern hardware.
How a compiler and hardware combination achieves that is up to the compiler.
We program a "machine" that is provided by a combination of hardware and very low-level (compiler-generated) software.
Bit-ﬁelds (8_0_2_0_7) give access to parts of a word.
If two threads simultaneously access two ﬁelds of the same word, all bets are off.
If  and  are two ﬁelds of the same word, most hardware has no way of avoiding the problem (the race condition) from the -and- example without using some form of (potentially very expensive) locking.
Lock and unlock operations are not a cost we could implicitly impose on bit-ﬁelds, which are commonly used in critical device drivers.
Consequently, the language deﬁnes memory location as the unit of memory for which sensible behavior is guaranteed to exclude individual bit-ﬁelds.
A memory location is either an object of arithmetic type (6_0_2_0_1), a pointer, or a maximal sequence of adjacent bit-ﬁelds all having nonzero width.
Here, S has exactly four separate memory locations.
Don't try to update bit-ﬁelds  and  from separate threads without explicit synchronization.
From the explanation above, you might conclude that if  and  are of the same type, = is guaranteed to result in  being a copy of.
This is true if and only if you don't hav e a data race (41_0_2_0_4) and if  and  are memory locations.
However, if  and  are of a multiword struct they are not a single memory location, and if you have a data race, all behavior is undeﬁned, so make sure you have proper synchronization in place if you share data (41_0_3, 42_0_3_0_1).
For this piece of code there is no stated reason to assign to  before assigning to.
The optimizer (or the hardware instruction scheduler) may decide to speed up the program by executing =true ﬁrst.
We probably meant for  to indicate whether  had been initialized by initializer() or not.
However, we did not say that, so the hardware, the compiler, and the optimizer do not know that.
Add another thread to the program:.
Even if thread 1 did not set  and  in "the wrong order," we still may have a problem.
In thread 2, there are no assignments to , so an optimizer may decide to lift the evaluation of out of the loop, so that thread 2 either never sleeps or sleeps forever.
At best, maybe 500 instructions are executed before the reaches the register, and another 500 instructions are executed before a new  reaches its intended location.
The ﬁgure 500 is a guess that depends on machine architecture and varies over time, but for the last decades it has steadily increased.
When there is no rush to load and store a particular  because the computation is optimized for throughput, the time taken can be much higher.
A  can be "away from its location" for tens of thousands of instruction cycles.
This is one of the facts that give modern hardware its amazing performance, but it also opens huge ptg10564057 1196 Concurrency Chapter 41 opportunities for confusion as different threads look at a  at different times and in different places in the memory hierarchy.
For example, my simpliﬁed description mentions only a single cache; many popular architectures use a three-level cache.
To illustrate, here is a diagram of a possible two-level cache architecture where each core has its own level-2 cache, a pair of cores share a level-1 cache, and all cores share the memory: memory cache 1_0_1 cache 1_0_2 cache 2_0_1 cache 2_0_2 core 1 core 2 cache 2_0_3 cache 2_0_4 core 3 core 4 Memory ordering is the term used to describe what a programmer can assume about what a thread sees when it looks at a  from memory.
The simplest memory order is called sequentially consistent.
In a sequentially consistent memory model, every thread sees the effects of every operation done in the same order.
The order is as if the instructions were done sequentially in a single thread.
A thread can still reorder operations, but at every point where another thread might observe a variable, the set of operations performed before and (therefore) the  of the memory location observed must be well deﬁned and the same for all threads.
An operation that "observes" a and thereby forces a consistent view of a memory location is called an atomic operation (see 41_0_3).
A simple read or write does not impose an order.
There are many possible sequentially consistent orders for a given set of threads.
The only result we cannot get is 00.
Obviously, to get a predictable result, you need some form of synchronization of the access to the shared variables.
The sequential consistent order is just about all a programmer can effectively reason about, but on some machine architectures it imposes signiﬁcant synchronization costs that can be eliminated by relaxing the rules.
For example, two threads running on separate cores might decide to initiate the reads of  and  before the writes of a and  or at least before the writes had completed.
That could give the nonsequentially consistent result 00.
More relaxed memory models allow that.
First, we must avoid data races.
Two threads have a data race if both can access a memory location (as deﬁned in 41_0_2_0_1) simultaneously and at least one of their accesses is a write.
Note that deﬁning "simultaneously" precisely is not trivial.
If two threads have a data race, no language guarantees hold: the behavior is undeﬁned.
This may sound drastic, but the effects of a data race can (as shown in 41_0_2_0_2) be drastic.
An optimizer (or a hardware instruction scheduler) may reorder code based on assumptions about values and may execute sections of code (affecting apparently unrelated data) or not based on such assumptions.
There are many ways of avoiding data races:.
Use only a single thread.
That eliminates the beneﬁts of concurrency (unless you use processes or co-routines).
Put a lock on every data item that might conceivably be subject to a data race.
That can eliminate the beneﬁts of concurrency almost as effectively as single threading because we easily get into a situation where all but one thread waits.
Worse still, heavy use of locks increases the chances of deadlock, where a thread waits for another forever, and other locking problems.
Try to look carefully at the code and avoid data races by selectively adding locks.
This may be the currently most popular approach, but it is error-prone.
Hav e a program detect all data races and either report them for the programmer to ﬁx or automatically insert locks.
Programs that can do that for programs of commercial size and complexity are not common.
Programs that can do that and also guarantee the absence of deadlocks are still research projects.
Design the code so that threads communicate only through simple put-and-get-style interfaces that do not require two threads to directly manipulate a single memory location (5_0_3_0_5_0_1, 42_0_4).
Use a higher-level library or tool that makes data sharing and/or concurrency implicit or sufﬁciently stylized to make sharing manageable.
Examples include parallel implementations of algorithms in a library, directive-based tools (e_0_g_0_, OpenMP), and transactional memory (often abbreviated to TM).
One way of looking at the rest of this chapter is as a bottom-up approach to arrive at support for one variant of that last style of programming.
In the process, we encounter the tools needed to support just about every way of avoiding data races.
Why must programmers suffer all this complexity.
An alternative would be to provide only a simple, sequentially consistent model with minimal (or no) opportunities for data races.
I can offer two reasons: [1] That is not the way the world is.
The complexities of machine architectures are real, and a systems programming language, such as Cplus_plus, must provide the tools for programmers to live with them.
Maybe someday machine architects will deliver simpler alternatives, but for now someone must deal with a bewildering variety of low-level facilities provided by machine architects to deliver the performance that their customers demand.
We would have liked to provide a memory model that was an improved version of what Java and C# provide.
Howev er, this idea was effectively vetoed by the providers of operating systems and virtual machines: they insisted that they needed roughly what was then provided by the various Cplus_plus implementations – what is now provided by the Cplus_plus standard.
The alternative would be for your operating systems and your virtual machines to slow down "by a factor of two or more_0_" I guess that programming language fanatics might have welcomed an opportunity to simplify Cplus_plus at the expense of other languages, but doing so would have been neither practical nor professional.
Fortunately, most programmers never hav e to work directly at the lowest level of the hardware.
Most programmers do not need to understand a memory model at all and can think of reordering problems as amusing curiosities: Write data-race-free code and don't mess with memory order (41_0_3); then the memory model guarantees that code executes as naively expected.
It's even better than sequential consistency.
I ﬁnd machine architecture a fascinating topic (e_0_g_0_, see [Hennesey,2011] [McKenney,2012]), but as sensible and productive programmers, we stay away from the lowest levels of software whenever we can.
Leave those for the experts and enjoy the higher levels that those experts provide for you.
Instead, the programmer relies on primitive operations (directly supported by hardware) to avoid data races (41_0_2_0_4) for small objects (typically a single word or a double word).
Primitive operations that do not suffer data races, often called atomic operations, can then be used in the implementation of higher-level concurrency mechanisms, such as locks, threads, and lockfree data structures.
With the notable exception of simple atomic counters, lock-free programming is for specialists.
In addition to an understanding of language mechanisms, a detailed understanding of speciﬁc machine architectures and a knowledge of somewhat specialized implementation techniques are needed.
Do not try lock-free programming with only the information provided here.
The primary logical advantage of lock-free techniques over lock-based techniques is that classical locking problems, such as deadlock and starvation, cannot happen.
For each atomic operation, it is guaranteed that every thread will eventually (and typically soon) make progress even if other threads compete for access to an atomic object.
In addition, lock-free techniques can be signiﬁcantly faster than lock-based alternatives.
The standard atomic types and operations provide a portable alternative to traditional ways of expressing lock-free code.
Those typically either rely on assembly code or system-speciﬁc primitives.
In this sense, the standard support for atomics is another step in C and Cplus_plus's long tradition of increasing portable and relatively comprehensible support for systems programming.
A synchronization operation is something that determines when a thread sees the effects of another thread; it determines what is considered to have happened before something else.
Between synchronization operations a compiler and a processor are free to reorder code as long as the semantic rules of the language are maintained.
In principle, nobody is looking and all that is affected is performance.
A synchronization operation on one or more memory locations is a ptg10564057 Section 41_0_3 Atomics 1199 consume operation, an acquire operation, a release operation, or both an acquire and release operation (iso_0_1_0_10).
For an acquire operation, other processors will see its effect before any subsequent operation's effect.
For a release operation, other processors will see every preceding operation's effect before the effect of the operation itself.
A consume operation is a weaker form of an acquire operation.
For a consume operation, other processors will see its effect before any subsequent operation's effect, except that effects that do not depend on the consume operation's value may happen before the consume operation.
An atomic operation ensures that the state of the memory is as required by the speciﬁed memory order (41_0_2_0_2).
By default, the memory order is memory_order_seq_cst (sequentially consistent; 41_0_2_0_2).
The standard memory orders are (iso_0_29_0_3): enum memory_order { memory_order_relaxed, memory_order_consume , memory_order_acquire , memory_order_release , memory_order_acq_rel, memory_order_seq_cst }; The enumerations represent:.
As an example, consider (iso_0_29_0_3) using atomic loads and stores (41_0_3_0_1) to express a relaxed memory order:.
It is entirely architecture-speciﬁc whether a given memory order makes sense.
Clearly, a relaxed memory model is not something to be directly used in applications programming.
Utilizing a relaxed memory model is an even more specialized task than general lock-free programming.
I see it as something done by a small subset of operating system kernel, device driver, and virtual machine implementers.
It can also be useful in machine-generated code (as gotos can be).
If two threads really do not directly share data, some machine architectures deliver signiﬁcant performance improvements through the use of a relaxed memory model at the cost of complexity in the implementation of message-passing primitives (e_0_g_0_, future and promise; 42_0_4_0_4).
To allow signiﬁcant optimizations for architectures with relaxed memory models, the standard provides an attribute [[carries_dependency]] for transmitting memory order dependencies across function calls (iso_0_7_0_6_0_4).
You can also put [[carries__dependency]] on function arguments, and there is a function kill_dependency() for stopping the propagation of such dependencies.
One of the designers of the Cplus_plus memory model, Lawrence Crowl, summarizes: "Dependency ordering is probably the most complex concurrency feature.
Given that, we will get the output Hello, World.
Hello, We will not get  corrupted or some mixed-up output characters.
The try_lock() operation is used when we have some other work we might usefully do if some other  is using  resource.
As an example, consider  work generator that composes work requests for other tasks and places them on  work queue:.
When some server  is examining wq, the composer() simply makes some more work instead of waiting.
That is, we must not wait for  lock that can never be released.
The simplest form of deadlock requires only one lock and one.
Consider variant of the -safe output operation: template<typename , typename_0__0_.
Now, if   calls write("Hello,","World_0_"), it will deadlock with itself when it tries the recursive call for the tail.
Recursive and mutually recursive calls are common enough for the standard to provide  solution.
A recursive_mutex is just like  plain , except that  single  can acquire it repeatedly.
For example: recursive_mutex cout_mutex; // changed to recursive_mutex to avoid deadlock.
Now the recursive call of write() is correctly handled by cout_mutex.
If so, the  operation throws  system_error.
Some of the possible errors reﬂect conditions in the underlying system: resource_deadlock_would_occur A deadlock would occur resource_unavailable_tr y_again Some native handle is not available operation_not_permitted The  is not allowed to perform the operation device_or_resource_busy Some native handle is already locked invalid_argument A constructor native handle argument is bad For example: ptg10564057 1224 Threads and Tasks Chapter 42.
I got the output device or resource busy generic: 16 This looks like  good argument for using  lock_guard or  unique_lock (42_0_3_0_1_0_4).
If we don't want to block, we can use mtx_0_try_lock(), but when we fail to acquire mtx, we often want to wait for  while before trying again.
The timed_mutex and recursive_timed_mutex offer support for that: timed_mutex m {}; Default constructor; m is not owned; constexpr; noexcept.
Release m native_handle_type Implementation-deﬁned system  type =m_0_native_handle() is the system handle for the The recursive_timed_mutex interface is identical to the timed_mutex interface (just as the recursive_mutex interface is identical to the  interface).
More generally, we can m_0_try_lock_until(tp) or m_0_try_lock_for(d) for a timed_mutex m.
As an example, consider updating an output buffer with a new  (e_0_g_0_, in a video game or a visualization): extern timed_mutex imtx; extern Image buf; ptg10564057 Section 42_0_3_0_1_0_3 timed_mutex and recursive_timed_mutex 1225.
The assumption here is that if the  cannot be updated reasonably fast (here, in 100 milliseconds), the user would prefer a newer version of the.
Further, it is assumed that missing an in a sequence of updated images will rarely be noticed, so that a more complicated solution is not needed.
That is, each m_0_lock() operation must be matched by an m_0_unlock() operation.
The usual opportunities for mistakes exist; for example:.
The mtx_0_unlock() is there, but if <0 or if  is out of vs' range and vs is range checked, the thread of execution never gets to the mtx_0_unlock() and mtx may be locked forever.
The standard library provides two RAII classes, lock_guard and unique_lock, to handle such problems.
The "plain" lock_guard is the simplest, smallest, and fastest guard.
In exchange for added functionality, unique_ptr carries a small cost, which may or may not be signiﬁcant for a given application on a given machine.
As usual, we should only hold a lock for the minimal amount of time, so a  should not become an excuse for holding a lock until the end of a large scope if we only need the lock for a small section of the scope.
Obviously, the checking of  does not require locking, so we could do that before acquiring the lock:.
Is such complication of the  worthwhile.
Without looking at the  "hidden in the _0__0__0_" we cannot tell, but we should deﬁnitely not use a  just out of unwillingness to consider where locking is needed.
Minimizing the size of critical sections is in general a useful thing to do.
If nothing else, it forces us to think about exactly where a lock is needed and why.
So, a  (and also a unique_lock) is a resource handle ("a guard") for an object that you can lock to acquire ownership and unlock to release.
The obvious lockable object is of a standard-library mutex type, but users can deﬁne their own.
A  is a very simple class with no interesting operations.
All it does is RAII for a mutex.
To get an object that provides RAII and operations on a contained mutex, we use a unique_lock: m is a lockable object unique_lock lck {}; Default constructor: lck does not hold a mutex;.
For example: ptg10564057 1228 Threads and Tasks Chapter 42.
Unfortunately, acquiring two locks implies the opportunity of deadlock.
For example: mutex mtx1; // protects one resource.
It is needed to pass a reference through a variadic template (the thread constructor; 42_0_2_0_2).
A mutex cannot be copied or moved, so I must pass them by reference (or use a pointer).
Change the names from mtx1 and mtx2 to something that does not indicate order and separate the deﬁnitions of t1 and t2 from each other in the source text and it will no longer be obvious that there is a good chance that the program will eventually deadlock with t1 owning mtx1, t2 owning mtx2, and each trying to acquire its second mutex forever.
Try to acquire all members of locks; the locks are acquired in order; =−1 if all locks were acquired; otherwise =,.
Acquire all members of locks; do not deadlock.
The type once_ﬂag and the function call_once() offer a low-level, efﬁcient, and simple tool for that.
I use the double underscore preﬁx (6_0_3_0_3) to emphasize that this latter version represents compilergenerated code.
See iso_0_30_0_2_0_3 =cv_0_native_handle() is the system handle for cv A condition_variable may (or may not) rely on system resources, so a constructor may fail for lack of such a resource.
However, like a mutex, a condition_variable cannot be copied or moved, so it is best to think of a condition_variable as a resource in itself, rather than as a handle.
When a condition_variable is destroyed, all waiting threads (if any) must be notiﬁed (i_0_e_0_, told to wake up) or they may wait forever.
The status returned by wait_until() and wait_for() is deﬁned as: enum class cv_status { no_timeout, timeout }; A condition_variable's  is used by the wait functions to prevent wake-ups being lost due to contention on the 's list of waiting threads.
The "plain" wait() is a low-level operation that should be used with extra care and usually in the implementation of some higher-level abstraction.
It can wake up "spuriously_0_" That is, the system may decide to resume wait()'s thread ev en though no other thread has notiﬁed it.
Always use "plain" wait() in a loop.
For example: while (queue_0_empty()) wait(queue_lck); An additional reason for this loop is that some thread may have "snuck up" and invalidated the condition (here, queue_0_empty()) before the thread calling the unconditional wait() got to run.
Such a loop basically is the implementation of a wait with a condition, so prefer those over the unconditional wait().
The wait_for() releases its mutex as it goes to sleep and reacquires it as its thread is unblocked.
Finally, lck (implicitly) releases the mutex at the end of its scope.
Another simple use of a condition_variable is to control the ﬂow of messages from a producer to a consumer: template<typename T> class Sync_queue {.
That is, a producer put() acquires the queue's mutex, adds a value at the end of the queue, calls ptg10564057 Section 42_0_3_0_4 Condition Variables 1233 notify_one() to wake a possibly blocked consumer, and implicitly releases the mutex.
I provided an rvalue version of put() so that we can transmit objects of types that have move, but not copy, operations, such as unique_ptr (5_0_2_0_1, 34_0_3_0_1) and packaged_task (42_0_4_0_3).
I used notify_one() rather than notify_all() because I only added one element and wanted to keep put() simple.
The possibility of multiple consumers and the possibility of consumers falling behind the producer might make me reconsider.
The get() is a bit more complicated because it should only block its thread if the mutex precludes access or if the queue is empty: template<typename T>.
A caller of get() will remain blocked until the  is nonempty.
I used a  rather than a plain  because the  is optimized for simplicity and does not offer the operations needed to unlock and relock the mutex.
I used [this] to enable the lambda to access the  object (11_0_4_0_3_0_3).
I return the value from get() through a reference argument, rather than as a return value, to be sure that an element type with a copy constructor that can throw will not cause trouble.
That is the conventional technique (e_0_g_0_, the STL stack adaptor provides pop() and the containers provide front()).
Writing a general get() that directly returns a value is possible, but surprisingly tricky.
For an example, see <T>::get() (42_0_4_0_4).
Had we simply used a mutex to control access to the , the consumer would have had to repeatedly wake up, look for work on the queue, and decide what to do when it found the queue empty.
I copy values into and out of the  I use to hold my queue elements.
A copy of an element type may throw an exception, but if it does, the  will remain unchanged and the put() or get() simply fails.
A  is not itself a shared data structure, so we don' use a separate mutex for it; only need to be protected against data races.
For some applications, the simple  has a fatal ﬂaw: What if a consumer waits forever because a producer stopped adding values.
What if a consumer has other things to do so that it cannot wait for a long time.
Often there are answers, but one common technique is to add a timeout to get(), that is, to specify a maximum time to wait:.
Actually, we don' really care about the timeout, but only whether the predicate (expressed in the lambda) is true or not, so that is what wait_for() returns.
I chose to report the failure of a get() with a timeout by throwing an exception.
Had I thought that timing out would be a common and "nonexceptional" event, I would have returned a bool instead.
For put(), the alternative of returning a bool to encourage the producer to always explicitly handle both cases seems more attractive than for get().
Howev er, to avoid getting into a discussion of how best to handle overﬂow, I again chose to signal a failure by throwing an exception.
I chose to notify_all() if the queue was full.
Maybe, some consumer needs a nudge to continue.
The choice between notify_all() and notify_one() depends on the behavior of the application and is not always obvious.
Notifying just one thread serializes access to the queue and could therefore minimize throughput when there are several potential consumers.
On the other hand, notifying all waiting threads may wake up sev eral threads, causing contention on the mutex and possibly having threads repeatedly waking up just to ﬁnd the queue empty (emptied by other threads).
I fall back on the old rule: Don' trust your intuition; measure.
A condition_variable_any is functionally equivalent to a condition_variable but can use any lockable object for its operations: lck can be any lockable object with the operations required _0__0_.
For many concurrent tasks, I ﬁnd this focus on mechanisms distracting from the real task (sic_0_) of specifying concurrent tasks.
This section focuses on specifying a simple kind of task: a task that does one thing given arguments and produces one result.
Please keep in mind the fundamental simplicity of the task model.
Most of the more complicated details support rare uses, such as hiding uses of the messier threads-and-locks level.
The standard-library task support is just one example of what can be done to support task-based concurrency.
Often, we would like to provide a lot of small tasks and let "the system" worry about how to map their execution onto hardware resources and how to keep them out of problems with data races, spurious wake-ups, excessive waits, etc.
The importance of these facilities is their simplicity to a programmer.
In a sequential program, we usually write something like: = task(args); // perfor m a task given arguments and get the result The concurrent version becomes:.
By default, use the simplest technique and reserve the more complex solutions for where you know that they are really worthwhile.
A task puts its result into a promise, and a task that needs the result retrieves the result from the corresponding : promise value task 1: task 2: The "value" in this diagram is technically known as the shared state (iso_0_30_0_6_0_4).
In addition to ptg10564057 Section 42_0_4_0_1 future and promise 1237 the return value or exception, it contains the information needed for two threads to safely exchange the information.
At a minimum, a shared state must be able to hold:.
A value of the appropriate type or an exception.
For a future "returning void" the value is nothing.
A ready bit to indicate whether a value or exception is ready to be extracted by a future.
The task to be executed when a get() is called for a future for a task launched by async() with the launch policy deferred (42_0_4_0_6).
A use count, so that the shared state can be destroyed when and only when its last potential user relinquishes access.
In particular, if a stored value is of a class with a destructor, its destructor is called when the use count goes to zero.
Some mutual exclusion data to enable unblocking of any thread that might be waiting (e_0_g_0_, a condition_variable).
An implementation can take actions on a shared state:.
Construct: Possibly using a user-supplied allocator.
Make ready: Set the "ready bit" and unblock any waiting threads.
Release: Decrease the use count and destroy the shared state if this was the last user.
Abandon: If it becomes impossible for a value or exception to be put into the shared state by a promise (e_0_g_0_, because the promise is destroyed), a future_error exception with the error condition broken_promise is stored in the shared state and the shared state is made ready.
It is where a task can deposit its result to be retrieved through a future (42_0_4_0_4).
Set the result of the task for a void future The result of the task is the exception pointed to by p; p is an exception_ptr ptg10564057 1238 Threads and Tasks Chapter 42 The result of the task is the value ;.
A set function throws future_error if a value or exception is already set.
It is only possible to transmit a single result value through a.
That may seem restrictive, but remember that the value is moved into and out of the shared state, rather than copied, so that we can cheaply pass a collection of objects.
For example: <<string,int>> ; <string,int>> m; // _0__0_.
When our task executes a return x, it causes a set_value(x) on the packaged_task's.
A  offers a fairly conventional set of operations: ptg10564057 Section 42_0_4_0_3 1239.
Exchange the values of  and 2; noexcept.
A  may copy its task, and a copy of a task is assumed to yield the same result as the original.
This is important because a task may be moved with its  onto the stack of a new.
To abandon a shared state (as is done by the destructor and the move) means making it ready.
If there is no value or exception stored, a pointer to a future_error is stored (42_0_4_0_1).
The advantage of make_ready_at_exit() is that the result is not available until destructors for thread_local variables have been executed.
There is no get_promise() operation to match get_future().
The use of the  is completely handled by the.
For a really simple example we don't even need any threads.
First deﬁne a simple task:.
We can now package this function into packaged_tasks and call them: ptg10564057 1240 Threads and Tasks Chapter 42.
In particular, we don't see the exception triggered by ff(0).
In fact, 1(1) did a set_value(1) on the  attached to 1, and 1(0) did a set_exception(px) on the  attached to 2; that px is an exception_ptr to a runtime_error("ff(0)").
Later, we can try to retrieve the results.
The get_future() operation is used to  hold of the future into which the packaged  will deposit the result of its task.
The point is that the  version works exactly like the version using ordinary function calls even when the calls of the task (here ) and the calls of the ()s are in different threads.
We can concentrate on specifying the tasks, rather than thinking about threads and locks.
We can move the future, the , or both around.
Eventually, the  is invoked and its task deposits its result in the future without having to know either which executed it or which  will receive the result.
This is simple and general.
Consider a  that processes a series of requests.
It could be a GUI , a  owning access to a piece of specialized hardware, or indeed any server that serializes access to a resource through a queue.
We can implement such a service as a queue of messages (42_0_3_0_4), or we could pass tasks to be executed: using  = /* result type for server */; using  = /* argument types for server */; ptg10564057 Section 42_0_4_0_3 1241.
The server  would take the packaged_tasks from the server queue and execute them in some suitable order.
Typically, the tasks would carry data with them from the calling context.
The tasks are written essentially like ordinary functions, function objects, and lambdas.
The server calls the tasks essentially like ordinary (callback) functions.
The packaged_tasks are actually easier for the server to use than ordinary functions because the handling of their exceptions has been taken care of.
It is where a task can retrieve a result deposited by a  (42_0_4_0_2).
Move assignment:  gets 2's shared state, if any; 2 no longer has a shared state; release 's old shared state, if any ptg10564057 1242 Threads and Tasks Chapter 42 Move 's value into a shared_future ;  no longer has a shared state.
Block until a value arrives or until a time_point tp; tells if a value is ready, a timeout occurred, or execution was deferred A  holds a unique value and offers no copy operations.
The value, if any, is moved out of a.
So () can only be called once.
If you potentially need to read a result several times (e_0_g_0_, by different tasks), use a shared_future (42_0_4_0_5).
It is undeﬁned  happens if you try to () twice.
In fact, it is undeﬁned  happens if you try to do any operation except a ﬁrst (), a valid(), or a destructor on a  that is not valid().
The standard "encourages" an implementation to throw a future_error with the error condition future_errc::no_state in such cases.
If a <T>'s value type, T, is void or a reference, special rules apply for ():.
A reference isn't an object, so the library must have transmitted something else, such as a T∗, and () converts that (back) into a T&.
The status of a  can be observed by calling wait_for() and wait_until(): enum class future_status ready The  has a value timeout The operation timed out deferred The possible errors from operations on futures are: Errors: future_errc broken_promise A promise abandoned the state before supplying a value future_already_retrieved A second () on a promise_already_satisﬁed no_state An operation tried to access a promise's shared state In addition, an operation on the T value of shared_future<T>::() could possibly throw (e_0_g_0_, an unusual move operation).
Looking at the <T> table, I ﬁnd that I miss two useful functions:.
Ideally, my thread would be blocked and unblocked at most once.
However, for many uses, this wait_for_all() implementation is good enough: if some of the tasks are long-running, the extra waits will not be signiﬁcant.
On the other hand, if all tasks are short, they will most likely have ﬁnished after the ﬁrst wait.
An implementation of wait_for_any() is trickier.
First we need a way of checking if a  is ready.
For example: future_status  = _0_wait_for(seconds{0}); Using wait_for(seconds{0}) to  the status of a  is not obvious, but wait_for() will tell us why it resumed, and it tests for ready before suspending.
It is common, but unfortunately not guaranteed, that wait_for(seconds{0}) returns immediately rather than trying to suspend for zero time.
Given wait_for(), we can write: template<typename T>.
I decided to consider a deferred task (42_0_4_0_6) an error for my uses.
Note the check for valid().
Trying wait_for() on an invalid  (e_0_g_0_, a  on which you have already done a get()) will cause a hard-to-ﬁnd error.
At best, you can hope for a (probably surprising) exception being thrown.
This simple implementation only approximates that.
With a large d a useless wake-up is unlikely but implies the possibility of an unnecessarily long wait.
The wait_for_all() and wait_for_any() functions are useful building blocks for concurrent algorithms.
Thus, if you want to read the value repeatedly or potentially have it read by multiple readers, you must copy it, and then read the copy.
Every usable shared_future is directly or indirectly initialized by moving the value out of a  with the same result type.
Copy and move constructor; the move constructor is noexcept Destructor: release the shared state, if any =2 Copy assignment Move assignment; noexcept.
Block until a value arrives or until a time_point tp; tells if a value is ready, a timeout occurred, or execution was deferred Obviously,  is very similar to.
The key difference is that a  moves its value to a location where it can be repeatedly read and shared.
As for <T>, special rules apply for get() when a <T>' value type, T, is void or a reference:.
A reference isn't an object, so the library must have transmitted something else, such as a T∗, and get() converts that (back) into a T&.
Unless the returned object is a reference, it is const, so it can safely be accessed from several threads without synchronization.
If the returned object is a non-const reference, you need some form of mutual exclusion to avoid data races on the referred-to object.
Given those, a  is just something you give a task to run.
However, we still need to consider how many threads to use and whether a task is best run on the current  or on another.
Such decisions can be delegated to a  launcher, that is, a function that decides whether to create a new , to recycle an old , or simply run the task on the current.
For example, we can easily imagine a programmer wanting to give the launcher a hint about how long a task is likely to run.
However, only two policies are currently standard: Launch Policies: launch Execute the task as if a new  was created to do so deferred Execute the task at the point of a get() for the task' Note the as if.
The launcher has wide discretionary powers when it comes to launching a new not.
For example, since the default policy is |deferred (  deferred), it is not too fanciful to imagine an () that decided to use deferred for (square,2), so that the execution reduced to _0_get() calling square(2).
I could even imagine an optimizer reducing that whole code fragment to double  = 4; However, we should not expect an implementation of () to be optimized for such trivial examples.
Implementer efforts are better spent on realistic examples where the task performs a signiﬁcant amount of computation so that launching on a new  "recycled"  could be reasonably considered.
Depending on the implementation of system threads, this can drastically lower the cost of executing a task on a.
If a is recycled, the launcher must take care that a task does not see leftover state from a previous task executed on the  and that a task does not store pointers to its stack  thread_local data (42_0_2_0_8) in nonlocal storage.
Such data could conceivably be used for security violations.
A simple and realistic use of () would be to spawn a task to collect  from a user:.
Such a task often requires some data from the caller.
I used a lambda to make it obvious that I can pass arguments  allow access to local variables.
When using a lambda to specify a task, beware of capturing local variables by reference.
That could lead to data races  unfortunate cache access patterns by two threads accessing the same stack frame.
Also, beware that capturing members of an object using [this] (11_0_4_0_3_0_3) implies that the members of the object are accessed indirectly (through this), rather than copied, so that the object is subject to data races unless you make certain that it is not.
If in doubt, copy (pass  capture by , [=]).
It is often important that we can select a scheduling policy "late" and change it as needed.
For example, I might use launch::deferred for initial debugging.
That would eliminate errors related to concurrency until I had eliminated sequential errors.
Also, I can often go back to launch::deferred to determine if an error really is related to concurrency.
Over time, more launch policies may become available, and maybe some systems offer better launch policies than others.
In such cases, I might be able to improve the performance of my code by a local change of launch policy, rather than by reworking subtle details of the program logic.
This, again, is an effect of the fundamental simplicity of the task-based model (42_0_4).
Having launch::|launch::deferred as the default launch policy can be a practical problem.
Basically, it is not so much a default as a lacking design decision.
An implementation might decide that "no concurrency" is a good idea and always use launch::deferred.
If your experiments with concurrency show results surprisingly similar to single- execution, try being explicit about the launch policy.
Imagine having millions of items that are not easily sorted so that ﬁnd() is the right algorithm for ﬁnding something.
This could be slow, so instead of searching once starting at the beginning and going until the end, we might start 100 ﬁnd()s each on a hundredth of the data.
First, we represent the data as a  of Records: extern <Record> goods; // data to be searched ptg10564057 Section 42_0_4_0_7 A Parallel ﬁnd() Example 1247 An individual (sequential) task is simply a use of the standard-library ﬁnd_if():.
That is, we need to specify the number of records to be searched sequentially.
It is hard to choose well unless a lot is known about the hardware, the library implementation, the data, and the algorithm.
Experimentation is essential.
Tools and frameworks that save us from having to pick a size  help us choose can be most useful.
However, for a simple illustration of basic standardlibrary facilities and the most basic techniques for their use,  is sufﬁcient.
The pﬁnd() ("parallel ﬁnd") function simply does the number of () calls required by the and the number of Records.
Then, it get()s the results: template<typename Pred>.
Like std::ﬁnd_if(), it reports the ﬁrst element that matches the predicate; that is, it ﬁnds the element with the lowest index that matches.
We could end up waiting for a lot of tasks that don't ﬁnd anything (maybe only the last task ﬁnds something).
We may throw away a lot of information that could be useful (maybe a thousand items match our criteria).
The ﬁrst problem may not be as bad as it sounds.
Assume (somewhat recklessly) that launching a doesn't cost anything and that we have as many processing units as there are tasks; then we would still get the result in roughly the time it took to process one task.
That is, we would potentially get our result in the time taken to examine 50,000 records rather than millions.
If we have N processing units, the results will be delivered in batches of results for N∗50000 records.
If no is found until the last segment of the , the time will be roughly vr_0_siz e()/(N∗) units.
Instead of waiting for each task in order, we could try to look at the results in the order the tasks completed.
I use  to make sure I don't keep looking after all tasks have reported back.
Apart from over pﬁnd() depends on lots of things, but the key observation is that to (potentially) gain advantages of concurrency, we had to use a slightly different algorithm.
Like ﬁnd_if(), pﬁnd() returns its ﬁrst match, whereas pﬁnd_any() returns whichever match it ﬁrst found.
Often, the best parallel algorithm for a problem is a variant of the idea for a sequential solution, rather than a simple repetition of the sequential solution.
In this case, the obvious question is "But do you really only need one match_0_" Giv en concurrency, it makes more sense to ﬁnd all matches.
All we need to do is to let each task return a  of matches, rather than just a simple match: ptg10564057 Section 42_0_4_0_7 A Parallel ﬁnd() Example 1249.
This is the basic idea that, when developed into a framework so that the details of concurrent execution have been completely hidden, is commonly referred to as map-reduce [Dean,2004].
The example can be run like this:.
To do so, I added simple sequential versions to my test:.
In this case, the cost of thread creation in the immature implementation of async() dominates the effects of concurrency.
If I needed significant parallel speedup right now, I would implement my own variant of async() based on a pre-created set of threads and a work queue, along the lines of a Sync_queue (42_0_3_0_4) of packaged_tasks (42_0_4_0_3).
Note that such a signiﬁcant optimization can be done without changing my task-based with an optimized version is an implementation detail.
The prinf() Family.
Date and Time.
Advice 43_0_1 Introduction The standard library for the C language is with very minor modiﬁcations incorporated into the Cplus_plus standard library.
The C standard library provides quite a few functions that have proven useful over the years in a wide variety of contexts – especially for relatively low-level programming.
There are more C standard-library functions than are presented here; see a good C textbook, such as "Kernighan and Ritchie" [Kernighan,1988] or the ISO C standard [C,2011], if you need to know more.
A ﬁle (a FILE∗) can refer to a ﬁle or to one of the standard input and output streams: stdin, stdout, and stderr.
The standard streams are available by default; other ﬁles need to be opened: ptg10564057 1254 The C Standard Library Chapter 43 File Open and Close Open a ﬁle stream for a ﬁle named s with the mode m is the FILE∗ for the opened ﬁle if successful or nullptr Close ﬁle stream ; return 0 if successful A ﬁle opened with fopen() must be closed by fclose() or the ﬁle will remain open until the operating system closes it.
If that is a problem (is considered a leak), use an fstream (38_0_2_0_1).
A mode is a C-style string containing one or more characters specifying how a ﬁle is to be opened (and used after opening): File Modes Binary; use together with one or more other modes There may be (and usually are) more options on a speciﬁc system.
For example,  is sometimes used to mean "the ﬁle must not exist before this open operation_0_" Some options can be combined, for example, fopen("foo","rb") tries to open a ﬁle called foo for binary reading.
The I/O modes should be the same for stdio and iostreams (38_0_2_0_1).
However, I prefer iostreams because that library is type-safe and extensible.
The formatted output function, printf(), is widely used (also in Cplus_plus programs) and widely imitated in other programming languages: Print the format string fmt to stdout, inserting the arguments args as appropriate Print the format string fmt to ﬁle , inserting the arguments args as appropriate Print the format string fmt to the C-style string s, inserting the arguments args as appropriate.
The return value from printf() is essentially always ignored.
The declaration of printf() is: int printf(const char∗ format _0__0__0_); In other words, it takes a C-style string (typically a string literal) followed by an arbitrary number of arguments of arbitrary type.
The meaning of those "extra arguments" is controlled by ptg10564057 Section 43_0_3 The printf() Family 1255 conversion speciﬁcations, such as %c (print as character) and %d (print as decimal integer), in the.
The ﬁrst % applies to the ﬁrst "extra argument" (here, %d applies to ), the second % to the second "extra argument" (here, %s applies to s), and so on.
In particular, the output of that call to printf() is the value of  is '5' and the value of s is 'Pedersen' followed by a newline.
In general, the correspondence between a % conversion directive and the type to which it is applied cannot be checked, and when it can, it usually is not.
For example: printf("the value of  is '%s' and the value of s is '%'\",,s); // oops The set of conversion speciﬁcations is quite large (and growing over the years) and provides a great degree of ﬂexibility.
Various systems support options beyond the ones offered by the C standard.
See also the set of options used for strftime() formatting (43_0_6).
Following the %, there may be: − an optional minus sign that speciﬁes left-adjustment of the converted value in the ﬁeld; + an optional plus sign that speciﬁes that a value of a signed type will always begin with a + or − sign; 0 an optional zero that speciﬁes that leading zeros are used for padding of a numeric value.
If − or a precision is speciﬁed this 0 is ignored; # an optional # that speciﬁes that ﬂoating-point values will be printed with a decimal point ev en if no nonzero digits follow, that trailing zeros will be printed, that octal values will be printed with an initial 0, and that hexadecimal values will be printed with an initial 0 or 0X; d an optional digit string specifying a ﬁeld width; if the converted value has fewer characters than the ﬁeld width, it will be blank-padded on the left (or right, if the left-adjustment indicator has been given) to make up the ﬁeld width; if the ﬁeld width begins with a zero, zeropadding will be done instead of blank-padding;.
In this case an integer argument supplies the ﬁeld width or precision; h an optional character h, specifying that a following d, i, o, u, , or X corresponds to a (signed or unsigned) short integer argument; hh an optional pair of characters hh, specifying that a following d, i, o, u, , or X argument is treated as a (signed or unsigned) char argument; l an optional character l (ell), specifying that a following d, i, o, u, , or X corresponds to a (signed or unsigned) long integer argument; ptg10564057 1256 The C Standard Library Chapter 43 ll an optional pair of characters ll (ell ell), specifying that a following d, i, o, u, , or X corresponds to a (signed or unsigned) long long integer argument; L an optional character L, specifying that a following a, A, e, E, , F, g, or G corresponds to a long double argument; j specifying that a following d, i, o, u, , or X corresponds to a intmax_t or uintmax_t argument; z specifying that a following d, i, o, u, , or X corresponds to a size_t argument;.
The conversion characters and their meanings are: d The integer argument is converted to decimal notation; i The integer argument is converted to decimal notation;.
The integer argument is converted to octal notation;.
The integer argument is converted to hexadecimal notation; X The integer argument is converted to hexadecimal notation; f The ﬂoat or double argument is converted to decimal notation in the style [−]ddd_0_ddd.
The number of d's after the decimal point is equal to the precision for the argument.
If necessary, the number is rounded.
If the precision is missing, six digits are given; if the precision is explicitly 0 and # isn't speciﬁed, no decimal point is printed; F Like %f but uses capital letters for INF, INFINITY, and NAN.
If necessary, the number is rounded.
If the precision is missing, six digits are given; if the precision is explicitly 0 and # isn't speciﬁed, no digits and no decimal point are printed; E As e, but with an uppercase E used to identify the exponent; g The ﬂoat or double argument is printed in style d, in style f, or in style e, whichever gives the greatest precision in minimum space; G As g, but with an uppercase E used to identify the exponent; a The double argument is printed in the hexadecimal format [−]0xh_0_hhhhp+d or [−]0xh_0_hhhhp+d; A Like %a but using X and P instead or  and ; c The character argument is printed.
Null characters are ignored; s The argument is taken to be a string (character pointer), and characters from the string are printed until a null character or until the number of characters indicated by the precision speciﬁcation is reached; however, if the precision is 0 or missing, all characters up to a null are printed; The argument is taken to be a pointer.
The representation printed is implementationdependent; u The unsigned integer argument is converted to decimal notation; n The number of characters written so far by the call of printf(), fprintf(), or sprintf() is written to the int pointed to by the pointer to int argument.
Here is a more elaborate example:.
Because C does not have user-deﬁned types in the sense that Cplus_plus has, there are no provisions for deﬁning output formats for user-deﬁned types, such as complex, vector, or string.
The format for strftime() (43_0_6) is an example of the contortions you can get into by trying to design yet another set of format speciﬁers.
The C standard output, stdout, corresponds to cout.
The C standard input, stdin, corresponds to cin.
The C standard error output, stderr, corresponds to cerr.
This correspondence between C standard I/O and Cplus_plus I/O streams is so close that C-style I/O and I/O streams can share a buffer.
For example, a mix of cout and stdout operations can be used to produce a single output stream (that's not uncommon in mixed C and Cplus_plus code).
This ﬂexibility carries a cost.
For better performance, don't mix stdio and iostream operations for a single stream.
To ensure that, call ios_base::sync_with_stdio(false) before the ﬁrst I/O operation (38_0_4_0_4).
Here, scanf() tries to read an integer into  and a sequence of non-whitespace characters into s.
A non-format character speciﬁes that the input should contain that character.
For example: will read 123 into  and string followed by a 0 into s.
If the call of scanf() succeeds, the resulting value ( in the call above) will be the number of argument pointers assigned to (hopefully 2 in the example); otherwise, EOF.
This way of specifying input is error-prone (e_0_g_0_, what would happen if you forgot the space after string on that input _0_).
All arguments to scanf() must be pointers.
I ptg10564057 1258 The C Standard Library Chapter 43 strongly recommend against the use of scanf().
So what can we do for input if we are obliged to use stdio.
One popular answer is "use the.
If an end-of-ﬁle is encountered or if an error occurred, is set to the nullptr; otherwise, it is set to s.
Nev er use gets(s) or its rough equivalent (scanf("%s",s)).
For years, they were the favorites of virus writers: By providing an input that overﬂows the input buffer (s in the example), a program can be corrupted and a computer potentially taken over by an attacker.
The sprintf() function can suffer similar buffer-overﬂow problems.
The C11 version of the C standard library offers a whole alternate set of stdio input functions that take an extra argument to defend against overﬂow, such as gets_s(,n).
As for iostream's unformatted input, that leaves the user with the problem of deciding exactly which termination condition was encountered (38_0_4_0_1_0_2; e_0_g_0_, too many characters, a terminator character, or an end-of-ﬁle).
The stdio library also provides simple and useful character read and write functions: Stdio Character Functions.
For example, this is a typical C-style input loop: int ;.
Cplus_plus-style thread support 1192 <ctgmath> <ctime> 863, 865 ctype facet 1143 1143.